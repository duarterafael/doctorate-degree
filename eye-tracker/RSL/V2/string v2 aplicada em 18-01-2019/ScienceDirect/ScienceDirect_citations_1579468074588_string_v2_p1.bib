@article{IVIE2010324,
title = "Cognitive process modeling of spatial ability: The assembling objects task",
journal = "Intelligence",
volume = "38",
number = "3",
pages = "324 - 335",
year = "2010",
issn = "0160-2896",
doi = "https://doi.org/10.1016/j.intell.2010.02.002",
url = "http://www.sciencedirect.com/science/article/pii/S0160289610000255",
author = "Jennifer L. Ivie and Susan E. Embretson",
keywords = "Spatial ability, Cognitive process modeling, Assembling objects, Eye tracking",
abstract = "Spatial ability tasks appear on many intelligence and aptitude tests. Although the construct validity of spatial ability tests has often been studied through traditional correlational methods, such as factor analysis, less is known about the cognitive processes involved in solving test items. This study examines the cognitive processes involved in the assembling objects task found on the Revised Minnesota Paper Form Board Test (RMPFBT), a spatial task in which a test taker must mentally assemble two-dimensional objects. A two-part study was conducted to examine the construct validity of these items and to explain how test takers solve assembling objects tasks. The first part of the study used quantitative methods to examine the contribution of item characteristics to the difficulty of the item and the response time necessary to solve the item. The second part of the study utilized an eye-tracking device to qualitatively examine the steps examinees follow to solve these items. As a result of the second part of this study, a new cognitive processing model is proposed."
}
@article{AZEVEDO2019207,
title = "Analyzing Multimodal Multichannel Data about Self-Regulated Learning with Advanced Learning Technologies: Issues and Challenges",
journal = "Computers in Human Behavior",
volume = "96",
pages = "207 - 210",
year = "2019",
issn = "0747-5632",
doi = "https://doi.org/10.1016/j.chb.2019.03.025",
url = "http://www.sciencedirect.com/science/article/pii/S0747563219301177",
author = "Roger Azevedo and Dragan Gašević",
abstract = "Analyzing multimodal multichannel data about self-regulated learning (SRL) obtained during the use of advanced learning technologies such as intelligent tutoring systems, serious games, hypermedia, and immersive virtual learning environments is key to understanding the interplay among cognitive, affective, metacognitive, and social processes and their impact on learning, problem solving, reasoning, and conceptual understanding in learners of all ages and contexts. In this special issue of Computers in Human Behavior, we report six studies conducted by interdisciplinary teams’ use of various trace methodologies such as eye tracking, log-files, physiological data, facial expressions of emotions, screen recordings, concurrent think-alouds, and linguistic analyses of discourse. The research studies focus on how these data were analyzed using a combination of traditional statistical techniques as well as educational data-mining procedures to detect, measure, and infer cognitive, metacognitive, and social processes related to regulating the self and others across several tasks, domains, ages, and contexts. The results of these studies point to future work necessitating interdisciplinary researchers’ collaboration to use theoretically based and empirically derived approaches to collecting, measuring, and modeling multimodal multichannel SRL data to extend our current models, frameworks, and theories by making them more predictive by elucidating the nature, complexity, and temporality of underlying processes. Lastly, analyses of multimodal multichannel SRL process data can significantly augment advanced learning technologies by providing real-time, intelligent, adaptive, individualized scaffolding and feedback to address learners’ self-regulatory needs."
}
@article{PERUZZINI2020105600,
title = "Exploring the potential of Operator 4.0 interface and monitoring",
journal = "Computers & Industrial Engineering",
volume = "139",
pages = "105600",
year = "2020",
issn = "0360-8352",
doi = "https://doi.org/10.1016/j.cie.2018.12.047",
url = "http://www.sciencedirect.com/science/article/pii/S036083521830651X",
author = "Margherita Peruzzini and Fabio Grandi and Marcello Pellicciari",
keywords = "Human factors, Operator 4.0, Digitization, Industry 4.0, Mixed reality",
abstract = "In the context of smart factories, where intelligent machines share data and support enhanced functionalities at a factory level, workers are still seen as spectators rather than active players (Hermann, Pentek, & Otto, 2017). Instead, Industry 4.0 represents a great opportunity for workers to become part of the intelligent system; on one hand, operators can generate data to program machines and optimize the process flows, on the other hand they can receive useful information to support their work and cooperate with smart systems (Romero et al., 2016). Diversely from machines, humans are naturally smart, flexible and intelligent, so putting the operators in the digital loop can bring more powerful and efficient factories. The paper aims at defining a theoretical human-centered framework for Operator 4.0, and testing its feasibility and impact on companies, thanks to the integration of human factors in 4.0 computerized industrial contexts. The proposed framework is based on data collection about the workers’ performance, actions and reactions, with the final objective to improve the overall factory performance and organization. Data are used to assess the workers’ ergonomics performance and perceived comfort and to build a proper knowledge about the human asset of the factory, to be integrated with the knowledge derived from machine data collection. The framework is cased on the adoption of an Operator 4.0 monitoring system, which consists of an eye tracking and a wearable biosensor, combined to a proper protocol analysis to interpret data and create a solid knowledge. Virtual prototypes are used to make the workers interact with the digital factory to conveniently simulate the human–machine interaction (HMI) in order to avoid bottlenecks at the shop floor, to optimize the workflows, and to improve the workstations’ design and layout. The study represents a step toward the design of human-centred industrial systems, including human factors in the digital twin. The research approach has been successfully tested on an industrial case study, developed in collaboration with CNH Industrial, for the re-design of assembly workstations."
}
@article{BALCOMBE2017238,
title = "Examining the relationship between visual attention and stated preferences: A discrete choice experiment using eye-tracking",
journal = "Journal of Economic Behavior & Organization",
volume = "144",
pages = "238 - 257",
year = "2017",
issn = "0167-2681",
doi = "https://doi.org/10.1016/j.jebo.2017.09.023",
url = "http://www.sciencedirect.com/science/article/pii/S0167268117302718",
author = "Kelvin Balcombe and Iain Fraser and Louis Williams and Eugene McSorley",
keywords = "Discrete choice experiment, Eye-tracking, Bayesian infinite-mixtures Logit",
abstract = "We examine the relationship between visual attention and stated preferences derived from a discrete choice experiment. Focussing on consumer preferences regarding country of origin food labels, we employ a Bayesian infinite mixture Logit to derive results that reveal patterns of respondent heterogeneity that would not be captured assuming that random parameters take a specific distributional form. Our results reveal weak relationships between the eye-tracking data, our stated preference results and various attribute use questions. Although respondents with higher levels of visual attendance value specific attributes more highly, the strength of the relationship is fairly weak. Therefore, whilst we maintain that eye-tracking is useful, we argue that there needs to be greater clarity about the aims and purpose of using eye-tracking in stated preference research."
}
@article{CHERNYSHOV2019475,
title = "Non-Parametric Procedures in Evaluation of Collective Professional Skills of a Human-Operators Shift",
journal = "IFAC-PapersOnLine",
volume = "52",
number = "13",
pages = "475 - 480",
year = "2019",
note = "9th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2019",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2019.11.107",
url = "http://www.sciencedirect.com/science/article/pii/S2405896319310547",
author = "K.R. Chernyshov",
keywords = "collective skills, knowledge, human-operator shift, input/output model, kernel regression estimation, strongly consistent estimate, system identification",
abstract = "The paper is devoted to a methodology oriented to eliciting professional skills of a shift of human-operators of a technological plant by applying system identification techniques. Within the frameworks, the aim is to derive an input/output model that might reflect the actual level of collective professional competences and skills. Deriving the required input/output model is based on applying such a kind of the “proxy”, that is indirect, variables as the time. Namely, there is applied the time that is needed to the shift of human-operators to make a decision on the plant process behavior using the information provided by information sources distributed over an information-and-control board, such as, say, group view displays (GVD) or, generically, within a total control room. In turn, these times are proposed to be fixed by use of eye trackers. Obtained in such a manner and calculated by use of data of observation of actual algorithm of collective performance of an experienced human-operator shift, the model characteristics represent a tool for evaluation of human-operators shift experience."
}
@article{KIM201528,
title = "Context-driven expectations about focus alternatives",
journal = "Cognition",
volume = "139",
pages = "28 - 49",
year = "2015",
issn = "0010-0277",
doi = "https://doi.org/10.1016/j.cognition.2015.02.009",
url = "http://www.sciencedirect.com/science/article/pii/S0010027715000402",
author = "Christina S. Kim and Christine Gunlogson and Michael K. Tanenhaus and Jeffrey T. Runner",
keywords = "Focus, Discourse processing, Visual world eye-tracking, Alternatives, Context dependence, Domain restriction",
abstract = "What is conveyed by a sentence frequently depends not only on the descriptive content carried by its words, but also on implicit alternatives determined by the context of use. Four visual world eye-tracking experiments examined how alternatives are generated based on aspects of the discourse context and used in interpreting sentences containing the focus operators only and also. Experiment 1 builds on previous reading time studies showing that the interpretations of only sentences are constrained by alternatives explicitly mentioned in the preceding discourse, providing fine-grained time course information about the expectations triggered by only. Experiments 2 and 3 show that, in the absence of explicitly mentioned alternatives, lexical and situation-based categories evoked by the context are possible sources of alternatives. While Experiments 1–3 all demonstrate the discourse dependence of alternatives, only explicit mention triggered expectations about alternatives that were specific to sentences with only. By comparing only with also, Experiment 4 begins to disentangle expectations linked to the meanings of specific operators from those generalizable to the class of focus-sensitive operators. Together, these findings show that the interpretation of sentences with focus operators draws on both dedicated mechanisms for introducing alternatives into the discourse context and general mechanisms associated with discourse processing."
}
@incollection{VANGOMPEL2000621,
title = "Chapter 24 - Unrestricted Race: A New Model of Syntactic Ambiguity Resolution",
editor = "Alan Kennedy and Ralph Radach and Dieter Heller and Joël Pynte",
booktitle = "Reading as a Perceptual Process",
publisher = "North-Holland",
address = "Oxford",
pages = "621 - 648",
year = "2000",
isbn = "978-0-08-043642-5",
doi = "https://doi.org/10.1016/B978-008043642-5/50029-2",
url = "http://www.sciencedirect.com/science/article/pii/B9780080436425500292",
author = "Roger P.G. van Gompel and Martin J. Pickering and Matthew J. Traxler",
abstract = "In this chapter, we focus on a previously ignored aspect of sentence processing theories: is processing difficulty caused by reanalysis or competition? According to two-stage theories (e.g., Frazier, 1979, Rayner et al., 1983), reanalysis should occur when an initially adopted reading is inappropriate. In contrast, current constraint-based theories (e.g., MacDonald, 1994, McRae et al., 1998) claim that processing difficulty is due to a competition between two or more syntactic analyses that are about equally activated. We review a number of eye-tracking experiments investigating this issue. No competition was observed in any of the experiments, thus ruling out current constraint-based theories. In fact, the opposite pattern emerged: sentences that should have produced processing difficulty according to constraint-based theories were actually easier to process than sentences that should not have produced difficulty. The data also turn out to be problematic for two-stage theories, as non-syntactic information appears to be employed before the point of reanalysis. The data provide evidence for a new model of syntactic ambiguity resolution (cf. Traxler et al., 1998, Van Gompel et al., 1999), the unrestricted race model. In this model, processing difficulty is due to reanalysis, but multiple sources of information can determine which analysis is initially adopted."
}
@article{DUECKER2019107250,
title = "No effect of cold pressor test-induced arousal on attentional benefits and costs in an endogenous spatial orienting paradigm",
journal = "Neuropsychologia",
volume = "135",
pages = "107250",
year = "2019",
issn = "0028-3932",
doi = "https://doi.org/10.1016/j.neuropsychologia.2019.107250",
url = "http://www.sciencedirect.com/science/article/pii/S0028393219302945",
author = "Felix Duecker and Helen C. Mayrhofer and Heidi I.L. Jacobs and Alexander T. Sack",
keywords = "Arousal, Cold pressor test, Visuospatial attention, Hemispatial bias, Replication",
abstract = "Previous studies have shown that arousal can influence hemispatial bias, suggesting that changes in arousal affect the neural networks involved in spatial attention control. The goal of the present study was to measure the effects of increased arousal on endogenous attentional orienting. We used a Spatial Orienting Paradigm to quantify attentional benefits and costs as measures of attentional orienting and re-orienting responses and exposed participants (N = 25; Experiment 1) to a bilateral feet Cold Pressor Test (CPT) to manipulate arousal. Increases in subjective distress ratings and blood pressure confirmed the effect of CPT on arousal. Although no overall effects of CPT on reaction times in the Spatial Orienting Paradigm were detected, an exploratory analysis of sex-specific effects revealed a left-lateralised decrease in benefits and increase in costs after CPT exposure in the male subsample (N = 11). To confirm these preliminary results, we repeated the experiment in a larger sample (N = 29, all male), but found no effect of CPT on orienting, with moderate to strong evidence in favour of a model excluding all (interaction) effects of CPT exposure (all BFIncl < 0.3). Instead, our replicated results indicate that voluntary orienting is unaffected by CPT-induced increases of arousal. In the light of previous studies, and keeping in mind the interpretative challenges of null results, we discuss how and why our findings may be specific to endogenous as opposed to exogenous orienting and how arousal could possibly lead to the previously established effects on visuospatial bias without simultaneously affecting orienting and the underlying attention control networks."
}
@article{HORREY2017342,
title = "Distraction and task engagement: How interesting and boring information impact driving performance and subjective and physiological responses",
journal = "Applied Ergonomics",
volume = "58",
pages = "342 - 348",
year = "2017",
issn = "0003-6870",
doi = "https://doi.org/10.1016/j.apergo.2016.07.011",
url = "http://www.sciencedirect.com/science/article/pii/S0003687016301429",
author = "William J. Horrey and Mary F. Lesch and Angela Garabet and Lucinda Simmons and Rammohan Maikala",
keywords = "Driver distraction, Task engagement/interest, Cerebral blood oxygenation, Heart rate, Pupillometry, Driving performance",
abstract = "As more devices and services are integrated into vehicles, drivers face new opportunities to perform additional tasks while driving. While many studies have explored the detrimental effects of varying task demands on driving performance, there has been little attention devoted to tasks that vary in terms of personal interest or investment—a quality we liken to the concept of task engagement. The purpose of this study was to explore the impact of task engagement on driving performance, subjective appraisals of performance and workload, and various physiological measurements. In this study, 31 participants (M = 37 yrs) completed three driving conditions in a driving simulator: listening to boring auditory material; listening to interesting material; and driving with no auditory material. Drivers were simultaneously monitored using near-infrared spectroscopy, heart monitoring and eye tracking systems. Drivers exhibited less variability in lane keeping and headway maintenance for both auditory conditions; however, response times to critical braking events were longer in the interesting audio condition. Drivers also perceived the interesting material to be less demanding and less complex, although the material was objectively matched for difficulty. Drivers showed a reduced concentration of cerebral oxygenated hemoglobin when listening to interesting material, compared to baseline and boring conditions, yet they exhibited superior recognition for this material. The practical implications, from a safety standpoint, are discussed."
}
@article{CARUANA201534,
title = "A frontotemporoparietal network common to initiating and responding to joint attention bids",
journal = "NeuroImage",
volume = "108",
pages = "34 - 46",
year = "2015",
issn = "1053-8119",
doi = "https://doi.org/10.1016/j.neuroimage.2014.12.041",
url = "http://www.sciencedirect.com/science/article/pii/S1053811914010337",
author = "Nathan Caruana and Jon Brock and Alexandra Woolgar",
keywords = "Joint attention, fMRI, Eye tracking, Virtual reality, Social cognition, Interaction",
abstract = "Joint attention is a fundamental cognitive ability that supports daily interpersonal relationships and communication. The Parallel Distributed Processing model (PDPM) postulates that responding to (RJA) and initiating (IJA) joint attention are predominantly supported by posterior-parietal and frontal regions respectively. It also argues that these neural networks integrate during development, supporting the parallel processes of self- and other-attention representation during interactions. However, direct evidence for the PDPM is limited due to a lack of ecologically valid experimental paradigms that can capture both RJA and IJA. Building on existing interactive approaches, we developed a virtual reality paradigm where participants engaged in an online interaction to complete a cooperative task. By including tightly controlled baseline conditions to remove activity associated with non-social task demands, we were able to directly contrast the neural correlates of RJA and IJA to determine whether these processes are supported by common brain regions. Both RJA and IJA activated broad frontotemporoparietal networks. Critically, a conjunction analysis identified that a subset of these regions were common to both RJA and IJA. This right-lateralised network included the dorsal portion of the middle frontal gyrus (MFG), inferior frontal gyrus (IFG), middle temporal gyrus (MTG), precentral gyrus, posterior superior temporal sulcus (pSTS), temporoparietal junction (TPJ) and precuneus. Additional activation was observed in this network for IJA relative to RJA at MFG, IFG, TPJ and precuneus. This is the first imaging study to directly investigate the neural correlates common to RJA and IJA engagement, and thus support the assumption that a broad integrated network underlies the parallel aspects of both initiating and responding to joint attention."
}
@article{SOUSSIGNAN2015173,
title = "Emotional communication in the context of joint attention for food stimuli: Effects on attentional and affective processing",
journal = "Biological Psychology",
volume = "104",
pages = "173 - 183",
year = "2015",
issn = "0301-0511",
doi = "https://doi.org/10.1016/j.biopsycho.2014.12.006",
url = "http://www.sciencedirect.com/science/article/pii/S0301051114002634",
author = "Robert Soussignan and Benoist Schaal and Véronique Boulanger and Samuel Garcia and Tao Jiang",
keywords = "Emotion, Communication, Facial expressions, Food, Gaze direction, Joint attention",
abstract = "Guided by distinct theoretical frameworks (the embodiment theories, shared-signal hypothesis, and appraisal theories), we examined the effects of gaze direction and emotional expressions (joy, disgust, and neutral) of virtual characters on attention orienting and affective reactivity of participants while they were engaged in joint attention for food stimuli contrasted by preference (disliked, moderately liked, and liked). The participants were exposed to videos of avatars looking at food and displaying facial expressions with their gaze directed either toward the food only or toward the food and participants consecutively. We recorded eye-tracking responses, heart rate, facial electromyography (zygomatic, corrugator, and levator labii regions), and food wanting/liking. The avatars’ joy faces increased the participants’ zygomatic reactions and food liking, with mutual eye contact boosting attentional responses. Eye contact also fostered disgust reactions to disliked food, regardless of the avatars’ expressions. The findings show that joint attention for food accompanied by face-to-face emotional communication elicits differential attentional and affective responses. The findings appear consistent with the appraisal theories of emotion."
}
@incollection{SCHOTTER2018263,
title = "Chapter Nine - Reading Ahead by Hedging Our Bets on Seeing the Future: Eye Tracking and Electrophysiology Evidence for Parafoveal Lexical Processing and Saccadic Control by Partial Word Recognition",
editor = "Kara D. Federmeier and Duane G. Watson",
series = "Psychology of Learning and Motivation",
publisher = "Academic Press",
volume = "68",
pages = "263 - 298",
year = "2018",
booktitle = "Current Topics in Language",
issn = "0079-7421",
doi = "https://doi.org/10.1016/bs.plm.2018.08.011",
url = "http://www.sciencedirect.com/science/article/pii/S0079742118300112",
author = "Elizabeth R. Schotter",
keywords = "Reading, Parafoveal processing, Eye movements, ERPs",
abstract = "How can cognition influence reading speed (i.e., the timing of saccades–eye fixations) when language processing (i.e., word recognition) seems so much slower? This paper suggests that the answer to this question requires two assumptions: (1) the triggering of saccades is based on partial, rather than complete, word recognition and (2) readers preview words in parafoveal vision prior to fixating them, allowing for a head-start on linguistic processing. I propose a novel theoretical framework about the use of parafoveal preview in reading (i.e., a hybrid account of forced fixations and trans-saccadic integration) and provide evidence for that framework from eye tracking studies, electrophysiology studies, and computational models."
}
@article{DALLAVIA201979,
title = "How accountability type influences information search processes and decision quality",
journal = "Accounting, Organizations and Society",
volume = "75",
pages = "79 - 91",
year = "2019",
issn = "0361-3682",
doi = "https://doi.org/10.1016/j.aos.2018.10.001",
url = "http://www.sciencedirect.com/science/article/pii/S036136821830521X",
author = "Nicola Dalla Via and Paolo Perego and Marcel van Rinsum",
keywords = "Process accountability, Outcome accountability, Information search effort, Causal chain, Eye-tracking, Balanced scorecard, Decision-making",
abstract = "This study investigates how accountability type (process or outcome) and causal chain framing influence information search processes and decision-making quality. Drawing on the accountability literature and causal reasoning theory, we predict that process accountability stimulates information search effort and enhances decision quality. Additionally, we posit that causal chain usage enhances focus on relevant cues, and increases search effort and decision quality under outcome accountability. In contrast, we argue that employing a causal chain under process accountability decreases search efforts and does not spur a similar increase in decision quality. We conduct an eye-tracking experiment in which participants decide on the amount of funding for a value-creating project after observing prior balanced scorecard performance data. Our results are consistent with our expectations and reveal that accountability type and causal chain framing interact. Under outcome accountability, providing a causal chain is paramount to achieve high decision quality. When process accountability is employed, however, providing a causal chain reduces information search effort and does not improve decision-making. We discuss important implications of our findings for management accounting research and practice."
}
@article{VENKATRAMAN201473,
title = "An overall probability of winning heuristic for complex risky decisions: Choice and eye fixation evidence",
journal = "Organizational Behavior and Human Decision Processes",
volume = "125",
number = "2",
pages = "73 - 87",
year = "2014",
issn = "0749-5978",
doi = "https://doi.org/10.1016/j.obhdp.2014.06.003",
url = "http://www.sciencedirect.com/science/article/pii/S0749597814000491",
author = "Vinod Venkatraman and John W. Payne and Scott A. Huettel",
keywords = "Risky choice, Risky choice models, Eye tracking, Process measures, Strategies, Heuristics, Adaptive decision making",
abstract = "When faced with multi-outcome gambles involving possibilities of both gains and losses, people often use a simple heuristic that maximizes the overall probability of winning (Pwin). Across three different studies, using choice data as well as process data from eye tracking, we demonstrate that the Pwin heuristic is a frequently used strategy for decisions involving complex (multiple outcome) mixed gambles. Crucially, we show systematic contextual and individual differences in the use of Pwin heuristic. We discuss the implication of these findings in the context of the broader debate about single versus multiple strategies in risky choice, and the need to extend the study of risky decision making from simple to more complex gambles."
}
@article{STARK2018185,
title = "Emotional text design in multimedia learning: A mixed-methods study using eye tracking",
journal = "Computers & Education",
volume = "120",
pages = "185 - 196",
year = "2018",
issn = "0360-1315",
doi = "https://doi.org/10.1016/j.compedu.2018.02.003",
url = "http://www.sciencedirect.com/science/article/pii/S0360131518300368",
author = "Lisa Stark and Roland Brünken and Babette Park",
abstract = "The present study investigated an extension of the emotional design hypothesis in multimedia learning for textual parts of multimedia instruction. In an one-factorial experimental mixed-methods design with three groups, participants learned with multimedia instruction incorporating a positive or negative emotional text design or the original learning text. Both the positive and negative emotional text design led to better learning outcomes compared with the control group. Further, the emotional text design facilitated elaboration processes but suppressed metacognitive processes during learning. Learners’ emotional state was not affected by a positive emotional text design, but participants in the group with the negative emotional text design showed a worse emotional state after learning. Qualitative data showed that even though both emotional text designs facilitated learning, cognitive mechanisms for these effects differed between the groups. Results of the present study support the extension of the emotional design hypotheses with regard to textual parts of learning environments."
}
@article{MOELLER2009209,
title = "Eye fixation behaviour in the number bisection task: Evidence for temporal specificity",
journal = "Acta Psychologica",
volume = "131",
number = "3",
pages = "209 - 220",
year = "2009",
issn = "0001-6918",
doi = "https://doi.org/10.1016/j.actpsy.2009.05.005",
url = "http://www.sciencedirect.com/science/article/pii/S0001691809000572",
author = "K. Moeller and M.H. Fischer and H.-C. Nuerk and K. Willmes",
keywords = "Number processing, Eye tracking, Parity, Multiplication facts, Number bisection task",
abstract = "Together with magnitude representations, knowledge about multiplicativity and parity contributes to numerical problem solving. In the present study, we used eye tracking to document how and when multiplicativity and parity are recruited in the number bisection task. Fourteen healthy adults evaluated whether the central number of a triplet (e.g., 21_24_27) corresponds to the arithmetic integer mean of the interval defined by the two outer numbers. We observed multiplicativity to specifically affect gaze duration on numbers, indicating that the information of multiplicative relatedness is activated at early processing stages. In contrast, parity only affected total reading time, suggesting involvement in later processing stages. We conclude that different representational features of numbers are available and integrated at different processing stages within the same task and outline a processing model for these temporal dynamics of numerical cognition."
}
@article{ZUSCHKE2019,
title = "An analysis of process-tracing research on consumer decision-making",
journal = "Journal of Business Research",
year = "2019",
issn = "0148-2963",
doi = "https://doi.org/10.1016/j.jbusres.2019.01.028",
url = "http://www.sciencedirect.com/science/article/pii/S0148296319300281",
author = "Nick Zuschke",
keywords = "Consumer decision-making, Process-tracing, Bibliometric analysis, Eye tracking, Consumer neuroscience, Verbal protocol",
abstract = "Eye tracking has been used for decades to provide insight into the cognitive processes that underlie consumers' decision-making. Since there is a wide variety of tools, ranging from information display boards to functional magnetic resonance imaging, that can be used to better understand these processes, eye tracking should not be viewed in isolation. In order to understand the roots, current developments, and future research avenues of eye-tracking research, it is necessary to focus on process-tracing research on consumer decision-making. This paper addresses this issue by quantitatively analyzing 347 articles, along with their 17,798 cited references, by means of factor and social network analysis. Six distinct, but to varying extents interconnected, key research streams dominate the field's research agenda. Revealing the emergence and growth of these research streams shows how their prevalence has changed over time. Several conclusions, based on the results, are drawn and used to indicate possible future research."
}
@article{RATIU201729,
title = "Language control in bilingual adults with and without history of mild traumatic brain injury",
journal = "Brain and Language",
volume = "166",
pages = "29 - 39",
year = "2017",
issn = "0093-934X",
doi = "https://doi.org/10.1016/j.bandl.2016.12.004",
url = "http://www.sciencedirect.com/science/article/pii/S0093934X16301110",
author = "Ileana Ratiu and Tamiko Azuma",
keywords = "Traumatic brain injury, Bilingualism, Executive function, Language control",
abstract = "Adults with a history of traumatic brain injury often show deficits in executive functioning (EF), including the ability to inhibit, switch, and attend to tasks. These abilities are critical for language processing in bilinguals. This study examined the effect of mild traumatic brain injury (mTBI) on EF and language processing in bilinguals using behavioral and eye-tracking measures. Twenty-two bilinguals with a history of mTBI and twenty healthy control bilinguals were administered executive function and language processing tasks. Bilinguals with a history of mTBI showed deficits in specific EFs and had higher rates of language processing errors than healthy control bilinguals. Additionally, individuals with a history of mTBI have different patterns of eye movements during reading than healthy control bilinguals. These data suggest that language processing deficits are related to underlying EF abilities. The findings provide important information regarding specific EF and language control deficits in bilinguals with a history mTBI."
}
@article{BURATTIN20191,
title = "Learning process modeling phases from modeling interactions and eye tracking data",
journal = "Data & Knowledge Engineering",
volume = "121",
pages = "1 - 17",
year = "2019",
issn = "0169-023X",
doi = "https://doi.org/10.1016/j.datak.2019.04.001",
url = "http://www.sciencedirect.com/science/article/pii/S0169023X17303282",
author = "Andrea Burattin and Michael Kaiser and Manuel Neurauter and Barbara Weber",
keywords = "Process of process modeling, Eye tracking, Interaction tracking, Automatic phase detection, Classification, Sequence labeling",
abstract = "The creation of a process model is a process consisting of five distinct phases, i.e., problem understanding, method finding, modeling, reconciliation, and validation. To enable a fine-grained analysis of process model creation based on phases or the development of phase-specific modeling support, an automatic approach to detect phases is needed. While approaches exist to automatically detect modeling and reconciliation phases based on user interactions, the detection of phases without user interactions (i.e., problem understanding, method finding, and validation) is still a problem. Exploiting a combination of user interactions and eye tracking data, this paper presents a two-step approach that is able to automatically detect the sequence of phases a modeler is engaged in during model creation. The evaluation of our approach shows promising results both in terms of quality as well as computation time demonstrating its feasibility."
}
@article{VANREIJMERSDAL202094,
title = "Effects of Disclosing Influencer Marketing in Videos: An Eye Tracking Study Among Children in Early Adolescence",
journal = "Journal of Interactive Marketing",
volume = "49",
pages = "94 - 106",
year = "2020",
issn = "1094-9968",
doi = "https://doi.org/10.1016/j.intmar.2019.09.001",
url = "http://www.sciencedirect.com/science/article/pii/S1094996819300957",
author = "Eva A. van Reijmersdal and Esther Rozendaal and Liselot Hudders and Ini Vanwesenbeeck and Veroline Cauberghe and Zeph M.C. van Berlo",
keywords = "Disclosure, Sponsored content, Brand placement, Native advertising, Vlogs, Early adolescents, Children, Eye tracking",
abstract = "This study focused on the effects of sponsorship disclosure timing on children's ability to understand that social influencer videos are sponsored. The study also investigated how sponsorship disclosure timing affects children's attitudes toward the sponsoring brand, the video, and the influencer. An experiment among 272 children in early adolescence (10–13 years of age) was conducted using eye tracking. Results show that a disclosure shown prior to the start of the videos leads to more visual attention than a disclosure shown concurrently with the start of videos. Consequently, disclosure prior to the start of videos is better processed, as indicated by disclosure memory, which then leads to a better understanding that the content is sponsored. This understanding evokes a more critical attitude toward the sponsored content in the video, and results in less positive attitudes toward the brands, the videos, and the influencers. Theoretically, this study provides insights into the mechanisms that explain disclosure timing effects among children in early adolescence. Practically, this study offers recommendations to policy makers to develop sponsorship disclosures that can increase transparency of online embedded advertising to minors."
}
@article{LOUWERSE20131043,
title = "Effects of eye gaze directions of facial images on looking behaviour and autonomic responses in adolescents with autism spectrum disorders",
journal = "Research in Autism Spectrum Disorders",
volume = "7",
number = "9",
pages = "1043 - 1053",
year = "2013",
issn = "1750-9467",
doi = "https://doi.org/10.1016/j.rasd.2013.04.013",
url = "http://www.sciencedirect.com/science/article/pii/S1750946713000846",
author = "A. Louwerse and J.N. van der Geest and J.H.M. Tulen and J. van der Ende and A.R. Van Gool and F.C. Verhulst and K. Greaves-Lord",
keywords = "Autism spectrum disorders, Eyes, Gaze direction, Eye-tracking, Heart rate, Skin conductance response",
abstract = "It has been suggested that atypical eye contact of individuals with autism spectrum disorders (ASDs) arises from an unusually high level of autonomic activity elicited by another person's gaze. The present study investigated visual fixation duration and autonomic reactivity (heart rate, skin conductance response) simultaneously, while adolescents looked towards photographs of neutral faces, with either direct eye gaze, averted eye gaze or closed eyes. Both cognitively able adolescents with ASD (n=31, mean age=16 years, mean IQ=104) and typically developing (TD) adolescents (n=34, mean age=16 years, mean IQ=108) looked significantly longer towards the eye region of faces with direct eye gaze compared with faces with averted eye gaze or closed eyes. The adolescents with ASD did not show higher levels of autonomic activity than TD adolescents while they were instructed to look at the eye region. This suggests that looking at the eye region of static faces does not particularly trigger high autonomic arousal in adolescents with ASD."
}
@incollection{BEESLEY20191,
title = "Chapter 1 - Eye Tracking as a Tool for Examining Cognitive Processes",
editor = "Gigi Foster",
booktitle = "Biophysical Measurement in Experimental Social Science Research",
publisher = "Academic Press",
pages = "1 - 30",
year = "2019",
isbn = "978-0-12-813092-6",
doi = "https://doi.org/10.1016/B978-0-12-813092-6.00002-2",
url = "http://www.sciencedirect.com/science/article/pii/B9780128130926000022",
author = "Tom Beesley and Daniel Pearson and Mike Le Pelley",
keywords = "Eye tracking, Eye movements, Attention, Experimental psychology",
abstract = "Eye tracking tools are now commonplace in the laboratories of experimental psychologists. Recording the position of a person's gaze, often several hundred times per second, can provide rich and precise data on the mechanisms and time course of cognitive processing. This approach has transformed cognitive psychology from the fields of language processing and reading, to categorization, cognitive development, and many more. In this chapter we discuss briefly the history of eye tracking research, when the technology is likely to benefit researchers, and the types of advantages it offers over traditional behavioral measures. We then present a selective review of areas of behavioral research in which eye tracking has had a significant impact, before providing a more detailed discussion of its use within the field of associative learning and attention."
}
@article{LINDSTROM2016517,
title = "Does the presence of a mannequin head change shopping behavior?",
journal = "Journal of Business Research",
volume = "69",
number = "2",
pages = "517 - 524",
year = "2016",
issn = "0148-2963",
doi = "https://doi.org/10.1016/j.jbusres.2015.04.011",
url = "http://www.sciencedirect.com/science/article/pii/S014829631500209X",
author = "Annika Lindström and Hanna Berg and Jens Nordfält and Anne L. Roggeveen and Dhruv Grewal",
keywords = "Retail atmospherics, Mannequin, Retail displays, In-store displays",
abstract = "Mannequins are ubiquitous; this research investigates a specific element of mannequin style, namely, the presence or absence of a humanized head. Study 1 demonstrates that in physical stores, the presence of a humanized head enhances purchase intentions for the merchandise displayed on that mannequin. However, in online stores, mannequin styles with and without humanized heads are equally effective. Study 2 confirms the physical store results among customers with less fashion knowledge (novices), but among customers with more fashion knowledge (experts), the results reverse, such that mannequins without humanized heads enhance purchase intentions. Further, accessories are more likely to be viewed by experts when the mannequin is headless. These results are based on experiments whose dependent measures included both survey and eye-tracking data."
}
@article{TITONE19991655,
title = "On the compositional and noncompositional nature of idiomatic expressions",
journal = "Journal of Pragmatics",
volume = "31",
number = "12",
pages = "1655 - 1674",
year = "1999",
note = "Literal and Figurative Language",
issn = "0378-2166",
doi = "https://doi.org/10.1016/S0378-2166(99)00008-9",
url = "http://www.sciencedirect.com/science/article/pii/S0378216699000089",
author = "Debra A. Titone and Cynthia M. Connine",
keywords = "Idiom processing, Compositionality, Eye movement recording, Semantic priming",
abstract = "The present paper reviews linguistic and psycholinguistic perspectives on idiom representation and models of idiom processing. Two approaches in defining idiom representation and processing characteristics are compared. According to the ‘noncompositional approach’, idioms are represented and processed similar to long words. In contrast, the ‘compositional approach’ emphasizes the semantic contribution of an idiom's component word meanings in interpretation. We argue that neither approach alone adequately captures the existing body of data on idiom processing, and propose a model of idiom representation and processing that ascribes noncompositional and compositional characteristics to idiomatic expressions. In this view, idiomatic expressions function simultaneously as semantically arbitrary word sequences and compositional phrases. Consistent with this hybrid model, the results of an eye tracking study are presented in which reading rates differ as a function of the inherent decomposability of idioms."
}
@article{LOWE201672,
title = "Principled animation design improves comprehension of complex dynamics",
journal = "Learning and Instruction",
volume = "45",
pages = "72 - 84",
year = "2016",
issn = "0959-4752",
doi = "https://doi.org/10.1016/j.learninstruc.2016.06.005",
url = "http://www.sciencedirect.com/science/article/pii/S0959475216300627",
author = "Richard K. Lowe and Jean-Michel Boucheix",
keywords = "Animation design, Complexity, Animation processing model, Mental model acquisition, Composition approach",
abstract = "Learners can have difficulty in decomposing conventionally designed animations to obtain raw material suitable for building high quality mental models. A composition approach to designing animations based on the Animation Processing Model was developed as a principled alternative to prevailing approaches. Outcomes from studying novel and conventional animation designs (independent variable) were compared with respect to mental model quality, knowledge of local kinematics, and capacity to transfer (dependent variables). Study of a compositional animation that presented material in a contiguous fashion resulted in higher quality mental models of a piano mechanism than non-contiguous or control (conventional) versions but no significant differences regarding local kinematics or transfer. Eye fixation data indicated that the compositional animation led to superior mental models because it particularly fostered relational processing. Implications for future research and the design of educational animations are discussed."
}
@article{MOLINA201454,
title = "Evaluating a graphical notation for modeling collaborative learning activities: A family of experiments",
journal = "Science of Computer Programming",
volume = "88",
pages = "54 - 81",
year = "2014",
note = "Software Development Concerns in the e-Learning Domain",
issn = "0167-6423",
doi = "https://doi.org/10.1016/j.scico.2014.02.019",
url = "http://www.sciencedirect.com/science/article/pii/S0167642314000860",
author = "Ana I. Molina and Miguel A. Redondo and Manuel Ortega and Carmen Lacave",
keywords = "Educational modeling, CSCL, Notation assessments, Empirical study, ",
abstract = "It is increasingly common to use languages and notations, mainly of a graphical nature, to assist in the design and specification of learning systems. There are several proposals, although few of them support the modeling of collaborative tasks. In this paper, we identify the main features to be considered for modeling this kind of activities and we propose the use of the CIAN notation for this purpose. In this work, we also try to empirically analyze the quality (in particular the understandability) of that notation. To this end, three empirical studies have been conducted. In these experiments we used several sources of information: subjective perception of the designers, their profiles and their performance on a set of understandability exercises, as well as the physical evidence provided by an eye tracker device. The results obtained denote positive perceptions about the use of the CIAN notation for modeling collaborative learning activities."
}
@article{LAFONT2018141,
title = "Driver’s emotional state and detection of vulnerable road users: Towards a better understanding of how emotions affect drivers’ perception using cardiac and ocular metrics",
journal = "Transportation Research Part F: Traffic Psychology and Behaviour",
volume = "55",
pages = "141 - 152",
year = "2018",
issn = "1369-8478",
doi = "https://doi.org/10.1016/j.trf.2018.02.032",
url = "http://www.sciencedirect.com/science/article/pii/S1369847817306794",
author = "Alex Lafont and Joceline Rogé and Daniel Ndiaye and Jean-Michel Boucheix",
keywords = "Anger, Vulnerable road users, Driving simulation, Autonomic nervous system, Heart rate variability, Eye-tracking",
abstract = "Traditionally, anger has been considered to have a detrimental effect on driving. However, recent studies suggest that this statement should be qualified, especially where vulnerable road user detection is concerned. One primary factor which may determine anger’s effect on a driver’s attention is its intensity. In the present study, different intensities of anger were elicited via film clips, then performances in vulnerable road user detection (i.e., of cyclists) were assessed while participants drove a car in a simulated environment. Cardiac and ocular measurements and self-reported data were used in order to accurately assess emotional state and attention management throughout the experiment. Results suggested that participants resorted to reappraisal strategies when they were exposed to the emotional film clips. This phenomenon did not directly affect cyclist detection performances, but evidence of different visual scanning strategies between groups emerged. The contribution of cardiac and ocular measurements to emotional assessment and the advantages of appraisal approaches of emotion were also discussed."
}
@incollection{VANGOMPEL20071,
title = "Chapter 1 - Eye-movement research: An overview of current and past developments",
editor = "Roger P.G. Van Gompel and Martin H. Fischer and Wayne S. Murray and Robin L. Hill",
booktitle = "Eye Movements",
publisher = "Elsevier",
address = "Oxford",
pages = "1 - 28",
year = "2007",
isbn = "978-0-08-044980-7",
doi = "https://doi.org/10.1016/B978-008044980-7/50003-3",
url = "http://www.sciencedirect.com/science/article/pii/B9780080449807500033",
author = "Roger P.G. Van Gompel and Martin H. Fischer and Wayne S. Murray and Robin L. Hill",
abstract = "Publisher Summary
This chapter discusses some of the issues that reflect the wide diversity of eye-movement research. It provides an up-to-date impression of the most significant developments in the area, based on findings from a survey of eye-movement researchers and database searches. Recent developments include the history of eye-movement research, eye movements as a method for investigating spoken language processing, and eye movements in natural environments. The modeling of eye movements has also seen a great deal of recent change and development. Areas that have been longer established but continue to produce important new findings are physiology and clinical studies of eye movements, transsaccadic integration, eye-movements and reading, and eye movements as a method for investigating attention and scene perception. The most important developments in eye-movement research have been highlighted. The chapter considers the state of eye-movement research by reporting results from a survey sent to participants of The 12th European Conference on Eye Movements (ECEM12) and a journal database search. The chapter describes computational modeling, new eye-tracking technologies, and anatomical and physiological mapping of the visual-oculomotor system as the most important recent developments."
}
@article{KAZANINA2007384,
title = "The effect of syntactic constraints on the processing of backwards anaphora",
journal = "Journal of Memory and Language",
volume = "56",
number = "3",
pages = "384 - 409",
year = "2007",
issn = "0749-596X",
doi = "https://doi.org/10.1016/j.jml.2006.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S0749596X06001379",
author = "Nina Kazanina and Ellen F. Lau and Moti Lieberman and Masaya Yoshida and Colin Phillips",
keywords = "Parsing, Coreference, Binding, Cataphora, Grammatical constraints, Pronouns",
abstract = "This article presents three studies that investigate when syntactic constraints become available during the processing of long-distance backwards pronominal dependencies (backwards anaphora or cataphora). Earlier work demonstrated that in such structures the parser initiates an active search for an antecedent for a pronoun, leading to gender mismatch effects in cases where a noun phrase in a potential antecedent position mismatches the gender of the pronoun [Van Gompel, R. P. G. & Liversedge, S. P. (2003). The influence of morphological information on cataphoric pronoun assignment. Journal of Experimental Psychology: Learning, Memory, and Cognition, 29, 128–139]. Results from three self-paced reading studies suggest that structural constraints on coreference, in particular Principle C of the Binding Theory [Chomsky, N. (1981). Lectures on government and binding. Dordrecht, Foris], exert an influence at an early stage of this search process, such that gender mismatch effects are elicited at grammatically licit antecedent positions, but not at grammatically illicit antecedent positions. The results also show that the distribution of gender mismatch effects is unlikely to be due to differences in the predictability of different potential antecedents. These findings suggest that backwards anaphora dependencies are processed with a grammatically constrained active search mechanism, similar to the mechanism used to process another type of long-distance dependency, the wh dependency (e.g., [Stowe, L. (1986). Evidence for online gap creation. Language and Cognitive Processes, 1, 227–245; Traxler, M. J., & Pickering, M. J. (1996). Plausibility and the processing of unbounded dependencies: an eye-tracking study. Journal of Memory and Language, 35, 454–475.]). We suggest that the temporal priority for syntactic information observed here reflects the predictability of structural information, rather than the need for an architectural constraint that delays the use of non-syntactic information."
}
@article{FERGUSON2019,
title = "Use of celebrity and non-celebrity persons in B2B advertisements: Effects on attention, recall, and hedonic and utilitarian attitudes",
journal = "Industrial Marketing Management",
year = "2019",
issn = "0019-8501",
doi = "https://doi.org/10.1016/j.indmarman.2019.02.003",
url = "http://www.sciencedirect.com/science/article/pii/S0019850118301871",
author = "Jodie L. Ferguson and Mayoor Mohan",
keywords = "B2B, Advertising, Celebrity, Eye-tracking, Attitudes",
abstract = "Images of people are often featured in business-to-business print advertisements. In some cases, person images in B2B ads may be perceived as having little or no pragmatic purpose in promoting the brand or product. The current research examines the effects of the presence of a celebrity or non-celebrity person in a B2B print ad on attention to the ad, hedonic and utilitarian attitudes towards the ad, and on aided brand recall. An eye-tracking study featured three experimental B2B ad conditions (i.e., no person, non-celebrity person, and celebrity person) conducted with business managers. The findings of this study suggest that while the presence of a celebrity endorser causes managers to pay more attention to the ad, the increase in time focusing on the advertisement brings about more negative hedonic attitudes towards the ad. Further, a celebrity endorser can reduce utilitarian attitudes towards the ad. An ad featuring a non-celebrity produced the highest brand recall."
}
@article{WIEBE2009667,
title = "Haptic feedback and students’ learning about levers: Unraveling the effect of simulated touch",
journal = "Computers & Education",
volume = "53",
number = "3",
pages = "667 - 676",
year = "2009",
issn = "0360-1315",
doi = "https://doi.org/10.1016/j.compedu.2009.04.004",
url = "http://www.sciencedirect.com/science/article/pii/S036013150900089X",
author = "Eric. N. Wiebe and James Minogue and M. Gail Jones and Jennifer Cowley and Denise Krebs",
keywords = "Elementary education, Human-computer interface, Interactive learning environments, Multimedia/hypermedia systems, Virtual reality",
abstract = "While there has been extensive experimental research on haptics, less has been conducted on cross-modal interactions between visual and haptic perception and even less still on cross-modal applications in instructional settings. This study looks at a simulation on the principles of levers using both visual and haptic feedback: one group received visual and haptic feedback while the other just visual feedback. Using the triangulation of learning scores, eye tracking data, and video analysis of interaction with the levers, the efficacy of haptic feedback to improve learning was explored. The results indicate that while the total fixation time on the levers and numeric readout was greater for the visual and haptic group, very similar patterns of visual attention were seen between groups. Perhaps surprisingly, the visual only group scored higher on an embedded assessment. Explanations for these results are synthesized from theories of cross-modal perception and cognitive architecture."
}
@article{TREVORS201631,
title = "Self-regulated learning processes vary as a function of epistemic beliefs and contexts: Mixed method evidence from eye tracking and concurrent and retrospective reports",
journal = "Learning and Instruction",
volume = "42",
pages = "31 - 46",
year = "2016",
issn = "0959-4752",
doi = "https://doi.org/10.1016/j.learninstruc.2015.11.003",
url = "http://www.sciencedirect.com/science/article/pii/S0959475215300426",
author = "Gregory Trevors and Reza Feyzi-Behnagh and Roger Azevedo and François Bouchet",
keywords = "Epistemic cognition, Self-regulated learning, Metacognition, Process data",
abstract = "The objective of the current studies was to investigate how epistemic cognition related to specific phases and components of self-regulated learning and its adaptation to learning conditions of varying quality. In a multi-study, mixed method design, we presented university students with science content that relayed conceptual discrepancies and collected quantitative and qualitative data to study how students responded to discrepancies. In Study 1 (n = 42), we collected eye tracking patterns, study times, and metacognitive ratings and found that participants adapted their behavioral processing as a function of their epistemic cognition and discrepancy type. In Study 2 (n = 20), we collected concurrent think-aloud protocols and retrospective interviews to further explore why discrepancies were noticed (or not) and how they were resolved. Results revealed that prior knowledge and epistemic self-efficacy in oneself as an evaluator of knowledge emerged as important themes to detecting and efficiently resolving discrepancies. We conclude with a discussion of theoretical and methodological implications."
}
@article{NISTOR2018335,
title = "What types of data are used in learning analytics? An overview of six cases",
journal = "Computers in Human Behavior",
volume = "89",
pages = "335 - 338",
year = "2018",
issn = "0747-5632",
doi = "https://doi.org/10.1016/j.chb.2018.07.038",
url = "http://www.sciencedirect.com/science/article/pii/S0747563218303601",
author = "Nicolae Nistor and Ángel Hernández-Garcíac",
keywords = "Learning analytics, Data types, Eye tracking, Automated dialog analysis, Log data analysis, Visual learning analytics",
abstract = "The rapid development of learning analytics makes it difficult for the readership of research literature to gain a structured overview over the different types of data available and subject to the application of learning analytics techniques or methods. This special issue reunites six examples of application of different learning analytics approaches using various data types, aiming to achieve different goals, and employing different instruments and methods: eye tracking, automated online dialog analysis, survey data from school ecosystems, log data analysis at individual and collaborative level, and visual learning analytics applied to Internet-of-Things data. These case studies are provided in the framework of the observed process–data–transformation–analysis–output pattern of practices. Brief conclusions pertaining to advantages, limitations and future work are drawn."
}
@article{RUF2014229,
title = "One click away is too far! How the presentation of cognitive learning aids influences their use in multimedia learning environments",
journal = "Computers in Human Behavior",
volume = "38",
pages = "229 - 239",
year = "2014",
issn = "0747-5632",
doi = "https://doi.org/10.1016/j.chb.2014.06.002",
url = "http://www.sciencedirect.com/science/article/pii/S0747563214003379",
author = "Tatjana Ruf and Rolf Ploetzner",
keywords = "Multimedia learning, Cognitive learning aids, Interface design, Usability, Eye tracking",
abstract = "In an experimental study, we investigated how the presentation of cognitive learning aids, as well as the availability of self-monitoring questions affect the frequency of use of cognitive learning aids in a multimedia learning environment. The learning aids were presented either dynamically, statically, or they were initially collapsed and the students had to activate them by clicking on a button. The comparability of all three versions of the multimedia learning environment was assured by means of repeated usability testing. Self-monitoring questions were either presented to the learners or not. A total of 60 undergraduate students participated in the study. Their activities in the learning environment, together with their eye movements were recorded. The students took advantage of the learning aids most when they were dynamically presented, less when they were statically presented, and least when they were presented in a collapsed form. The differences in use of the learning aids were statistically significant with large effect sizes. The availability of self-monitoring questions had no significant effect on the use of learning aids."
}
@article{BARRAFREM2019102188,
title = "Tracing risky decisions for oneself and others: The role of intuition and deliberation",
journal = "Journal of Economic Psychology",
pages = "102188",
year = "2019",
issn = "0167-4870",
doi = "https://doi.org/10.1016/j.joep.2019.102188",
url = "http://www.sciencedirect.com/science/article/pii/S0167487019303654",
author = "Kinga Barrafrem and Jan Hausfeld",
keywords = "Decision making for others, Risk preferences, Decision noise, Dual-process theory, Eye-tracking",
abstract = "This study contributes to the understanding of how individuals make choices for themselves and on behalf of others in a risky environment. In a laboratory eye-tracking experiment, we investigate whether risk preferences, decision error, and information processing differ between decisions made for oneself and on behalf of others. While we find no differences in risk preferences when deciding for oneself or for someone else, individuals have a greater decision error when deciding for others. Process data partly explains these differences. Individuals spend less time, have less fixations, and inspect less information when deciding for others. We detect similar processing patterns when comparing intuitive and deliberative decision making. We argue that the processing of decisions for oneself is more effortful and involves more extensive deliberation which, in turn, is related to less decision errors."
}
@article{PETRUSEL20171,
title = "How visual cognition influences process model comprehension",
journal = "Decision Support Systems",
volume = "96",
pages = "1 - 16",
year = "2017",
issn = "0167-9236",
doi = "https://doi.org/10.1016/j.dss.2017.01.005",
url = "http://www.sciencedirect.com/science/article/pii/S016792361730012X",
author = "Razvan Petrusel and Jan Mendling and Hajo A. Reijers",
keywords = "Business process model comprehension, Visual cognition factors of model comprehension, Theoretical perspective model comprehension, Eye-tracking experiment business process model, Complexity of process model comprehension task",
abstract = "Process analysts and other professionals extensively use process models to analyze business processes and identify performance improvement opportunities. Therefore, it is important that such models can be easily and properly understood. Previous research has mainly focused on two types of factors that are important in this context: (i) properties of the model itself, and (ii) properties of the model reader. The work in this paper aims at determining how the performance of subjects varies across different types of comprehension tasks, which is a new angle. To reason about the complexity of comprehension tasks we take a theoretical perspective that is grounded in visual cognition. We test our hypotheses using a free-simulation experiment that incorporates eye-tracking technology. We find that model-related and person-related factors are fully mediated by variables of visual cognition. Moreover, in comparison, visual cognition variables provide a significantly higher explanatory power for the duration and efficiency of comprehension tasks. These insights shed a new perspective on what influences sense-making of process models, shifting the attention from model and reader characteristics to the complexity of the problem-solving task at hand. Our work opens the way to investigate and develop effective strategies to support readers of process models, for example through the context-sensitive use of visual cues."
}
@incollection{WILSON201835,
title = "Chapter 3 - The quiet eye is sensitive to exercise-induced physiological stress",
editor = "Samuele Marcora and Mustafa Sarkar",
series = "Progress in Brain Research",
publisher = "Elsevier",
volume = "240",
pages = "35 - 52",
year = "2018",
booktitle = "Sport and the Brain: The Science of Preparing, Enduring and Winning, Part C",
issn = "0079-6123",
doi = "https://doi.org/10.1016/bs.pbr.2018.08.008",
url = "http://www.sciencedirect.com/science/article/pii/S0079612318301006",
author = "Mark R. Wilson and Ann Webb and Lee J. Wylie and Samuel J. Vine",
keywords = "Basketball, Attention, Fatigue, Eye tracking, Psychophysiology",
abstract = "The current study sought to explore attentional mechanisms underpinning visuomotor performance degradation following acute exercise. Ten experienced basketball players took free throws while wearing mobile eye tracking glasses, before and after performing a bout of cycling exercise. Shooting accuracy was measured using a 6-point scoring system, and quiet eye duration (the final fixation to a target) was adopted as an objective measure of top-down attentional control. Four intensities of exercise (based on an initial ramp test) were performed in a counterbalanced order: rest, moderate, heavy and severe. The four intensities resulted in participants reaching 52±4%, 58±4%, 76±6% and 86±5% of their heart rate max, respectively. Performance and quiet eye were only significantly impaired (19% and 45% drops, respectively) between pre- and post-intervention at the severe intensity workload level. Additionally, exercise-induced changes in quiet eye predicted 33% of the subsequent change in performance accuracy. The results suggest that attentional disruptions may at least partially explain why sporting skills break down under acute fatigue. Implications for training to mitigate against these impairments are discussed."
}
@article{WILLEMS2019113080,
title = "Reputation Star Society: Are star ratings consulted as substitute or complementary information?",
journal = "Decision Support Systems",
volume = "124",
pages = "113080",
year = "2019",
issn = "0167-9236",
doi = "https://doi.org/10.1016/j.dss.2019.113080",
url = "http://www.sciencedirect.com/science/article/pii/S0167923619301095",
author = "Jurgen Willems and Carolin J. Waldner and John C. Ronquillo",
keywords = "Online reputation systems, Star ratings, Eye-tracking, Decision-making",
abstract = "To simplify decision making processes, online platforms frequently display reputation star ratings as an indication of the quality of a product, service, or organization. Can information provided by such star ratings draw away attention from other information? This is an important question for platform developers to adjust the use of such ratings. We conduct a between-subjects laboratory experiment (n = 121) where we manipulate the difference between the reputation star ratings of two social profit organizations, and ask respondents to indicate which organization they prefer. Applying eye-tracking technology, we analyze how the visual attention between the treatment conditions differs. Our findings show that reputation star ratings are consulted as complementary information, rather than as substitute information. Moreover, the results suggest that the lack of stars – not the presence of more stars – attracts visual attention."
}
@article{HEIKOOP2018193,
title = "Effects of mental demands on situation awareness during platooning: A driving simulator study",
journal = "Transportation Research Part F: Traffic Psychology and Behaviour",
volume = "58",
pages = "193 - 209",
year = "2018",
issn = "1369-8478",
doi = "https://doi.org/10.1016/j.trf.2018.04.015",
url = "http://www.sciencedirect.com/science/article/pii/S1369847817304308",
author = "Daniël D. Heikoop and Joost C.F. de Winter and Bart van Arem and Neville A. Stanton",
abstract = "Previous research shows that drivers of automated vehicles are likely to engage in visually demanding tasks, causing impaired situation awareness. How mental task demands affect situation awareness is less clear. In a driving simulator experiment, 33 participants completed three 40-min runs in an automated platoon, each run with a different level of mental task demands. Results showed that high task demands (i.e., performing a 2-back task, a working memory task in which participants had to recall a letter, presented two letters ago) induced high self-reported mental demands (71% on the NASA Task Load Index), while participants reported low levels of self-reported task engagement (measured with the Dundee Stress State Questionnaire) in all three task conditions in comparison to the pre-task measurement. Participants’ situation awareness, as measured using a think-out-loud protocol, was affected by mental task demands, with participants being more involved with the mental task itself (i.e., to remember letters) and less likely to comment on situational features (e.g., car, looking, overtaking) when task demands increased. Furthermore, our results shed light on temporal effects, with heart rate decreasing and self-constructed mental models of automation growing in complexity, with run number. It is concluded that mental task demands reduce situation awareness, and that not only type-of-task, but also time-on-task, should be considered in Human Factors research of automated driving."
}
@article{KOOP2013151,
title = "The response dynamics of preferential choice",
journal = "Cognitive Psychology",
volume = "67",
number = "4",
pages = "151 - 185",
year = "2013",
issn = "0010-0285",
doi = "https://doi.org/10.1016/j.cogpsych.2013.09.001",
url = "http://www.sciencedirect.com/science/article/pii/S0010028513000492",
author = "Gregory J. Koop and Joseph G. Johnson",
keywords = "Decision making, Computational model, Methodology, Process models, Preference reversals, Risky decision making",
abstract = "The ubiquity of psychological process models requires an increased degree of sophistication in the methods and metrics that we use to evaluate them. We contribute to this venture by capitalizing on recent work in cognitive science analyzing response dynamics, which shows that the bearing information processing dynamics have on intended action is also revealed in the motor system. This decidedly “embodied” view suggests that researchers are missing out on potential dependent variables with which to evaluate their models—those associated with the motor response that produces a choice. The current work develops a method for collecting and analyzing such data in the domain of decision making. We first validate this method using widely normed stimuli from the International Affective Picture System (Experiment 1), and demonstrate that curvature in response trajectories provides a metric of the competition between choice options. We next extend the method to risky decision making (Experiment 2) and develop predictions for three popular classes of process model. The data provided by response dynamics demonstrate that choices contrary to the maxim of risk seeking in losses and risk aversion in gains may be the product of at least one “online” preference reversal, and can thus begin to discriminate amongst the candidate models. Finally, we incorporate attentional data collected via eye-tracking (Experiment 3) to develop a formal computational model of joint information sampling and preference accumulation. In sum, we validate response dynamics for use in preferential choice tasks and demonstrate the unique conclusions afforded by response dynamics over and above traditional methods."
}
@article{LI2020102799,
title = "Children's attention toward cartoon executed photos",
journal = "Annals of Tourism Research",
volume = "80",
pages = "102799",
year = "2020",
issn = "0160-7383",
doi = "https://doi.org/10.1016/j.annals.2019.102799",
url = "http://www.sciencedirect.com/science/article/pii/S0160738319301562",
author = "Mimi Li and Yuhao Chen and Jingqiang Wang and Tingting Liu",
keywords = "Tourism photographs, Children, Eye tracking, Visual attention, Advertisement",
abstract = "The study is intended to examine the effect of cartoon execution on children's attention toward and preferences for tourism photographs. A 3 (photo categories) × 2 (photo effects) × 2 (display order) repeated-measures experiment was designed to compare children's fixation counts, fixation duration, and dwell time between normal and cartoon-executed photos of tourism attractions in culture, nature, and recreation categories. Follow-up interviews were conducted to triangulate experimental findings. Results indicate that cartoon execution, as a common advertising tactic, can effectively increase children's attention to tourism photographs, but the effects vary by category. Findings from this study contribute to the body of knowledge on advertising effectiveness and tourism and provide insight for destination marketing organizations."
}
@article{TALLON2019145,
title = "Comprehension of business process models: Insight into cognitive strategies via eye tracking",
journal = "Expert Systems with Applications",
volume = "136",
pages = "145 - 158",
year = "2019",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2019.06.032",
url = "http://www.sciencedirect.com/science/article/pii/S0957417419304324",
author = "Miles Tallon and Michael Winter and Rüdiger Pryss and Katrin Rakoczy and Manfred Reichert and Mark W. Greenlee and Ulrich Frick",
keywords = "Visual literacy, Business process model, Eye tracking, Latent class analysis, Cognitive workload",
abstract = "Process Models (PM) are visual documentations of the business processes within or across enterprises. Activities (tasks) are arranged together into a model (i.e., similar to flowcharts). This study aimed at understanding the underlying structure of PM comprehension. Though standards for describing PM have been defined, the cognitive work load they evoke, their structure, and the efficacy of information transmission are only partially understood. Two studies were conducted to better differentiate the concept of visual literacy (VL) and logical reasoning in interpreting PM. Study I: A total of 1047 students from 52 school classes were assessed. Three different process models of increasing complexity were presented on tablets. Additionally, written labels of the models’ elements were randomly allocated to scholars in a 3-group between-subjects design. Comprehension of process models was assessed by a series of 3 × 4 (=12) dichotomous test items. Latent Class Analysis of solved items revealed 6 qualitatively differing solution patterns, suggesting that a single test score is insufficient to reflect participants’ performance. Study II: Overall, 21 experts and 15 novices with respect to visual literacy were presented the same set of PMs as in Study I, while wearing eye tracking glasses. The fixation duration on relevant parts of the PM and on questions were recorded, as well as the total time needed to solve all 12 test items. The number of gaze transitions between process model and comprehension questions was measured as well. Being an expert in visual literacy did not alter the capability of correctly understanding graphical logical PMs. Presenting PMs that are labelled by single letters had a significant influence on reducing the time spent on irrelevant model parts but did not affect the fixation duration on relevant areas of interest. Both samples’ participants required longer response times with increasing model complexity. The number of toggles (i.e., gaze transitions between model and statement area of interest) was predictive for membership in one of the latent classes. Contrary to expectations, denoting the PM events and decisions not with real-world descriptions, but with single letters, led to lower cognitive workload in responding to comprehension questions and to better results. Visual Literacy experts could neither outperform novices nor high-school students in comprehending PM."
}
@article{RABAGLIATI201715,
title = "How do children learn to avoid referential ambiguity? Insights from eye-tracking",
journal = "Journal of Memory and Language",
volume = "94",
pages = "15 - 27",
year = "2017",
issn = "0749-596X",
doi = "https://doi.org/10.1016/j.jml.2016.09.007",
url = "http://www.sciencedirect.com/science/article/pii/S0749596X16301838",
author = "Hugh Rabagliati and Alexander Robertson",
keywords = "Referential communication, Language production, Development, Eye tracking, Ambiguity",
abstract = "Children have considerable difficulty producing informative and unambiguous referring expressions, a fact that still lacks a full explanation. Potential insight can come from psycholinguistic models of ambiguity avoidance in adults, which suggest that, before describing any scene, speakers pro-actively monitor for some — but not all — types of potential ambiguity, and then subsequently monitor whether their just-produced expression provides an ambiguous description. Our experiments used eye tracking to assess the developing roles of these skills in children’s referential communication. Experiment 1 shows that adults’ eye movements can index the processes of both pro-active and self-monitoring. Experiments 2 and 3 show that children (n=110) typically do not pro-actively monitor for potential ambiguity, although they do show evidence of pro-active monitoring on the occasions when they produce informative expressions. However, we do find evidence that children consistently monitor their own descriptions for ambiguity, even though they rarely correct their utterances. We propose that the process of self-monitoring might act as a learning signal, that guides children as they acquire the ability to monitor pro-actively."
}
@article{ANDREU201220,
title = "Auditory word recognition of nouns and verbs in children with Specific Language Impairment (SLI)",
journal = "Journal of Communication Disorders",
volume = "45",
number = "1",
pages = "20 - 34",
year = "2012",
issn = "0021-9924",
doi = "https://doi.org/10.1016/j.jcomdis.2011.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S0021992411000724",
author = "Llorenç Andreu and Monica Sanz-Torrent and Joan Guàrdia-Olmos",
keywords = "Language processing, Language development, Specific language impairment, Word recognition, Verb argument structure",
abstract = "Nouns are fundamentally different from verbs semantically and syntactically, since verbs can specify one, two, or three nominal arguments. In this study, 25 children with Specific Language Impairment (age 5;3–8;2 years) and 50 typically developing children (3;3–8;2 years) participated in an eye-tracking experiment of spoken language comprehension to compare the dynamics of spoken word recognition for nouns and verbs in Spanish. Listeners’ eye movements were recorded as they searched an array of pictures in response to hearing a noun or verb. Results showed significant an animacy effect before the word was finished as images that contain more animate entities attracted their looks which suggest an underdevelopment suppression mechanisms inhibition. Moreover, after word finished all the groups showed differences between nouns and verbs. They were faster in recognizing nouns than verbs and one-argument were recognized faster than two- and three-verb arguments whereas. Children with SLI were slower that their controls and especially in the recognition of three-argument verbs. We suggest that this was due to an incomplete argument structure representation that affects processing times. Learning outcomes: (1) As a result of this activity, the participant will be able to describe the differences between adults and children with and without SLI in spoken word recognition of nouns and verbs. (2) As a result of this activity, the participant will be able to describe the animacy effect."
}
@article{FIEDLER2015139,
title = "Attention and moral behavior",
journal = "Current Opinion in Psychology",
volume = "6",
pages = "139 - 144",
year = "2015",
note = "Morality and ethics",
issn = "2352-250X",
doi = "https://doi.org/10.1016/j.copsyc.2015.08.008",
url = "http://www.sciencedirect.com/science/article/pii/S2352250X1500202X",
author = "Susann Fiedler and Andreas Glöckner",
abstract = "Moral judgments and decisions are accompanied by specific patterns of attention, which can be indicative for the underlying cognitive processes. In this opinion paper we address methodological, theoretical and empirical issues concerning the relation between attention and morality. First, we discuss potential advantages of using measures of attention based on eye-tracking to investigate processes of judgment and choice in general and concerning morality in particular. Second, we review empirical studies and identify regularities concerning attention patterns in moral judgments. Third, taking into account these findings we provide suggestions for the development and testing of more detailed and better formalized cognitive process models for moral behavior based on interactive activation and parallel constraint satisfaction mechanisms."
}
@article{YANG2020102020,
title = "How augmented reality affects advertising effectiveness: The mediating effects of curiosity and attention toward the ad",
journal = "Journal of Retailing and Consumer Services",
volume = "54",
pages = "102020",
year = "2020",
issn = "0969-6989",
doi = "https://doi.org/10.1016/j.jretconser.2019.102020",
url = "http://www.sciencedirect.com/science/article/pii/S0969698919306149",
author = "Shuai Yang and Jeffrey R. Carlson and Sixing Chen",
keywords = "Augmented reality (AR), Curiosity, Field experiment, Eye-tracking experiment",
abstract = "Many major consumer-driven companies have started to use augmented-reality (AR) technology and AR apps to enrich their customers' shopping experiences and engagement with their brands, and to ultimately increase sales. However, there is scant research discussing the application of AR in an advertising context. Thus, the major goal of this study is to explore how, why, and when augmented reality influences advertising effectiveness. A field experiment and two laboratory experiments demonstrate that an AR advertisement increases consumers’ attitude toward the ad through an increase in their curiosity toward the ad and attention toward the ad (i.e., measured by a physiological measure using eye-tracking). However, the effects only hold when consumers are unfamiliar with the AR ad technology. Overall, this study provides practical implications to advertisers who are considering integrating augmented reality technology in their advertising efforts."
}
@article{FEHRENBACHER20181,
title = "The moderating role of decision mode in subjective performance evaluation",
journal = "Management Accounting Research",
volume = "41",
pages = "1 - 10",
year = "2018",
issn = "1044-5005",
doi = "https://doi.org/10.1016/j.mar.2018.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S1044500518300210",
author = "Dennis D. Fehrenbacher and Axel K.-D. Schulz and Kristian Rotaru",
keywords = "Subjective performance evaluation, Performance measurement, Spill-over effect, Eye tracking",
abstract = "We use eye tracking technology to provide a better understanding of cognitive processes behind biases in subjective performance evaluation. In our experiment, subjective performance evaluation involves a supervisor evaluating the office administration performance of a subordinate. Consistent with previous literature, we find that the subjective evaluation of subordinate performance is influenced by performance on an unrelated objective measure used to evaluate the subordinate (spill-over). We predict and provide evidence that the supervisor’s decision modes (intuition versus deliberation) interact with the level of performance on the objective performance measure to determine the subjective performance evaluation and the magnitude of the spill-over. Specifically, we find that individuals who use more effortful, deliberate decision modes show lower levels of spill-over. As such, we contribute to the accounting literature by examining how biases in performance evaluation can be reduced and showing ways to capture cognitive processes accompanying those biases more precisely."
}
@article{KANG2020102862,
title = "Pupillometric decoding of high-level musical imagery",
journal = "Consciousness and Cognition",
volume = "77",
pages = "102862",
year = "2020",
issn = "1053-8100",
doi = "https://doi.org/10.1016/j.concog.2019.102862",
url = "http://www.sciencedirect.com/science/article/pii/S1053810019304751",
author = "Olivia Kang and Mahzarin R. Banaji",
keywords = "Pupillometry, Pupil dilation, Mental imagery, Auditory imagination, Music, Norepinephrine, LC-NE system, Attention",
abstract = "Humans report imagining sound where no physical sound is present: we replay conversations, practice speeches, and “hear” music all within the confines of our minds. Research has identified neural substrates underlying auditory imagery; yet deciphering its explicit contents has been elusive. Here we present a novel pupillometric method for decoding what individuals hear “inside their heads”. Independent of light, pupils dilate and constrict in response to noradrenergic activity. Hence, stimuli evoking unique and reliable patterns of attention and arousal even when imagined should concurrently produce identifiable patterns of pupil-size dynamics (PSDs). Participants listened to and then silently imagined music while eye-tracked. Using machine learning algorithms, we decoded the imagined songs within- and across-participants following classifier-training on PSDs collected during both imagination and perception. Echoing findings in vision, cross-domain decoding accuracy increased with imagery strength. These data suggest that light-independent PSDs are a neural signature sensitive enough to decode imagination."
}
@article{ORTH2014524,
title = "Is Beauty in the Aisles of the Retailer? Package Processing in Visually Complex Contexts",
journal = "Journal of Retailing",
volume = "90",
number = "4",
pages = "524 - 537",
year = "2014",
issn = "0022-4359",
doi = "https://doi.org/10.1016/j.jretai.2014.05.004",
url = "http://www.sciencedirect.com/science/article/pii/S0022435914000335",
author = "Ulrich R. Orth and Roberta C. Crouch",
keywords = "Attractiveness, Design, Field dependence, Fluency, Shopping goal, Visual complexity",
abstract = "Visual appeal is an important consideration in the design of brand packages because attractiveness guides behavior. The visual complexity of a context (i.e., the quantity, irregularity, detail, and dissimilarity of objects) in which a retailer displays a package may impact its attractiveness by influencing attention and processing fluency. Employing consumer samples, and stimuli ranging from the abstract to the realistic, three studies provide evidence that people process a package more fluently, thus increasing its attractiveness, when it is presented in a low rather than high complexity context. This effect is more pronounced with inherently appealing packages, and with people who are more field-dependent or pursuing utilitarian shopping goals. Study 1 establishes effects by employing psychometric measures and abstract stimuli; study 2 corroborates findings with another product category and realistic stimuli; and study 3 complements psychometric measures with eye tracking data to demonstrate that visually more complex contexts divert viewer attention, hereby lowering processing fluency and target attractiveness. The authors discuss the theoretical contribution and strategic insights the research provides for retailers, brand managers, and designers."
}
@article{CARVALHO2020,
title = "Measuring Pedophilic Sexual Interest",
journal = "The Journal of Sexual Medicine",
year = "2020",
issn = "1743-6095",
doi = "https://doi.org/10.1016/j.jsxm.2019.12.008",
url = "http://www.sciencedirect.com/science/article/pii/S1743609519318673",
author = "Joana Carvalho and John Bradford and Lisa Murphy and Peer Briken and Paul Fedoroff",
keywords = "Pedophilia, Assessment, Sexual arousal, Sexual interest, Penile plethysmography, Attention",
abstract = "Introduction
Pedophilic sexual interest is an important risk factor in sexual offender recidivism and remains a key component in the clinical assessment of child sexual offenders and people diagnosed with pedophilia. Despite concerns about the absence of universally accepted standardized clinical assessment methods, there are a number of established techniques aimed at assessing people with sexual interest in children.
Aim
To provide a foundation from which to understand existing methods available for the assessment of people with pedophilic sexual interests, including strengths and limitations of each approach.
Methods
A group of clinical experts provide a clinically oriented, narrative review on assessment methods for pedophilic sexual interest, including the rationale behind each method and its implementation. Evidence on validity supporting the techniques, limitations, and ethical issues is also discussed.
Results
The assessment methods were grouped according to the following categories: self-report, genital psychophysiological assessment, indirect measurement, and behavioral measurement of pedophilic interest. Although most techniques performed well in discriminating child sexual offenders with pedophilic interest from distinct comparison groups, there are several limitations, including the current lack of standardization and the ethical challenges posed by this sensitive area.
Clinical implications
An understanding of the different measures available for the assessment of problematic sexual interests plays a vital role in forensic clinical determinations of risk of recidivism and in the identification of treatment targets for men who have committed sexual offenses. Several independent but complimentary methods exist to assess sexual interest. Ongoing work on the international standardization of assessment based on methodologically sound research aimed at determining best practices will address some of the shortcomings of these assessments while improving their reliability.
Strengths & limitations
This article provides a general review on a number of methods aimed at assessing pedophilic interest. However, these methods mirror clinical practice largely used within North America and parts of continental Europe. As a result of cultural differences, opposing paradigms on assessment and treatment of pedophilia, and diverse legal regulation between jurisdictions and countries, these practices may not be applicable on an international scale where other special procedures may be required.
Conclusion
A number of techniques have been used within clinical and research settings that vary from self-report to objective measures. Most methods have demonstrated efficacy. Continued work to combine evidence and experience from diverse populations and multiple countries will improve the quality of the methods available. Carvalho J, Bradford J, Murphy L, et al. Measuring Pedophilic Sexual Interest. J Sex Med 2019; XX:XXX–XXX."
}
@article{PETRUSEL201663,
title = "Task-specific visual cues for improving process model understanding",
journal = "Information and Software Technology",
volume = "79",
pages = "63 - 78",
year = "2016",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2016.07.003",
url = "http://www.sciencedirect.com/science/article/pii/S0950584916301173",
author = "Razvan Petrusel and Jan Mendling and Hajo A. Reijers",
keywords = "Business process model understanding, Visual cues, Scoping task specific model elements, Process model relevant region, Color process model elements",
abstract = "Context
Business process models support various stakeholders in managing business processes and designing process-aware information systems. In order to make effective use of these models, they have to be readily understandable.
Objective
Prior research has emphasized the potential of visual cues to highlight relevant matters in models such that stakeholders can use them more efficiently. What prior research does not explain is in how far visual cues can be customized to specific understanding tasks and how this influences cognition.
Method
In this paper, we address these questions with an experimental research design, in which we use eye-tracking equipment to capture how process experts use models to answer comprehension questions. As a treatment, we designed two manipulations of the secondary notation, namely coloring and layout, to direct attention to the elements relevant for the specific tasks.
Results
Our results indicate that both manipulations improve both eye-tracking-based measures and performance measures such as duration and efficiency, with color having the stronger effect.
Conclusions
Our findings lay the foundation for novel features of process modeling tools that provide modifications of secondary notation in response to specific user queries. More generally, our research emphasizes the importance of the relevant region associated with a particular model understanding task."
}
@article{DEGAULMYN2015288,
title = "L’attention conjointe dans le trouble précoce du spectre autistique : des modèles théoriques à l’évaluation clinique",
journal = "Neuropsychiatrie de l'Enfance et de l'Adolescence",
volume = "63",
number = "5",
pages = "288 - 296",
year = "2015",
issn = "0222-9617",
doi = "https://doi.org/10.1016/j.neurenf.2015.03.009",
url = "http://www.sciencedirect.com/science/article/pii/S0222961715000495",
author = "A. de Gaulmyn and M. Montreuil and Y. Contejean and R. Miljkovitch",
keywords = "Attention conjointe, Autisme, Diagnostic précoce, Évaluation clinique, Joint attention, Autism, Early detection, Clinical evaluation",
abstract = "Résumé
L’identification des symptômes du trouble du spectre autistique (TSA) par le diagnostic clinique permet de déterminer les capacités de communication et de socialisation à stimuler ou aider à la régulation du comportement par une prise en charge de l’enfant avec TSA. L’exigence croissante d’une mise en évidence de ces symptômes de façon précoce rend nécessaire une bonne compréhension des modèles théoriques sous-jacents. Parmi ces derniers, les modèles traitant de l’attention conjointe, l’une des premières capacités communicatives du jeune enfant, sont particulièrement importants pour l’évaluation précoce. Cet article a pour but d’établir un lien entre ces modèles et les outils cliniques utilisés pour le diagnostic et l’évaluation du développement, en se focalisant sur les capacités d’attention conjointe. Une revue de la littérature des modèles existants et des expérimentations dans le cadre de l’autisme permet de définir les principaux mécanismes comportementaux de l’attention conjointe chez le très jeune enfant. Un tableau de correspondance a été élaboré pour identifier leur présence dans les outils cliniques. Les éléments qui se retrouvent simultanément dans les quatre outils étudiés sont concentrés sur la compréhension des intentions. Bien que ce résultat reflète le consensus de la recherche sur ce sujet, deux éléments constitutifs de l’attention conjointe, liés à l’exploration visuelle et au désengagement attentionnel ne sont pas repris dans les outils cliniques. Il s’agit de mécanismes explorés par des modèles théoriques récents et utilisant des méthodes innovantes comme le détecteur de mouvement oculaire (eye-tracking). Ces nouvelles technologies sont aujourd’hui couramment utilisées dans le domaine de la recherche et suggèrent une évolution des modèles théoriques de l’attention conjointe, mais leur application clinique n’est pas encore mise en place, ce qui pourrait expliquer l’absence de ces éléments dans les outils actuels. Il serait intéressant de les intégrer dans les outils d’évaluation clinique et favoriser leur intégration dans le dépistage précoce de l’autisme.
Clinical diagnosis of autism spectrum disorder (ASD) symptoms leads to identification of communication, socialization or psychomotor skills that need to be enhanced through treatment of children with ASD. A thorough understanding of underlying theoretical models of ASD is urged by a growing need for early screening of these symptoms. Among these models, those focused on joint attention, one of infants’ first communication skills, are particularly relevant for early diagnosis. This article is aimed at linking these models to the clinical assessments used for diagnosing and evaluating development, with special attention to joint attention skills. A review of the literature of existing models and research on autism helps identify the main bevioral mechanisms involved in joint attention in infancy. A table of correspondance has been developed to examine their presence among clinical assessments. Items present in the four instruments considered concern the understanding of intentions. Although this result is consistent with the consensus of research on this issue, two items concerning joint attention are absent from the instruments. They concern mechanisms explored by recent theoretical models based on innovative methods such as eye-tracking. These new technologies are now commonly used in research studies and lead theoretical models of joint attention to evolve. However, their practical impact on clinical assessments is not yet in place, which accounts for the absence of these items in existing instruments. It would be interesting to integrate them in clinical assessments and encourage their integration in the early detection of autism."
}
@article{SONGA2019485,
title = "How do implicit/explicit attitudes and emotional reactions to sustainable logo relate? A neurophysiological study",
journal = "Food Quality and Preference",
volume = "71",
pages = "485 - 496",
year = "2019",
issn = "0950-3293",
doi = "https://doi.org/10.1016/j.foodqual.2018.04.008",
url = "http://www.sciencedirect.com/science/article/pii/S0950329318303379",
author = "Giulia Songa and Hendrik Slabbinck and Iris Vermeir and Vincenzo Russo",
keywords = "Implicit association test, Eye-tracking, Consumers’ emotions, Attitudes, Visual behaviour, Indirect measurement",
abstract = "Food package labels can be used to influence consumers’ evaluation and purchasing behaviour, fostering sustainable consumption. Therefore, it is important to understand consumers’ emotional reaction to food package labels that convey sustainable information. The aim of the present research is to get a better understanding of the relation between consumers’ attitudes and emotional reactions often used to measure the effectiveness of a communication. Particularly, we focused on recyclability, assessing participants’ prior explicit and implicit attitudes towards recyclability and their emotional reaction to food packages featuring logos of (non-)recyclability. The emotional reaction was measured both at an explicit and at an implicit level, using direct (self-reported) and indirect (eye movement, facial expressions and pupil dilation) techniques respectively. Results showed that explicit attitudes predicted self-reported emotions, while implicit attitudes predicted the spontaneous emotional reactions, highlighting the importance to assess both explicit and implicit attitudes. Moreover, results showed that the relation between the time that people looked at the logo and the spontaneous emotional reaction was contingent upon the participant’s implicit attitudes. Finally, a follow-up analysis revealed that people with positive implicit attitudes towards recyclability were faster in detecting the recyclable logo and spent more time on processing the logo which on its turn resulted in better emotional reactions. Thus, the results suggest that implicit attitudes influence both visual attention and emotional reactions. Overall, the research contributes to a better understanding of the relation between prior attitudes and emotional reactions to food packaging, and supports the use of an approach that comprises both direct and indirect measures of attitudes and emotions."
}
@article{PLOETZNER201412,
title = "Simultaneously presented animations facilitate the learning of higher-order relationships",
journal = "Computers in Human Behavior",
volume = "34",
pages = "12 - 22",
year = "2014",
issn = "0747-5632",
doi = "https://doi.org/10.1016/j.chb.2014.01.039",
url = "http://www.sciencedirect.com/science/article/pii/S074756321400051X",
author = "Rolf Ploetzner and Richard Lowe",
keywords = "Animation, Sequential presentation, Simultaneous presentation, Animation processing, Eye tracking, Learning",
abstract = "In an experimental study, we investigated how the simultaneous and sequential presentation of animation episodes affects learners’ perceptual interrogation of the animation as well as their acquisition of higher-order relationships. Of the 60 students who participated in the study, 30 studied the animation episodes presented simultaneously and 30 studied the same episodes presented sequentially. The eye movements of eight participants from each group were recorded while they studied the animation episodes. The simultaneous presentation resulted in significantly more visual transitions between the episodes than the sequential presentation. Further, in case of the simultaneous presentation significantly more bi-directional visual transitions occurred than in case of the sequential presentation. Learning of higher-order relationships was significantly more successful from simultaneously presented episodes than from sequentially presented episodes."
}
@article{RUYTENBEEK201746,
title = "Indirect request processing, sentence types and illocutionary forces",
journal = "Journal of Pragmatics",
volume = "119",
pages = "46 - 62",
year = "2017",
issn = "0378-2166",
doi = "https://doi.org/10.1016/j.pragma.2017.07.011",
url = "http://www.sciencedirect.com/science/article/pii/S0378216617301649",
author = "Nicolas Ruytenbeek and Ekaterina Ostashchenko and Mikhail Kissine",
keywords = "Literalism, Indirect requests, Conventionalization, Imperatives, Deontic modals",
abstract = "According to the literalist view of speech acts, morpho-syntactic sentence types are associated directly at the semantic level with an illocutionary force. By contrast, according to contextualist theories illocutionary force emerges from contexts of use. To date, however, there is little experimental evidence relevant to this debate. We propose two experimental, eye-tracking studies to test two predictions of the literalist view: First, unlike for the highly conventionalised Can you? forms, whenever a non-conventionalised construction such as Is it possible to? is interpreted as a request, its question interpretation should also be activated. Second, the directive interpretation of modal You must declaratives should activate the statement interpretation and, therefore, be costlier than that of imperatives. In Study 1, we show, first, that, in contexts where both the non-directive and directive interpretation of indirect requests are available, the latter are processed as fast as that of the corresponding imperatives, independently of the conventionalisation degree of the indirect request at hand. Second, eye fixation data show that the comprehension of indirect requests does not activate their direct meaning. Study 2 shows that modal You must declaratives are understood as imperatives and do not activate a statement interpretation; this supports the view that obligation modal requests are as direct as imperative requests."
}
@article{KUKONA201672,
title = "The real-time prediction and inhibition of linguistic outcomes: Effects of language and literacy skill",
journal = "Acta Psychologica",
volume = "171",
pages = "72 - 84",
year = "2016",
issn = "0001-6918",
doi = "https://doi.org/10.1016/j.actpsy.2016.09.009",
url = "http://www.sciencedirect.com/science/article/pii/S0001691816302293",
author = "Anuenue Kukona and David Braze and Clinton L. Johns and W. Einar Mencl and Julie A. Van Dyke and James S. Magnuson and Kenneth R. Pugh and Donald P. Shankweiler and Whitney Tabor",
keywords = "Anticipation, Language comprehension, Individual differences, Rapid automatized naming (RAN), Sentence processing, Visual world paradigm",
abstract = "Recent studies have found considerable individual variation in language comprehenders' predictive behaviors, as revealed by their anticipatory eye movements during language comprehension. The current study investigated the relationship between these predictive behaviors and the language and literacy skills of a diverse, community-based sample of young adults. We found that rapid automatized naming (RAN) was a key determinant of comprehenders' prediction ability (e.g., as reflected in predictive eye movements to a white cake on hearing “The boy will eat the white…”). Simultaneously, comprehension-based measures predicted participants' ability to inhibit eye movements to objects that shared features with predictable referents but were implausible completions (e.g., as reflected in eye movements to a white but inedible white car). These findings suggest that the excitatory and inhibitory mechanisms that support prediction during language processing are closely linked with specific cognitive abilities that support literacy. We show that a self-organizing cognitive architecture captures this pattern of results."
}
@article{GALIL2019405,
title = "Cheating behavior in children: Integrating gaze allocation and social awareness",
journal = "Journal of Experimental Child Psychology",
volume = "178",
pages = "405 - 416",
year = "2019",
issn = "0022-0965",
doi = "https://doi.org/10.1016/j.jecp.2018.08.013",
url = "http://www.sciencedirect.com/science/article/pii/S0022096518301474",
author = "Avshalom Galil and Jessica Yarmolovsky and Maor Gidron and Ronny Geva",
keywords = "Cheating, Gaze behavior, Social awareness, Attention, Decision making",
abstract = "Children’s cheating and factors supporting honesty are not well understood. The current work explored variables involved in children’s cheating through eye-tracking and an implicit manipulation in which extrinsic awareness of the effects of one’s behaviors on others was primed. Participants played a computer game with the option for a monetary gain in which they could earn more if they selectively erred in response to more profitable stimuli. Results show that children cheat by making selective effort toward more profitable errors; however, extrinsic awareness inhibits these cheating behaviors. Importantly, gaze toward children’s earnings mediates this relationship, suggesting that extrinsic awareness mitigates an impulsive looking pattern, which in turn results in less cheating. Findings suggest that an implicit manipulation, highlighting the potential implications of one’s actions for others, seems to effectively suppress cheating among children. Furthermore, attention toward earnings offers a cognitive process that acts to mediate the effect of this manipulation on cheating. Taken together, this framework suggests psychoneurocognitive and social processes that influence cheating in children, offering a direction for future implicit intervention techniques to support honest performance."
}
@article{ROBBINS2019105266,
title = "How does drivers’ visual search change as a function of experience? A systematic review and meta-analysis",
journal = "Accident Analysis & Prevention",
volume = "132",
pages = "105266",
year = "2019",
issn = "0001-4575",
doi = "https://doi.org/10.1016/j.aap.2019.105266",
url = "http://www.sciencedirect.com/science/article/pii/S0001457519303094",
author = "Chloe Robbins and Peter Chapman",
keywords = "Driving, Experience, Novice drivers, Experienced drivers, Visual search, Eye movements",
abstract = "Novice drivers are statistically over-represented in reported road crashes, with recent evidence suggesting that some of this increased crash involvement may be a result of limitations in their cognitive processing. Such processing has typically been measured by recording drivers’ patterns of eye movements, however, the exact ways in which eye movements are reported and interpreted varies substantially between different studies in the literature. Therefore, the objective of this systematic review was to investigate whether novice drivers and experienced drivers do differ in clear and reproducible ways in their visual search. Studies were identified through searches of Web of Science, Medline, TRID Database, and the TRB Research in Progress Database, with no restrictions on publication status. Studies were included if they compared the visual search of a novice driver group (<3 years driving experience) and an experienced driver group (>3 years driving experience) using an eye tracking method and reported at least one of the following four visual search outcomes: fixation durations, horizontal spread of search, vertical spread of search and number of fixations. Two reviewers independently screened searches and assessed the full texts of potentially included studies. Of the 235 studies initially identified 18 were included in the review, with 13 studies reporting sufficient data to be included in the meta-analysis for at least one outcome measure. Given that the included studies deployed a range of method types, additional sub-group analyses were conducted using this factor. Sensitivity analyses were also conducted by temporarily removing extreme experience groups (e.g. driving instructors and learner drivers) in order to test the effect of different levels of experience and training. The meta-analyses, along with support from results discussed narratively, revealed that novice drivers have a narrower horizontal spread of search compared to experienced drivers, however, there were no overall differences in fixation durations, vertical spread of search or number of fixations when the studies were pooled together. These findings have important primary implications for the development of novice training interventions, with novice drivers needing to develop a broader horizontal spread of visual search, but not to necessarily learn to fixate further down the road. Subgroup analyses also provided considerations for future research studies in terms of the experience of the driver groups, and the method type used."
}
@incollection{KOC2018129,
title = "Chapter 5 - How Can Consumer Science Be Used for Gaining Information About Consumers and the Market?: The role of psychophysiological and neuromarketing research",
editor = "Alessio Cavicchi and Cristina Santini",
booktitle = "Case Studies in the Traditional Food Sector",
publisher = "Woodhead Publishing",
pages = "129 - 152",
year = "2018",
series = "Woodhead Publishing Series in Food Science, Technology and Nutrition",
isbn = "978-0-08-101007-5",
doi = "https://doi.org/10.1016/B978-0-08-101007-5.00013-0",
url = "http://www.sciencedirect.com/science/article/pii/B9780081010075000130",
author = "Erdogan Koc and Hakan Boz",
keywords = "Food consumption, neuromarketing, consumer studies, consumer neuroscience, psychophysiological research techniques, psychoneurobiochemistry, EEG, eye tracker, GSR",
abstract = "This chapter provides an in-depth analysis and explanation of psychophysiological/neuromarketing research tools such as the eye tracker, fMRI, EEG, HR, and GSR for gaining an insight into consumer behavior in the traditional food and wine market. The chapter particularly investigates the need for the new psychophysiological/neuromarketing research tools compared with traditional methods, a review of the research carried out with modern consumer science tools, and how data could be collected and analyzed in a traditional food and wine market through the use of these tools. The chapter concludes with a case example showing the application of psychophysiological/neuromarketing research tools."
}
@article{DEAMER2019100159,
title = "Non-literal understanding and psychosis: Metaphor comprehension in individuals with a diagnosis of schizophrenia",
journal = "Schizophrenia Research: Cognition",
volume = "18",
pages = "100159",
year = "2019",
issn = "2215-0013",
doi = "https://doi.org/10.1016/j.scog.2019.100159",
url = "http://www.sciencedirect.com/science/article/pii/S2215001318300477",
author = "Felicity Deamer and Ellen Palmer and Quoc C. Vuong and Nicol Ferrier and Andreas Finkelmeyer and Wolfram Hinzen and Stuart Watson",
keywords = "Metaphor, Schizophrenia, Non-literal language, Psychosis",
abstract = "Previous studies suggest that understanding of non-literal expressions, and in particular metaphors, can be impaired in people with schizophrenia; although it is not clear why. We explored metaphor comprehension capacity using a novel picture selection paradigm; we compared task performance between people with schizophrenia and healthy comparator subjects and we further examined the relationships between the ability to interpret figurative expressions non-literally and performance on a number of other cognitive tasks. Eye-tracking was used to examine task strategy. We showed that even when IQ, years of education, and capacities for theory of mind and associative learning are factored in as covariates, patients are significantly more likely to interpret metaphorical expressions literally, despite eye-tracking findings suggesting that patients are following the same interpretation strategy as healthy controls. Inhibitory control deficits are likely to be one of multiple factors contributing to the poorer performance of our schizophrenia group on the metaphor trials of the picture selection task."
}
@article{ABLINGER201612,
title = "Diverging receptive and expressive word processing mechanisms in a deep dyslexic reader",
journal = "Neuropsychologia",
volume = "81",
pages = "12 - 21",
year = "2016",
issn = "0028-3932",
doi = "https://doi.org/10.1016/j.neuropsychologia.2015.11.023",
url = "http://www.sciencedirect.com/science/article/pii/S0028393215302396",
author = "Irene Ablinger and Ralph Radach",
keywords = "Deep dyslexia, Aphasia, Reading therapy, Eye movements, Reading strategy",
abstract = "We report on KJ, a patient with acquired dyslexia due to cerebral artery infarction. He represents an unusually clear case of an “output” deep dyslexic reader, with a distinct pattern of pure semantic reading. According to current neuropsychological models of reading, the severity of this condition is directly related to the degree of impairment in semantic and phonological representations and the resulting imbalance in the interaction between the two word processing pathways. The present work sought to examine whether an innovative eye movement supported intervention combining lexical and segmental therapy would strengthen phonological processing and lead to an attenuation of the extreme semantic over-involvement in KJ's word identification process. Reading performance was assessed before (T1) between (T2) and after (T3) therapy using both analyses of linguistic errors and word viewing patterns. Therapy resulted in improved reading aloud accuracy along with a change in error distribution that suggested a return to more sequential reading. Interestingly, this was in contrast to the dynamics of moment-to-moment word processing, as eye movement analyses still suggested a predominantly holistic strategy, even at T3. So, in addition to documenting the success of the therapeutic intervention, our results call for a theoretically important conclusion: Real-time letter and word recognition routines should be considered separately from properties of the verbal output. Combining both perspectives may provide a promising strategy for future assessment and therapy evaluation."
}
@article{LOWE2011650,
title = "Cueing complex animations: Does direction of attention foster learning processes?",
journal = "Learning and Instruction",
volume = "21",
number = "5",
pages = "650 - 663",
year = "2011",
issn = "0959-4752",
doi = "https://doi.org/10.1016/j.learninstruc.2011.02.002",
url = "http://www.sciencedirect.com/science/article/pii/S095947521100020X",
author = "Richard Lowe and Jean-Michel Boucheix",
keywords = "Animation, Cues, Learning, Attention-direction",
abstract = "The time course of learners’ processing of a complex animation was studied using a dynamic diagram of a piano mechanism. Over successive repetitions of the material, two forms of cueing (standard colour cueing and anti-cueing) were administered either before or during the animated segment of the presentation. An uncued group and two other control conditions were also employed. Development of an internal representation of the movements depicted in the animation was evaluated through participant demonstrations of the mechanism’s operation on a replica piano mechanism. Eye tracking (fixation lengths) indicated that overall, conventional visuospatially-based cueing was largely ineffective for directing attention across the presentations of the animation. Demonstration scores from cued animations were no better than those produced from the uncued version. Cue obedience for standard colour cueing was initially superior to that for anti-cues but fell away after the animation’s first exposure. Contrary to expectations, there was no difference in cue obedience for cueing applied before or during animation of the display. The findings suggest that alternatives to visuospatial cues are needed to help learners process complex animations more effectively."
}
@article{SALMERON20091308,
title = "Do graphical overviews facilitate or hinder comprehension in hypertext?",
journal = "Computers & Education",
volume = "53",
number = "4",
pages = "1308 - 1319",
year = "2009",
note = "Learning with ICT: New perspectives on help seeking and information searching",
issn = "0360-1315",
doi = "https://doi.org/10.1016/j.compedu.2009.06.013",
url = "http://www.sciencedirect.com/science/article/pii/S0360131509001602",
author = "Ladislao Salmerón and Thierry Baccino and Jose J. Cañas and Rafael I. Madrid and Inmaculada Fajardo",
keywords = "Hypertext comprehension, Graphical overviews, Eye movements",
abstract = "Educational hypertexts usually include graphical overviews, conveying the structure of the text schematically with the aim of fostering comprehension. Despite the claims about their relevance, there is currently no consensus on the impact that hypertext overviews have on the reader’s comprehension. In the present paper we have explored how hypertext overviews might affect comprehension with regard to (a) the time at which students read the overview and (b) the hypertext difficulty. The results from two eye-tracking studies revealed that reading a graphical overview at the beginning of the hypertext is related to an improvement in the participant’s comprehension of quite difficult hypertexts, whereas reading an overview at the end of the hypertext is linked to a decrease in the student’s comprehension of easier hypertexts. These findings are interpreted in light of the Assimilation Theory and the Active Processing model. Finally, the key educational and hypertext design implications of the results are discussed."
}
@article{SHARAFI201579,
title = "A systematic literature review on the usage of eye-tracking in software engineering",
journal = "Information and Software Technology",
volume = "67",
pages = "79 - 107",
year = "2015",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2015.06.008",
url = "http://www.sciencedirect.com/science/article/pii/S0950584915001196",
author = "Zohreh Sharafi and Zéphyrin Soh and Yann-Gaël Guéhéneuc",
keywords = "Eye-tracking, Software engineering, Experiment",
abstract = "Context
Eye-tracking is a mean to collect evidence regarding some participants’ cognitive processes. Eye-trackers monitor participants’ visual attention by collecting eye-movement data. These data are useful to get insights into participants’ cognitive processes during reasoning tasks.
Objective
The Evidence-based Software Engineering (EBSE) paradigm has been proposed in 2004 and, since then, has been used to provide detailed insights regarding different topics in software engineering research and practice. Systematic Literature Reviews (SLR) are also useful in the context of EBSE by bringing together all existing evidence of research and results about a particular topic. This SLR evaluates the current state of the art of using eye-trackers in software engineering and provides evidence on the uses and contributions of eye-trackers to empirical studies in software engineering.
Method
We perform a SLR covering eye-tracking studies in software engineering published from 1990 up to the end of 2014. To search all recognised resources, instead of applying manual search, we perform an extensive automated search using Engineering Village. We identify 36 relevant publications, including nine journal papers, two workshop papers, and 25 conference papers.
Results
The software engineering community started using eye-trackers in the 1990s and they have become increasingly recognised as useful tools to conduct empirical studies from 2006. We observe that researchers use eye-trackers to study model comprehension, code comprehension, debugging, collaborative interaction, and traceability. Moreover, we find that studies use different metrics based on eye-movement data to obtain quantitative measures. We also report the limitations of current eye-tracking technology, which threaten the validity of previous studies, along with suggestions to mitigate these limitations.
Conclusion
However, not withstanding these limitations and threats, we conclude that the advent of new eye-trackers makes the use of these tools easier and less obtrusive and that the software engineering community could benefit more from this technology."
}
@article{ALMOTERI2018174,
title = "Inattentional blindness and pattern-matching failure: The case of failure to recognize clinical cues",
journal = "Applied Ergonomics",
volume = "73",
pages = "174 - 182",
year = "2018",
issn = "0003-6870",
doi = "https://doi.org/10.1016/j.apergo.2018.07.001",
url = "http://www.sciencedirect.com/science/article/pii/S0003687018301893",
author = "Modi Owied Al-Moteri and Mark Symmons and Simon Cooper and Virginia Plummer",
keywords = "Attention, Notice, Nursing, Patient safety, Inattentional blindness, Eye tracking, Pattern matching",
abstract = "Eye-tracking methodology was used to investigate lapses in the appropriate treatment of ward patients due to not noticing critical cues of deterioration. Forty nursing participants with different levels of experience participated in an interactive screen-based simulation of hypovolemic shock. The results show that 65% of the participants exhibited at least one episode of non-fixation on clinically relevant, fully visible cues that were in plain sight. Thirty-five percent of participants dwelt for sufficient time (>200 ms) on important cues for perception to take place, but no action followed, indicating they had pattern-matching failure. When participants fail to notice what, they should notice in patient status until it is too late, this can have serious consequences. Much work needs to be done, since these human perceptual limitations can affect patient safety in general wards."
}
@article{PRICE2017208,
title = "Sources of relative clause processing difficulty: Evidence from Russian",
journal = "Journal of Memory and Language",
volume = "97",
pages = "208 - 244",
year = "2017",
issn = "0749-596X",
doi = "https://doi.org/10.1016/j.jml.2017.07.013",
url = "http://www.sciencedirect.com/science/article/pii/S0749596X16301000",
author = "Iya K. Price and Jeffrey Witzel",
keywords = "Sentence processing, Relative clauses, Russian, Self-paced reading, Eye tracking, Corpus",
abstract = "This study investigates the sources of processing difficulty in complex sentences involving relative clauses (RCs). Self-paced reading and eye tracking were used to test the comprehension of Russian subject- and object-extracted RCs (SRCs and ORCs) that had the same word-order configuration, but different noun phrase (NP) types (full NPs vs. pronouns) in the embedded clause. In both SRCs and ORCs, this NP intervened between the modified noun and the RC verb. A corpus analysis and acceptability rating experiment indicated different frequency/preference profiles for this word order depending on RC type and embedded NP type. In line with these profiles, processing difficulty was revealed early in the embedded clause for less frequent/dispreferred constructions. Later in the embedded clause, the processing of the RC verb was comparable for both SRCs and ORCs when the same number of NP arguments was available for integration. While there were no indications of an ORC penalty at or after this verb, late-stage comprehension difficulty was found for full-NP ORCs, but not for their pronominal counterparts, suggesting that similarity-based interference in combination with ORC structure influences the overall comprehension of these sentences. Taken together, these findings support a hybrid model under which independent sources of processing difficulty affect different stages of RC comprehension."
}
@article{VERVOORT20141453,
title = "Emotion regulatory function of parent attention to child pain and associated implications for parental pain control behaviour",
journal = "PAIN®",
volume = "155",
number = "8",
pages = "1453 - 1463",
year = "2014",
issn = "0304-3959",
doi = "https://doi.org/10.1016/j.pain.2014.04.015",
url = "http://www.sciencedirect.com/science/article/pii/S0304395914001948",
author = "Tine Vervoort and Zina Trost and Stefan Sütterlin and Line Caes and Agnes Moors",
keywords = "Attention, Children, Emotion regulation, Eye movement, Facial pain expression, Parental protective behaviour, Parents",
abstract = "We investigated the function of parental attention to child pain in regulating parental distress and pain control behaviour when observing their child performing a painful (cold pressor) task (CPT); we also studied the moderating role of parental state anxiety. Participants were 62 schoolchildren and one of their parents. Parental attention towards or away from child pain (ie, attend to pain vs avoid pain) was experimentally manipulated during a viewing task pairing unfamiliar children’s neutral and pain faces. Before and after the viewing task, parental distress regulation was assessed by heart rate (HR) and heart rate variability (HRV). In a subsequent phase, parents observed their own child perform a CPT task, allowing assessment of parental pain control behaviour (indexed by latency to stop their child’s CPT performance) and parental distress, which was assessed via self-report before and after observation of child CPT performance. Eye tracking during the viewing task and self-reported attention to own child’s pain confirmed successful attention manipulation. Further, findings indicated that the effect of attentional strategy on parental emotion regulation (indexed by HR, self-report) and pain control behaviour depended on parents’ state anxiety. Specifically, whereas low anxious parents reported more distress and demonstrated more pain control behaviour in the Attend to Pain condition, high anxious parents reported more distress and showed more pain control behaviour in the Avoid Pain condition. This inverse pattern was likewise apparent in physiological distress indices (HR) in response to the initial viewing task. Theoretical/clinical implications and further research directions are discussed."
}
@article{BODENSCHATZ2020,
title = "Face perception without subjective awareness – Emotional expressions guide early gaze behavior in clinically depressed and healthy individuals",
journal = "Journal of Affective Disorders",
year = "2020",
issn = "0165-0327",
doi = "https://doi.org/10.1016/j.jad.2020.01.039",
url = "http://www.sciencedirect.com/science/article/pii/S0165032719315885",
author = "Charlott Maria Bodenschatz and Marija Skopinceva and Theresa Ruß and Anette Kersting and Thomas Suslow",
keywords = "Eye-tracking, Depression, Emotional facial expressions, Affective priming, Automatic face processing",
abstract = "Background
: Major depressive disorder is associated with attentional biases in the explicit processing of emotional facial expressions. It is unclear if attentional biases for emotional faces also exist at an automatic level of perception.
Method
: Gaze behavior of twenty-nine clinically depressed individuals and twenty-nine gender matched healthy controls was compared in an affective priming task. Happy, neutral, sad, angry, and fearful facial expressions were presented very briefly as primes with forward and backward masking, followed by a neutral expression. Participants’ early gaze behavior on neutral faces was analyzed for the eyes and mouth as areas of interest. Only participants who were subjectively unaware of the emotional prime faces were included in the analyses.
Results
: Masked emotional facial expressions elicited early eye movements toward diagnostic features of the face. Both, depressed patients and healthy controls oriented their initial fixation on the face more often to the eye region after the presentation of fearful or sad compared to happy primes. However, depressed patients oriented their gaze generally far less to the eye and mouth region compared to healthy controls.
Limitation
: Awareness of emotional prime faces was assessed by a systematic interview but not by an objective detection task.
Conclusion
: Our data suggest enhanced attentional orienting toward the eye region due to fearful and sad faces in depressed and healthy individuals. In spite of this early expression-specific vigilance, depressed individuals oriented their gaze overall less to the eyes and mouth compared to healthy controls, which might represent an avoidance of facial features."
}
@article{WIESER200993,
title = "Is eye to eye contact really threatening and avoided in social anxiety?—An eye-tracking and psychophysiology study",
journal = "Journal of Anxiety Disorders",
volume = "23",
number = "1",
pages = "93 - 103",
year = "2009",
issn = "0887-6185",
doi = "https://doi.org/10.1016/j.janxdis.2008.04.004",
url = "http://www.sciencedirect.com/science/article/pii/S0887618508000972",
author = "Matthias J. Wieser and Paul Pauli and Georg W. Alpers and Andreas Mühlberger",
keywords = "Social anxiety, Mutual gaze, Eye movements, Dynamic facial expressions",
abstract = "The effects of direct and averted gaze on autonomic arousal and gaze behavior in social anxiety were investigated using a new paradigm including animated movie stimuli and eye-tracking methodology. While high, medium, and low socially anxious (HSA vs. MSA vs. LSA) women watched animated movie clips, in which faces responded to the gaze of the participants with either direct or averted gaze, their eye movements, heart rate (HR) and skin conductance responses (SCR) were continuously recorded. Groups did not differ in their gaze behavior concerning direct vs. averted gaze, but high socially anxious women tended to fixate the eye region of the presented face longer than MSA and LSA, respectively. Furthermore, they responded to direct gaze with more pronounced cardiac acceleration. This physiological finding indicates that direct gaze may be a fear-relevant feature for socially anxious individuals in social interaction. However, this seems not to result in gaze avoidance. Future studies should examine the role of gaze direction and its interaction with facial expressions in social anxiety and its consequences for avoidance behavior and fear responses. Additionally, further research is needed to clarify the role of gaze perception in social anxiety."
}
@article{LI2019100940,
title = "Hybrid data-driven vigilance model in traffic control center using eye-tracking data and context data",
journal = "Advanced Engineering Informatics",
volume = "42",
pages = "100940",
year = "2019",
issn = "1474-0346",
doi = "https://doi.org/10.1016/j.aei.2019.100940",
url = "http://www.sciencedirect.com/science/article/pii/S1474034619300540",
author = "Fan Li and Ching-Hung Lee and Chun-Hsien Chen and Li Pheng Khoo",
keywords = "Internet of things, Traffic control center, Vigilance detection, Data-driven, Eye movements",
abstract = "Vigilance decrement of traffic controllers would greatly threaten public safety. Hence, extensive studies have been conducted to establish the physiological data-based vigilance model for objectively monitoring or detecting vigilance decrement. Nevertheless, most of them using intrusive devices to collect physiological data and failed to consider context information. Consequently, these models can be used in a laboratory environment while cannot adapt to dynamic working conditions of traffic controllers. The goal of this research is to develop an adaptive vigilance model for monitoring vigilance objectively and non-intrusively. In recent years, with advanced information and communication technology, a massive amount of data can be collected from connected daily use items. Hence, we proposed a hybrid data-driven approach based on connected objects for establishing vigilance model in the traffic control center and provide an elaborated case study to illustrate the method. Specifically, eye movements are selected as the primary inputs of the proposed vigilance model; Bagged trees technique is adapted to generate the vigilance model. The results of case study indicated that (1) eye metrics would be correlated with the vigilance performance subjected to the mental fatigue levels, (2) the bagged trees with the fusion features as inputs achieved a relatively stable performance under the condition of data loss, (3) the proposed method could achieve better performance than the other classic machine learning methods."
}
@article{LI20155663,
title = "How Cockpit Design Impacts Pilots’ Attention Distribution and Perceived Workload during Aiming a Stationary Target",
journal = "Procedia Manufacturing",
volume = "3",
pages = "5663 - 5669",
year = "2015",
note = "6th International Conference on Applied Human Factors and Ergonomics (AHFE 2015) and the Affiliated Conferences, AHFE 2015",
issn = "2351-9789",
doi = "https://doi.org/10.1016/j.promfg.2015.07.781",
url = "http://www.sciencedirect.com/science/article/pii/S2351978915007829",
author = "Wen-Chin Li and Chung-San Yu and Matthew Greaves and Graham Braithwaite",
keywords = "Attention Distribution, Interface Design, Situation Awareness, Perceived Workload, Visual Scan",
abstract = "The eye movement data in five areas of interest (AOIs) were analyzed as follows, Head-up Display (HUD); Integrated Control Panel (ICP); Right Multiple Function Display (RMFD); Left Multiple Function Display (LMFD); and Outside of cockpit (OC). The scenario is performing an air-to-surface task to aim at a stationary target. The results show significant differences in pilots’ percentage of fixation between two interface designs on the ICP (t=-3.36, p<.005, Cohen's d=-.98); RMFD (t=-4.85, p<.001, Cohen's d=-1.55) and LMFD (t=-2.56, p<.05, Cohen's d=-.79). There were significant differences in pilots’ fixation duration between two interfaces on the HUD (t=2.64, p<.05, Cohen's d=.81); ICP (t=-3.00, p<.005, Cohen's d=-.94); RMFD (t=-5.32, p<.001, Cohen's d=-1.65) and LMFD (t=-2.77, p<.05, Cohen's d=-.92). By the application of eye tracker devices, interface designers can precisely evaluate pilots’ visual behavior among interfaces of cockpit and SA performance. In addition, extra workload might have a negative impact on pilots’ SA performance and increase the probability of operating hazards, and so there is the opportunity to compensate for the negative impact of workload through human-centered design. The current research uses eye-tracking devices to investigate pilots’ visual behaviors and interface design and has potential to facilitate system designers’ understanding of pilots’ attention distribution and situational awareness for improving the integration of cockpit designs and ultimately aviation safety."
}
@article{YEH2014153,
title = "A model of how working memory capacity influences insight problem solving in situations with multiple visual representations: An eye tracking analysis",
journal = "Thinking Skills and Creativity",
volume = "13",
pages = "153 - 167",
year = "2014",
issn = "1871-1871",
doi = "https://doi.org/10.1016/j.tsc.2014.04.003",
url = "http://www.sciencedirect.com/science/article/pii/S1871187114000273",
author = "Yu-chu Yeh and Jie-Li Tsai and Wei-Chin Hsu and Chun Fu Lin",
keywords = "Attention, Eye movement, Insight problem, Working memory",
abstract = "Insight problem solving, which involves the restructuring of problems and insights, should be closely related to attention and working memory (WM). This study aimed to employ eye-tracking techniques to understand the process by which attention and WM capacity may influence insight problem solving when situations with multiple visual representations are employed. Fourteen graduate students participated in a 70-minute experimental session in this study. The adapted situation-based creativity task (SCT) and the adapted situation-based WM task (SWMT) were employed to measure WM capacity and insight problem solving. Using situation-based visual WM tasks and insight problem solving the findings of this study suggest the following. First, fixation, gaze duration, and saccades to targets are effective eye movement indicators that can aid in the understanding of the cognitive processes of WM and insight problem solving. Second, attention, eye movements, and WM capacity interactively influence insight problem solving, and that influence varies with WM capacity and the insight stage. Accordingly, we propose three stages of insight processes based on eye movements."
}
@article{BOUCHEIX201371,
title = "Cueing animations: Dynamic signaling aids information extraction and comprehension",
journal = "Learning and Instruction",
volume = "25",
pages = "71 - 84",
year = "2013",
issn = "0959-4752",
doi = "https://doi.org/10.1016/j.learninstruc.2012.11.005",
url = "http://www.sciencedirect.com/science/article/pii/S0959475212001004",
author = "Jean-Michel Boucheix and Richard K. Lowe and Dian K. Putri and Jonathan Groff",
keywords = "Animation processing model, Event cueing, Cue obedience, Eye tracking, Time-locked data",
abstract = "The effectiveness of animations containing two novel forms of animation cueing that target relations between event units rather than individual entities was compared with that of animations containing conventional entity-based cueing or no cues. These relational event unit cues (progressive path and local coordinated cues) were specifically designed to support key learning processes posited by the Animation Processing Model (Lowe & Boucheix, 2008). Four groups of undergraduates (N = 84) studied a user-controllable animation of a piano mechanism and then were assessed for mental model quality (via a written comprehension test) and knowledge of the mechanism's dynamics (via a novel non-verbal manipulation test). Time-locked eye tracking was used to characterize participants' obedience to cues (initial engagement versus ongoing loyalty) across the learning period. For both output measures, participants in the two relational event unit cueing conditions were superior to those in the entity-based and uncued conditions. Time-locked eye tracking analysis of cue obedience revealed that initial cue engagement did not guarantee ongoing cue loyalty. The findings suggest that the Animation Processing Model provides a principled basis for designing more effective animation support."
}
@article{CHEN201461,
title = "Eye movements predict students' computer-based assessment performance of physics concepts in different presentation modalities",
journal = "Computers & Education",
volume = "74",
pages = "61 - 72",
year = "2014",
issn = "0360-1315",
doi = "https://doi.org/10.1016/j.compedu.2013.12.012",
url = "http://www.sciencedirect.com/science/article/pii/S0360131513003369",
author = "Sheng-Chang Chen and Hsiao-Ching She and Ming-Hua Chuang and Jiun-Yu Wu and Jie-Li Tsai and Tzyy-Ping Jung",
keywords = "Evaluation methodologies, Applications in subject areas, Media in education, Teaching/learning strategies, Interdisciplinary projects",
abstract = "Despite decades of studies on the link between eye movements and human cognitive processes, the exact nature of the link between eye movements and computer-based assessment performance still remains unknown. To bridge this gap, the present study investigates whether human eye movement dynamics can predict computer-based assessment performance (accuracy of response) in different presentation modalities (picture vs. text). Eye-tracking system was employed to collect 63 college students' eye movement behaviors while they are engaging in the computer-based physics concept questions presented as either pictures or text. Students' responses were collected immediately after the picture or text presentations in order to determine the accuracy of responses. The results demonstrated that students' eye movement behavior can successfully predict their computer-based assessment performance. Remarkably, the mean fixation duration has the greatest power to predict the likelihood of responding the correct physics concepts successfully, followed by re-reading time in proportion. Additionally, the mean saccade distance has the least and negative power to predict the likelihood of responding the physics concepts correctly in the picture presentation. Interestingly, pictorial presentations appear to convey physics concepts more quickly and efficiently than do textual presentations. This study adds empirical evidence of a prediction model between eye movement behaviors and successful cognitive performance. Moreover, it provides insight into the modality effects on students' computer-based assessment performance through the use of eye movement behavior evidence."
}
@article{SILLENCE2016200,
title = "Examining trust factors in online food risk information: The case of unpasteurized or ‘raw’ milk",
journal = "Appetite",
volume = "99",
pages = "200 - 210",
year = "2016",
issn = "0195-6663",
doi = "https://doi.org/10.1016/j.appet.2016.01.010",
url = "http://www.sciencedirect.com/science/article/pii/S0195666316300095",
author = "Elizabeth Sillence and Claire Hardy and Lydia C. Medeiros and Jeffrey T. LeJeune",
keywords = "Unpasteurized milk, Trust, Internet, Food safety, Online information, Eye tracking",
abstract = "The internet has become an increasingly important way of communicating with consumers about food risk information. However, relatively little is known about how consumers evaluate and come to trust the information they encounter online. Using the example of unpasteurized or raw milk this paper presents two studies exploring the trust factors associated with online information about the risks and benefits of raw milk consumption. In the first study, eye-tracking data was collected from 33 pasteurised milk consumers whilst they viewed six different milk related websites. A descriptive analysis of the eye-tracking data was conducted to explore viewing patterns. Reports revealed the importance of images as a way of capturing initial attention and foregrounding other features and highlighted the significance of introductory text within a homepage. In the second, qualitative study, 41 consumers, some of whom drank raw milk, viewed a selection of milk related websites before participating in either a group discussion or interview. Seventeen of the participants also took part in a follow up telephone interview 2 weeks later. The qualitative data supports the importance of good design whilst noting that balance, authorship agenda, the nature of evidence and personal relevance were also key factors affecting consumers trust judgements. The results of both studies provide support for a staged approach to online trust in which consumers engage in a more rapid, heuristic assessment of a site before moving on to a more in-depth evaluation of the information available. Findings are discussed in relation to the development of trustworthy online food safety resources."
}
@article{PFIFFELMANN2019,
title = "Personalized advertisements with integration of names and photographs: An eye-tracking experiment",
journal = "Journal of Business Research",
year = "2019",
issn = "0148-2963",
doi = "https://doi.org/10.1016/j.jbusres.2019.08.017",
url = "http://www.sciencedirect.com/science/article/pii/S0148296319304874",
author = "Jean Pfiffelmann and Nathalie Dens and Sébastien Soulez",
keywords = "Online advertising, Personalization, Persuasion knowledge, Eye tracking, Recruitment advertising",
abstract = "This article examines the influence of a job recruitment advertisement personalized with a recipient's name and photograph on the visual attention to the advertisement, the attitudes toward the advertisement and, ultimately, job-pursuit intentions. Perceived ad intrusiveness and attitudinal persuasion knowledge may function as parallel mediators of visual attention and attitude toward the advertisement, with personal privacy concerns as a moderator of this relationship. In a between-subjects eye-tracking experiment, 72 participants view an advertisement on LinkedIn that is either personalized or not personalized. Although the participants fixate on the personalized advertisement more frequently and view it longer, they do not notice it faster or return to it more frequently. Furthermore, enhanced visual attention augments perceived intrusiveness, regardless of participants' levels of privacy concern, and decreases attitudinal persuasion knowledge for those who are less concerned about privacy."
}
@article{FORGACS2014101,
title = "Lateralized processing of novel metaphors: Disentangling figurativeness and novelty",
journal = "Neuropsychologia",
volume = "56",
pages = "101 - 109",
year = "2014",
issn = "0028-3932",
doi = "https://doi.org/10.1016/j.neuropsychologia.2014.01.003",
url = "http://www.sciencedirect.com/science/article/pii/S0028393214000074",
author = "Bálint Forgács and Ágnes Lukács and Csaba Pléh",
keywords = "Metaphor, Figurative language, Right hemisphere, Salience, Coarse coding, Divided visual field",
abstract = "One of the intriguing and sometimes controversial findings in figurative language research is a right-hemisphere processing advantage for novel metaphors. The current divided visual field study introduced novel literal expressions as a control condition to assess processing novelty independent of figurativeness. Participants evaluated word pairs belonging to one of the five categories: (1) conventional metaphorical, (2) conventional literal, (3) novel metaphorical, (4) novel literal, and (5) unrelated expressions in a semantic decision task. We presented expressions without sentence context and controlled for additional factors including emotional valence, arousal, and imageability that could potentially influence hemispheric processing. We also utilized an eye-tracker to ensure lateralized presentation. We did not find the previously reported right-hemispherical processing advantage for novel metaphors. Processing was faster in the left hemisphere for all types of word pairs, and accuracy was also higher in the right visual field - left hemisphere. Novel metaphors were processed just as fast as novel literal expressions, suggesting that the primary challenge during the comprehension of novel expressions is not a serial processing of salience, but perhaps a more left hemisphere weighted semantic integration. Our results cast doubt on the right-hemisphere theory of metaphors, and raise the possibility that other uncontrolled variables were responsible for previous results. The lateralization of processing of two word expressions seems to be more contingent on the specific task at hand than their figurativeness or saliency."
}
@article{SRINIVASAN2019364,
title = "Recent developments towards enhancing process safety: Inherent safety and cognitive engineering",
journal = "Computers & Chemical Engineering",
volume = "128",
pages = "364 - 383",
year = "2019",
issn = "0098-1354",
doi = "https://doi.org/10.1016/j.compchemeng.2019.05.034",
url = "http://www.sciencedirect.com/science/article/pii/S0098135419301802",
author = "Rajagopalan Srinivasan and Babji Srinivasan and Mohd Umair Iqbal and Andreja Nemet and Zdravko Kravanja",
keywords = "Simultaneous risk assessment, Inherent safety, Human error, Cognitive engineering, Eye tracking",
abstract = "Safety is paramount aspect of any chemical plant. In this paper various approaches to enhance process safety are evaluated. The specific enhancements include process design methodologies for improving inherent safety and cognitive engineering to reduce human errors. Their aim is to reduce the number and the consequences of possible deviation events, which depends predominantly on quality of the equipment and human error potential. The consequences are linked to the substances and their inventories. An inherent safety index is used to assess the properties of substances and process units while the potential for human error is characterized using various physiological measures. Our research indicates that application of process synthesis methodologies for simultaneous inherent safety assessment and advanced cognitive engineering approaches for human error reduction will lead to enhanced process safety."
}
@article{WU2012626,
title = "HCI and Eye Tracking Technology for Learning Effect",
journal = "Procedia - Social and Behavioral Sciences",
volume = "64",
pages = "626 - 632",
year = "2012",
note = "12 th International Educational Technology Conference - IETC 2012",
issn = "1877-0428",
doi = "https://doi.org/10.1016/j.sbspro.2012.11.073",
url = "http://www.sciencedirect.com/science/article/pii/S1877042812050501",
author = "Ching-I Wu",
keywords = "Human-computer interaction, eye-tracking, education, processing mode",
abstract = "The utilizing of interactive teaching and integrated application in technology has revolutionalized ways of teaching and learning. By making use of the interactive input and output devices that users are able to control the learning information from stem to stem. According to the research in Sander & McCormick (1987), it indicated that more than 80% that human beings manage to process cognitive information through visual operation. That is to say, the eye movement is an essential source of information in the cognitive processes. In combination with the human-computer interaction and eye movement processes, only if the eye obtain the correct teaching message which will generate the greatest effect for the content delivery in the digital learning industry. Therefore, the experiences of human-computer interaction and the eye tracking technology have been widely used in usability testing for different digital learning contents. This article will review the representative theory of interactive behaviour, eye tracking technologies and related studies. In addition, we will also discuss teaching operation and other basic data analysis in the use of eye tracking technology."
}
@article{PASCHKE20121844,
title = "Mirrored or identical — Is the role of visual perception underestimated in the mental rotation process of 3D-objects?: A combined fMRI-eye tracking-study",
journal = "Neuropsychologia",
volume = "50",
number = "8",
pages = "1844 - 1851",
year = "2012",
issn = "0028-3932",
doi = "https://doi.org/10.1016/j.neuropsychologia.2012.04.010",
url = "http://www.sciencedirect.com/science/article/pii/S0028393212001613",
author = "Kerstin Paschke and Kirsten Jordan and Torsten Wüstenberg and Jürgen Baudewig and Jürgen Leo Müller",
keywords = "Mental rotation, Visual perception, Functional magnetic resonance imaging, Eye-tracking",
abstract = "The mental-rotation task is a well known research paradigm to examine cognitive processes of mental imaging and mental manipulation (Shepard & Metzler, 1971). So far, research has been focused on stimulus orientation which indicates the necessary amount of mental rotation. But little attention has been paid to stimulus parity, specifically if and how identical and mirror-reversed stimuli are processed differently. We wanted to fill this gap by combining performance, eye-tracking, and neurofunctional measures using pairwise presented three-dimensional Shepard–Metzler stimuli in a self-paced event-related fMRI design. Based on our results we tried to reason at which stage of the mental-rotation process the treatment of mirrored and identical stimuli begins to diverge. As a common finding, response times for tasks with mirrored stimuli were longer compared to tasks with identical stimuli reflecting their higher cognitive demand. Moreover, we observed smaller saccade amplitudes for mirrored than for identical stimuli suggesting a smaller functional field of view during stimulus perception. The eye-movement results were complemented by our neurofunctional findings. Here, the processing of mirrored stimuli led to less activation in parts of the early visual cortex that respond to the visual periphery than the processing of identical figures. This activation difference remained after eye-movement-associated activations had been excluded. We explain our findings by stimulus-parity-induced differences in saliency maps built up to enhance perception. Thus, the treatment of mirrored and identical stimuli begins to diverge very early in the mental-rotation process and is associated with differences in visual processing."
}
@article{AVERY2018321,
title = "HPV vaccination campaign fear visuals: An eye-tracking study exploring effects of visual attention and type on message informative value, recall, and behavioral intentions",
journal = "Public Relations Review",
volume = "44",
number = "3",
pages = "321 - 330",
year = "2018",
issn = "0363-8111",
doi = "https://doi.org/10.1016/j.pubrev.2018.02.005",
url = "http://www.sciencedirect.com/science/article/pii/S0363811117301595",
author = "Elizabeth Johnson Avery and Sejin Park",
keywords = "Public relations, Health campaigns, Visual effects, Fear appeals, Eye-tracking, HPV vaccination",
abstract = "HPV is the most common sexually transmitted disease, and there are alarming global disparities in cervical cancer and HPV vaccination uptake (CDC, 2016a). To inform HPV vaccination public health campaigns, an experiment with a psychophysiological measure (eye-tracking) explores the effects of visual attention to vaccination messages on message recall, informative value, and behavioral intentions. Results indicate 1) visual type affects recall and informative value of vaccination messages as well as intentions to vaccinate; 2) visual attention is negatively related to message recall only when a non-fear visual is used; and 3) visual attention predicts intent to vaccinate only when a fear visual is utilized. These results suggest the use of fear appeals in health, crisis, and risk public relations campaigns may promote performance of recommended safeguarding behaviors."
}
@article{GONZALEZVIEJO201872,
title = "Robotics and computer vision techniques combined with non-invasive consumer biometrics to assess quality traits from beer foamability using machine learning: A potential for artificial intelligence applications",
journal = "Food Control",
volume = "92",
pages = "72 - 79",
year = "2018",
issn = "0956-7135",
doi = "https://doi.org/10.1016/j.foodcont.2018.04.037",
url = "http://www.sciencedirect.com/science/article/pii/S0956713518302007",
author = "Claudia Gonzalez Viejo and Sigfredo Fuentes and Kate Howell and Damir Torrico and Frank R. Dunshea",
keywords = "Biometrics, Beer quality, Artificial intelligence, Visual consumer test, Artificial neural networks",
abstract = "Foam-related parameters greatly influence other sensory attributes of beer such as aromas, flavors and mouthfeel; therefore, the visual assessment of beers is one of the most important quality traits, since it creates the first impression of consumers in determining the willingness to taste the product and perceived quality. Sensory analysis has been extensively used to assess consumers acceptability; however, this can only obtain their self-reported conscious responses. Therefore, biometric techniques have been used to assess the subconscious responses, which provide more information from consumers when integrated with sensory evaluation questionnaires. In this study, non-invasive biometrics along with a sensory questionnaire were used to assess consumers perception to visual attributes of 15 beers from pouring videos obtained using the RoboBEER (automatic robotic pourer). The sensory session was conducted with 30 participants using an integrated camera system, which consists of an infrared thermal camera and video recording coupled with a Bio-sensory computer application (App) and an eye tracking device. Objective physical parameters from beer pouring were obtained using the RoboBEER and computer vision algorithms. Results from the Just About Right (JAR) and acceptance tests showed that consumers preferred top fermentation beers, which have a medium foam height and stability, and tend to highly penalize bottom fermentation beers with lower foam. The principal components analysis explained a total of 52% of data variability. A correlation matrix was developed to assess significant correlations between the conscious, subconscious and physical data such as the positive correlation between perceived quality and heart rate, and the negative correlation between foam stability liking and foam drainage. Furthermore, an artificial neural network model (ANN) with 82% accuracy was developed using 28 parameters from the subconscious and objective physical data as inputs to classify beers per participant according to their level of liking of foam height (low and high). The combined use of these techniques showed to be an accurate and rapid tool to assess the visual sensory perception of beers based on the RoboBEER and biometric outputs from consumers with significant potential applications for fast screening within the beer industry."
}
@article{CHEVAL2016825,
title = "Homophobia: An Impulsive Attraction to the Same Sex? Evidence From Eye-Tracking Data in a Picture-Viewing Task",
journal = "The Journal of Sexual Medicine",
volume = "13",
number = "5",
pages = "825 - 834",
year = "2016",
issn = "1743-6095",
doi = "https://doi.org/10.1016/j.jsxm.2016.02.165",
url = "http://www.sciencedirect.com/science/article/pii/S1743609516003192",
author = "Boris Cheval and Remi Radel and Emmanuelle Grob and Paolo Ghisletta and Francesco Bianchi-Demicheli and Julien Chanal",
keywords = "Homophobia, Impulsive Approach Tendencies, Viewing-Time, Eye-Tracking",
abstract = "Introduction
Some models suggest that homophobia can be explained as a denied attraction toward same-sex individuals. While it has been found that homophobic men have same-sex attraction, these results are not consistent.
Aim
This study drew on the dual-process models to test the assumption that sexual interest in homosexual cues among men high in homophobia will depend on their specific impulses toward homosexual-related stimuli.
Methods
Heterosexual men (N = 38) first completed a scale measuring their level of homonegativity. Then, they performed a manikin task to evaluate their impulsive approach tendencies toward homosexual stimuli (IAHS).
Main outcomes measures
A picture-viewing task was performed with simultaneous eye-tracking recording to assess participants' viewing time of the visual area of interest (i.e., face and body).
Results
IAHS positively predicted the viewing time of homosexual photographs among men with a high score of homonegativity. Men with a high homonegativity score looked significantly longer at homosexual than at heterosexual photographs but only when they had a high IAHS.
Conclusion
These findings confirm the importance of considering the variability in impulsive processes to understand why some (but not all) men high in homophobia have homosexual interest. These findings reinforce the theoretical basis for elaborating a dual-process model for behaviors in the sexual context."
}
@article{HOCHSTADT2009991,
title = "Set-shifting and the on-line processing of relative clauses in Parkinson's disease: Results from a novel eye-tracking method",
journal = "Cortex",
volume = "45",
number = "8",
pages = "991 - 1011",
year = "2009",
note = "Special Issue on "Parkinson's Disease, Language and Cognition"",
issn = "0010-9452",
doi = "https://doi.org/10.1016/j.cortex.2009.03.010",
url = "http://www.sciencedirect.com/science/article/pii/S0010945209001129",
author = "Jesse Hochstadt",
keywords = "Syntax comprehension, Executive function, Context, Sequencing, Basal ganglia, Verbal working memory",
abstract = "Past research indicates that in Parkinson's disease (PD), set-shifting deficits cause impaired comprehension of sentences containing restrictive relative clauses (RCs). Some research also suggests that verbal working memory deficits impair comprehension of long-distance (LD) dependencies in sentences with center-embedded RCs. To test whether these deficits impair comprehension by affecting on-line processing, we tracked patients' eye movements as they matched pictures with sentences with final- or center-embedded RCs (e.g., The queen was kicking the cook who was fat, The queen who was kicking the cook was thin) and active or passive verbs. Decreases in looks to distracters ruled out at the transitive verb (e.g., a cook kicking a queen) and the adjective (a fat queen kicking a thin cook) reflected how effective processing was at those points. Though patients showed greater difficulty comprehending center-embedded and passive sentences, set-shifting errors correlated with comprehension of all sentences. Consistent with this, patients with poorer comprehension exhibited impaired on-line processing of both center-embedded and final RCs (for which comprehension was better due to their grammatical simplicity), and these effects correlated with set-shifting errors. We consider two possible explanations for this apparently general RC-processing deficit. First, because RCs are infrequent, set-shifting may be needed to override the processor's expectations for higher-frequency structures. Second, because restrictive RCs typically refer to information already in the discourse context, set-shifting may be needed to redirect attention from linguistic foreground to background information. Eye-tracking data indicated no difficulty processing LD dependencies; correlations of verbal working memory with comprehension of passive and center-embedded sentences may reflect off-line use of memory. In trials with passive verbs, patients looked toward the verb distracter before even processing the verb. This effect was larger than that previously seen for young participants, suggesting that PD may amplify a normal bias to assume the subject noun is the agent."
}
@article{HUA2015917,
title = "On semantic-instructed attention: From video eye-tracking dataset to memory-guided probabilistic saliency model",
journal = "Neurocomputing",
volume = "168",
pages = "917 - 929",
year = "2015",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2015.05.033",
url = "http://www.sciencedirect.com/science/article/pii/S0925231215006931",
author = "Yan Hua and Meng Yang and Zhicheng Zhao and Renlai Zhou and Anni Cai",
keywords = "Semantic-instructed viewing, Eye-tracking, Top-down attention, Memory, Saliency model",
abstract = "Visual attention influenced by example images and predefined targets are widely studied in both cognitive and computer vision fields. Nevertheless, semantics, known to be related to high-level human perception, have a great influence on top-down attention process. Understanding the impact of semantics on visual attention is beneficial for providing psychological and computational guidance on many real-world applications, e.g., semantic video retrieval. In this paper, we intend to study the mechanisms of attention control and computational modeling of saliency detection for dynamic scenes under semantic-instructed viewing conditions. We start our study by establishing a dataset REMoT, the first video eye-tracking dataset with semantic instructions to our best knowledge. We collect the fixation locations of subjects when they are given four kinds of instructions with different levels of noise. The fixation behavior analysis on REMoT shows that the process of semantic-instructed attention can be explained with long-term memory and short-term memory of human visual system. Inspired by this finding, we propose a memory-guided probabilistic model to exploit the semantic-instructed top-down attention. The experience of attention distribution to similar scenes in long-term memory is simulated by linear mapping of global scene features. An HMM-like conditional probabilistic chain is constructed to model the dynamic fixation patterns among neighboring frames in short-term memory. Then, a generative saliency model is constructed which probabilistically combines the top-down and a bottom-up modules for semantic-instructed saliency detection. We compare our model to state-of-the-art models on REMoT and a widely used dataset RSD. Experimental results show that our model achieves significant improvements not only in predicting visual attention under correct instructions, but also in detecting saliency for free viewing."
}
@article{DOTAN20191058,
title = "Track It to Crack It: Dissecting Processing Stages with Finger Tracking",
journal = "Trends in Cognitive Sciences",
volume = "23",
number = "12",
pages = "1058 - 1070",
year = "2019",
issn = "1364-6613",
doi = "https://doi.org/10.1016/j.tics.2019.10.002",
url = "http://www.sciencedirect.com/science/article/pii/S1364661319302372",
author = "Dror Dotan and Pedro Pinheiro-Chagas and Fosca Al Roumi and Stanislas Dehaene",
keywords = "trajectory tracking, serial versus parallel processing, decision-making",
abstract = "A central goal in cognitive science is to parse the series of processing stages underlying a cognitive task. A powerful yet simple behavioral method that can resolve this problem is finger trajectory tracking: by continuously tracking the finger position and speed as a participant chooses a response, and by analyzing which stimulus features affect the trajectory at each time point during the trial, we can estimate the absolute timing and order of each processing stage, and detect transient effects, changes of mind, serial versus parallel processing, and real-time fluctuations in subjective confidence. We suggest that trajectory tracking, which provides considerably more information than mere response times, may provide a comprehensive understanding of the fast temporal dynamics of cognitive operations."
}
@incollection{WONG2014187,
title = "8 - E-commerce Websites",
editor = "Jennifer Romano Bergstrom and Andrew Jonathan Schall",
booktitle = "Eye Tracking in User Experience Design",
publisher = "Morgan Kaufmann",
address = "Boston",
pages = "187 - 216",
year = "2014",
isbn = "978-0-12-408138-3",
doi = "https://doi.org/10.1016/B978-0-12-408138-3.00008-X",
url = "http://www.sciencedirect.com/science/article/pii/B978012408138300008X",
author = "Wilkey Wong and Mike Bartels and Nina Chrobot",
keywords = "cross-selling, e-commerce, online transactions, PDP, performance metrics, product display page, user experience metrics",
abstract = "This chapter is an examination of how eye tracking can be used to measure the performance of transactional online experiences. It explains how eye-tracking metrics can inform our understanding of attentional distribution, element viewing, and perceptual flow. These elements, combined with other data collection and analysis techniques referenced in the chapter provide insights into the performance of e-commerce components such as cross-selling opportunities and product display pages."
}
@article{FIEDLER2013272,
title = "Social Value Orientation and information search in social dilemmas: An eye-tracking analysis",
journal = "Organizational Behavior and Human Decision Processes",
volume = "120",
number = "2",
pages = "272 - 284",
year = "2013",
note = "Social Dilemmas",
issn = "0749-5978",
doi = "https://doi.org/10.1016/j.obhdp.2012.07.002",
url = "http://www.sciencedirect.com/science/article/pii/S074959781200091X",
author = "Susann Fiedler and Andreas Glöckner and Andreas Nicklisch and Stephan Dickert",
keywords = "Social Value Orientation, Information search, Process tracing, Cooperation, Information processing",
abstract = "Previous work has demonstrated that Social Value Orientation (SVO) is related to cooperative behavior in social dilemmas. However, little is known concerning the underlying processes. In two eye-tracking studies investigating decisions in money allocation tasks (Experiment 1) and Public Good Dilemmas (Experiment 2), we show that differences in SVO are accompanied by consistent differences in information search. Decision time, number of fixations, the proportion of inspected information, the degree of attention towards the others’ payoffs, and the number of transitions from and towards others’ payoffs gradually increase with absolute SVO deviation from a pure selfish orientation. Overall these effects seem to be similar for individuals caring positively (i.e., cooperative) or negatively (i.e., competitive) about others. The fact that changes are gradual instead of abrupt indicates that differences in SVO seem to be related to gradual changes in weights given to outcomes for self and others."
}
@article{BARDEEN201767,
title = "A longitudinal examination of the role of attentional control in the relationship between posttraumatic stress and threat-related attentional bias: An eye-tracking study",
journal = "Behaviour Research and Therapy",
volume = "99",
pages = "67 - 77",
year = "2017",
issn = "0005-7967",
doi = "https://doi.org/10.1016/j.brat.2017.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S0005796717301936",
author = "Joseph R. Bardeen and Thomas A. Daniel",
keywords = "Eye tracking, Attentional bias, Attentional control, Inhibition, Longitudinal, Arousal",
abstract = "The purpose of the present study was to use eye-tracking technology to (a) show that attentional control can be used to reduce attentional bias to threat (ABT) among those with higher levels of posttraumatic stress (PTS) symptoms, (b) identify the specific attentional control (AC) processes (i.e., inhibition, shifting, working memory updating) that account for this effect, and (c) determine the short- (sympathetic nervous system reactivity) and long-term effects (PTS symptoms) of using attentional control in this manner. At Time 1 (T1), participants (N = 116 trauma exposed) completed self-report measures, an eye-tracking task assessing ABT, and behavioral measures assessing cognitive processes. A subsample (n = 49) completed an online follow-up assessment (T2). AC at T1 moderated the PTS-ABT relationship. Inhibitory ability appears to be driving this effect. Those with higher PTS symptoms and higher AC at T1, who spent less time attending to threat stimuli and had the lowest sympathetic response, had the highest levels of PTS symptoms at T2. Findings suggest that the habitual use of AC (especially inhibition) to shift attention from threat to neutral stimuli may alleviate distress in the short-term for those with higher PTS symptoms, but maintain, and perhaps exacerbate, PTS symptoms over longer periods."
}
@article{KUKONA201123,
title = "The time course of anticipatory constraint integration",
journal = "Cognition",
volume = "119",
number = "1",
pages = "23 - 42",
year = "2011",
issn = "0010-0277",
doi = "https://doi.org/10.1016/j.cognition.2010.12.002",
url = "http://www.sciencedirect.com/science/article/pii/S0010027710002933",
author = "Anuenue Kukona and Shin-Yi Fang and Karen A. Aicher and Helen Chen and James S. Magnuson",
keywords = "Sentence processing, Thematic roles, Anticipation, Eye tracking",
abstract = "Several studies have demonstrated that as listeners hear sentences describing events in a scene, their eye movements anticipate upcoming linguistic items predicted by the unfolding relationship between scene and sentence. While this may reflect active prediction based on structural or contextual expectations, the influence of local thematic priming between words has not been fully examined. In Experiment 1, we presented verbs (e.g., arrest) in active (Subject–Verb–Object) sentences with displays containing verb-related patients (e.g., crook) and agents (e.g., policeman). We examined patient and agent fixations following the verb, after the agent role had been filled by another entity, but prior to bottom-up specification of the object. Participants were nearly as likely to fixate agents “anticipatorily” as patients, even though the agent role was already filled. However, the patient advantage suggested simultaneous influences of both local priming and active prediction. In Experiment 2, using passive sentences (Object–Verb–Subject), we found stronger, but still graded influences of role prediction when more time elapsed between verb and target, and more syntactic cues were available. We interpret anticipatory fixations as emerging from constraint-based processes that involve both non-predictive thematic priming and active prediction."
}
@article{GLOCKNER2014641,
title = "What is adaptive about adaptive decision making? A parallel constraint satisfaction account",
journal = "Cognition",
volume = "133",
number = "3",
pages = "641 - 666",
year = "2014",
issn = "0010-0277",
doi = "https://doi.org/10.1016/j.cognition.2014.08.017",
url = "http://www.sciencedirect.com/science/article/pii/S0010027714001747",
author = "Andreas Glöckner and Benjamin E. Hilbig and Marc Jekel",
keywords = "Adaptive cognition, Parallel constraint satisfaction, Adaptive decision making, Probabilistic inferences, Decision strategies",
abstract = "There is broad consensus that human cognition is adaptive. However, the vital question of how exactly this adaptivity is achieved has remained largely open. Herein, we contrast two frameworks which account for adaptive decision making, namely broad and general single-mechanism accounts vs. multi-strategy accounts. We propose and fully specify a single-mechanism model for decision making based on parallel constraint satisfaction processes (PCS-DM) and contrast it theoretically and empirically against a multi-strategy account. To achieve sufficiently sensitive tests, we rely on a multiple-measure methodology including choice, reaction time, and confidence data as well as eye-tracking. Results show that manipulating the environmental structure produces clear adaptive shifts in choice patterns – as both frameworks would predict. However, results on the process level (reaction time, confidence), in information acquisition (eye-tracking), and from cross-predicting choice consistently corroborate single-mechanisms accounts in general, and the proposed parallel constraint satisfaction model for decision making in particular."
}
@article{ZHOU201941,
title = "Eye movements and visual discomfort when viewing stereoscopic 3D content",
journal = "Digital Signal Processing",
volume = "91",
pages = "41 - 53",
year = "2019",
note = "Quality Perception of Advanced Multimedia Systems",
issn = "1051-2004",
doi = "https://doi.org/10.1016/j.dsp.2018.12.008",
url = "http://www.sciencedirect.com/science/article/pii/S1051200418308893",
author = "Jun Zhou and Ling Wang and Haibing Yin and Alan C. Bovik",
keywords = "Stereoscopic 3D, Eye-tracking, Visual discomfort, Eye movement features",
abstract = "The visual brain fuses the left and right images projected onto the two eyes from a stereoscopic 3D (S3D) display, perceives parallax, and rebuilds a sense of depth. In this process, the eyes adjust vergence and accommodation to adapt to the depths and parallax of the points they gazed at. Conflicts between accommodation and vergence when viewing S3D content potentially lead to visual discomfort. A variety of approaches have been taken towards understanding the perceptual bases of discomfort felt when viewing S3D, including extreme disparities or disparity gradients, negative disparities, dichoptic presentations, and so on. However less effort has been applied towards understanding the role of eye movements as they relate to visual discomfort when viewing S3D. To study eye movements in the context of S3D viewing discomfort, a Shifted-S3D-Image-Database (SSID) is constructed using 11 original nature scene S3D images and their 6 shifted versions. We conducted eye-tracking experiments on humans viewing S3D images in SSID while simultaneously collecting their judgments of experienced visual discomfort. From the collected eye-tracking data, regions of interest (ROIs) were extracted by kernel density estimation using the fixation data, and an empirical formula fitted between the disparities of salient objects marked by the ROIs and the mean opinion scores (MOS). Finally, eye-tracking data was used to analyze the eye movement characteristics related to S3D image quality. Fifteen eye movement features were extracted, and a visual discomfort predication model learned using a support vector regressor (SVR). By analyzing the correlations between features and MOS, we conclude that angular disparity features have a strong correlation with human judgments of discomfort."
}
@article{LOTZ2019532,
title = "Response times and gaze behavior of truck drivers in time critical conditional automated driving take-overs",
journal = "Transportation Research Part F: Traffic Psychology and Behaviour",
volume = "64",
pages = "532 - 551",
year = "2019",
issn = "1369-8478",
doi = "https://doi.org/10.1016/j.trf.2019.06.008",
url = "http://www.sciencedirect.com/science/article/pii/S1369847818302559",
author = "Alexander Lotz and Nele Russwinkel and Enrico Wohlfarth",
keywords = "Conditional autonomous driving, Driving simulator, Non-driving related tasks, CAD duration, Take-over situations, Truck",
abstract = "The desire to enable conditional automated driving (CAD) in the near future, entails the challenge to manage drivers’ safe transitions from automation back to manual control. Several factors have been considered in recent years in the passenger car context, while the truck has largely been disregarded. For the first time take-over behavior of heavy-duty truck drivers in time critical take-overs is considered in CAD research. This study analyzes the effect of non-driving related tasks, CAD duration, take-over situations and number of take-overs on reaction times of truck drivers. Gaze behavior was tracked with a remote eye-tracker; reaction times and driver interaction during CAD drives was recorded and analyzed. Two different non-driving related tasks were presented in nine unique take-over situations, while also controlling for the duration of CAD. Contrary to assumption, no influence of non-driving related tasks or CAD duration on reaction times is found. Notably, different reaction times are recorded due to the nine unique take-over situations. Finally, it is shown that our take-over times decrease over the course of the experiment and are far lower than other published reaction times (M = 1.35 s) in the passenger car context. The findings are discussed and implications with regard to other published studies are drawn."
}
@article{GRAY2004359,
title = "Soft constraints in interactive behavior: the case of ignoring perfect knowledge in-the-world for imperfect knowledge in-the-head",
journal = "Cognitive Science",
volume = "28",
number = "3",
pages = "359 - 382",
year = "2004",
issn = "0364-0213",
doi = "https://doi.org/10.1016/j.cogsci.2003.12.001",
url = "http://www.sciencedirect.com/science/article/pii/S0364021304000059",
author = "Wayne D. Gray and Wai-Tat Fu",
keywords = "Interactive behavior, Rational analysis, Knowledge in-the-world, Human–computer interaction, Embodied cognition, Embodiment level, Soft constraints, Bounded rationality, Interface design, Information access, Eye tracking",
abstract = "Constraints and dependencies among the elements of embodied cognition form patterns or microstrategies of interactive behavior. Hard constraints determine which microstrategies are possible. Soft constraints determine which of the possible microstrategies are most likely to be selected. When selection is non-deliberate or automatic the least effort microstrategy is chosen. In calculating the effort required to execute a microstrategy each of the three types of operations, memory retrieval, perception, and action, are given equal weight; that is, perceptual-motor activity does not have a privileged status with respect to memory. Soft constraints can work contrary to the designer’s intentions by making the access of perfect knowledge in-the-world more effortful than the access of imperfect knowledge in-the-head. These implications of soft constraints are tested in two experiments. In experiment 1 we varied the perceptual-motor effort of accessing knowledge in-the-world as well as the effort of retrieving items from memory. In experiment 2 we replicated one of the experiment 1 conditions to collect eye movement data. The results suggest that milliseconds matter. Soft constraints lead to a reliance on knowledge in-the-head even when the absolute difference in perceptual-motor versus memory retrieval effort is small, and even when relying on memory leads to a higher error rate and lower performance. We discuss the implications of soft constraints for routine interactive behavior, accounts of embodied cognition, and tool and interface design."
}
@article{SUI2020104077,
title = "The timing of gaze-contingent decision prompts influences risky choice",
journal = "Cognition",
volume = "195",
pages = "104077",
year = "2020",
issn = "0010-0277",
doi = "https://doi.org/10.1016/j.cognition.2019.104077",
url = "http://www.sciencedirect.com/science/article/pii/S0010027719302501",
author = "Xiao-Yang Sui and Hong-Zhi Liu and Li-Lin Rao",
keywords = "Risky choice, Eye tracking, Gaze-contingent manipulation, Dynamic",
abstract = "Risky decisions are ubiquitous in daily life and are central to human behavior, but little attention has been devoted to exploring whether risky choice can be influenced by gaze direction. In the current study, we used gaze-contingent manipulation to manipulate an individual’s gaze while he/she decided between two risky options, and we examined whether risky decisions could be biased toward a randomly determined target. We found that participants’ risky choices were biased toward a randomly determined target when they were manipulated to gaze longer at the target option (Study 1, N=37; Study 3, N=40) or at the target outcome dimension (Study 2, N=37). We also found that both the relative time advantage and the location of the last fixation mediated the effect of the gaze-contingent manipulation on risky choice in the valid trials. However, the mediation effects of the relative time advantage and the location of the last fixation were not significant when timed-out trials were included in Studies 2 and 3, indicating that the gaze-contingent manipulation did not effectively enforce a bias toward attending to a particular stimulus through eye gaze in all trials. Future work is needed to improve the effectiveness of the gaze-contingent prompt procedure."
}
@article{DEHAIS2012588,
title = "Cognitive conflict in human–automation interactions: A psychophysiological study",
journal = "Applied Ergonomics",
volume = "43",
number = "3",
pages = "588 - 595",
year = "2012",
issn = "0003-6870",
doi = "https://doi.org/10.1016/j.apergo.2011.09.004",
url = "http://www.sciencedirect.com/science/article/pii/S0003687011001311",
author = "Frédéric Dehais and Mickaël Causse and François Vachon and Sébastien Tremblay",
keywords = "Human–automation conflicts, Robotic, Perseveration behavior, Attentional shrinking, Eye tracking, Physiological measurement",
abstract = "The review of literature in sociology and distributed artificial intelligence reveals that the occurrence of conflict is a remarkable precursor to the disruption of multi-agent systems. The study of this concept could be applied to human factors concerns, as man-system conflict appears to provoke perseveration behavior and to degrade attentional abilities with a trend to excessive focus. Once entangled in such conflicts, the human operator will do anything to succeed in his current goal even if it jeopardizes the mission. In order to confirm these findings, an experimental setup, composed of a real unmanned ground vehicle, a ground station is developed. A scenario involving an authority conflict between the participants and the robot is proposed. Analysis of the effects of the conflict on the participants’ cognition and arousal is assessed through heart-rate measurement (reflecting stress level) and eye-tracking techniques (index of attentional focus). Our results clearly show that the occurrence of the conflict leads to perseveration behavior and can induce higher heart rate as well as excessive attentional focus. These results are discussed in terms of task commitment issues and increased arousal. Moreover, our results suggest that individual differences may predict susceptibility to perseveration behavior."
}
@article{SMITH201428,
title = "Literacy effects on language and vision: Emergent effects from an amodal shared resource (ASR) computational model",
journal = "Cognitive Psychology",
volume = "75",
pages = "28 - 54",
year = "2014",
issn = "0010-0285",
doi = "https://doi.org/10.1016/j.cogpsych.2014.07.002",
url = "http://www.sciencedirect.com/science/article/pii/S0010028514000553",
author = "Alastair C. Smith and Padraic Monaghan and Falk Huettig",
keywords = "Literacy, Computational modelling, Visual attention, Speech processing, Eye movements, Visual world paradigm",
abstract = "Learning to read and write requires an individual to connect additional orthographic representations to pre-existing mappings between phonological and semantic representations of words. Past empirical results suggest that the process of learning to read and write (at least in alphabetic languages) elicits changes in the language processing system, by either increasing the cognitive efficiency of mapping between representations associated with a word, or by changing the granularity of phonological processing of spoken language, or through a combination of both. Behavioural effects of literacy have typically been assessed in offline explicit tasks that have addressed only phonological processing. However, a recent eye tracking study compared high and low literate participants on effects of phonology and semantics in processing measured implicitly using eye movements. High literates’ eye movements were more affected by phonological overlap in online speech than low literates, with only subtle differences observed in semantics. We determined whether these effects were due to cognitive efficiency and/or granularity of speech processing in a multimodal model of speech processing – the amodal shared resource model (ASR, Smith, Monaghan, & Huettig, 2013a,b). We found that cognitive efficiency in the model had only a marginal effect on semantic processing and did not affect performance for phonological processing, whereas fine-grained versus coarse-grained phonological representations in the model simulated the high/low literacy effects on phonological processing, suggesting that literacy has a focused effect in changing the grain-size of phonological mappings."
}
@article{BREEN2014922,
title = "An evaluation of eye tracking technology in the assessment of 12 lead electrocardiography interpretation",
journal = "Journal of Electrocardiology",
volume = "47",
number = "6",
pages = "922 - 929",
year = "2014",
issn = "0022-0736",
doi = "https://doi.org/10.1016/j.jelectrocard.2014.08.008",
url = "http://www.sciencedirect.com/science/article/pii/S0022073614003148",
author = "Cathal J. Breen and Raymond Bond and Dewar Finlay",
keywords = "Eye tracking, ECG, Pedagogy, Assessment, Healthcare Science",
abstract = "Introduction
This study investigated eye tracking technology for 12 lead electrocardiography interpretation to Healthcare Scientist students.
Methods
Participants (n=33) interpreted ten 12 lead ECG recordings and randomized to receive objective individual appraisal on their efforts either by traditional didactic format or by eye tracker software.
Results
One hundred percent of participants reported the experience positively at improving their ECG interpretation competency. ECG analysis time ranged between 13.2 and 59.5s. The rhythm strip was the most common lead studied and fixated on for the longest duration (mean 9.9s). Lead I was studied for the shortest duration (mean 0.25s). Feedback using eye tracking data during ECG interpretation did not produce any significant variation between the assessment marks of the study and the control groups (p=0.32).
Conclusions
Although the hypothesis of this study was rejected active teaching and early feedback practices are recommended within this discipline."
}
@article{SHARMA201643,
title = "Eye gaze movement studies of control room operators: A novel approach to improve process safety",
journal = "Computers & Chemical Engineering",
volume = "85",
pages = "43 - 57",
year = "2016",
issn = "0098-1354",
doi = "https://doi.org/10.1016/j.compchemeng.2015.09.012",
url = "http://www.sciencedirect.com/science/article/pii/S0098135415003075",
author = "Chandresh Sharma and Punitkumar Bhavsar and Babji Srinivasan and Rajagopalan Srinivasan",
keywords = "Cognitive engineering, Human error, Eye tracking, Process safety",
abstract = "Process industries continue to suffer from accidents despite significant regulatory intervention since the mid-1980s. Human error is widely considered to be the major cause for most accidents today. Detailed analysis of various incidents indicates that reduced staffing levels in control rooms and inadequate operator training with complex automation strategies as common reasons for human errors. Therefore, there is a need to develop deeper understanding of human errors as well as strategies to prevent them. However, similar to hardware failures, traditionally human error has been quantified using likelihood approaches; this viewpoint abnegates the role of the cognitive abilities of the operators. Recent studies in other safety critical domains (aviation, health-care) show that operator's level of situation awareness as inferred by eye tracking is a good online indicator of human error. In this work, a novel attempt is made to understand the behavior of the operator in a typical chemical plant control room using the information obtained from eye tracker. Experimental studies conducted on 72 participants reveal that fixation patterns contain signatures about the operators learning and awareness at various situations. Implications of these findings on human error in process plant operations them are discussed."
}
@article{AGRAFIOTIS2006531,
title = "A perceptually optimised video coding system for sign language communication at low bit rates",
journal = "Signal Processing: Image Communication",
volume = "21",
number = "7",
pages = "531 - 549",
year = "2006",
issn = "0923-5965",
doi = "https://doi.org/10.1016/j.image.2006.02.003",
url = "http://www.sciencedirect.com/science/article/pii/S0923596506000142",
author = "Dimitris Agrafiotis and Nishan Canagarajah and David R. Bull and Jim Kyle and Helen Seers and Matthew Dye",
keywords = "Sign language video coding, Eye tracking, Foveated video coding, Rate control, H.264",
abstract = "The ability to communicate remotely through the use of video as promised by wireless networks and already practised over fixed networks, is for deaf people as important as voice telephony is for hearing people. Sign languages are visual–spatial languages and as such demand good image quality for interaction and understanding. In this paper, we first analyse the sign language viewer's eye-gaze, based on the results of an eye-tracking study that we conducted, as well as the video content involved in sign language person-to-person communication. Based on this analysis we propose a sign language video coding system using foveated processing, which can lead to bit rate savings without compromising the comprehension of the coded sequence or equivalently produce a coded sequence with higher comprehension value at the same bit rate. We support this claim with the results of an initial comprehension assessment trial of such coded sequences by deaf users. The proposed system constitutes a new paradigm for coding sign language image sequences at limited bit rates."
}