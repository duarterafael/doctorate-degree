@article{KODER2019,
title = "Children's metonymy comprehension: Evidence from eye-tracking and picture selection",
journal = "Journal of Pragmatics",
year = "2019",
issn = "0378-2166",
doi = "https://doi.org/10.1016/j.pragma.2019.07.007",
url = "http://www.sciencedirect.com/science/article/pii/S0378216618305174",
author = "Franziska Köder and Ingrid Lossius Falkum",
abstract = "In this paper we investigate children's processing and comprehension of metonymy, a type of figurative use of language where an object or individual is referred to via a salient property (e.g., The beard used to refer to a man with a big beard). We tested 126 children aged 3 to 8 years and an adult control group, using a novel methodology which combines an online (eye-tracking) and an offline (picture selection) measure. The results from the picture selection task replicate the findings of a U-shape reported in Falkum et al. (2017), with a better performance of 3-year-olds compared to 4- to-5-year-olds, who tend to prefer literal interpretations of target metonymic utterances. The gaze data, however, while also suggesting an early sensitivity to metonymy from the age of 3, show a continuous improvement of understanding with age. We discuss the results in the light of theoretical accounts of children's pragmatic development. We argue that eye-tracking is a ‘purer’ and cognitively less demanding measure of figurative language comprehension, which sheds new light on children's developing pragmatic competence."
}
@article{BONHAGE201533,
title = "Combined eye tracking and fMRI reveals neural basis of linguistic predictions during sentence comprehension",
journal = "Cortex",
volume = "68",
pages = "33 - 47",
year = "2015",
note = "Special issue: Prediction in speech and language processing",
issn = "0010-9452",
doi = "https://doi.org/10.1016/j.cortex.2015.04.011",
url = "http://www.sciencedirect.com/science/article/pii/S0010945215001355",
author = "Corinna E. Bonhage and Jutta L. Mueller and Angela D. Friederici and Christian J. Fiebach",
keywords = "Prediction, Language, Syntax, fMRI, Eye tracking",
abstract = "It is widely agreed upon that linguistic predictions are an integral part of language comprehension. Yet, experimental proof of their existence remains challenging. Here, we introduce a new predictive eye gaze reading task combining eye tracking and functional magnetic resonance imaging (fMRI) that allows us to infer the existence and timing of linguistic predictions via anticipatory eye-movements. Participants read different types of word sequences (i.e., regular sentences, meaningless jabberwocky sentences, non-word lists) up to the pre-final word. The final target word was displayed with a temporal delay and its screen position was dependent on the syntactic word category (nouns vs verbs). During the delay, anticipatory eye-movements into the correct target word area were indicative of linguistic predictions. For fMRI analysis, the predictive sentence conditions were contrasted to the non-word condition, with the anticipatory eye-movements specifying differences in timing across conditions. A conjunction analysis of both sentence conditions revealed the neural substrate of word category prediction, namely a distributed network of cortical and subcortical brain regions including language systems, basal ganglia, thalamus, and hippocampus. Direct contrasts between the regular sentence condition and the jabberwocky condition indicate that prediction of word category in meaningless jabberwocky sentences relies on classical left-hemispheric language systems involving Brodman's area 44/45 in the left inferior frontal gyrus, left superior temporal areas, and the dorsal caudate nucleus. Regular sentences, in contrast, allowed for the prediction of specific words. Word-specific predictions were specifically associated with more widely distributed temporal and parietal cortical systems, most prominently in the right hemisphere. Our results support the presence of linguistic predictions during sentence processing and demonstrate the validity of the predictive eye gaze paradigm for measuring syntactic and semantic aspects of linguistic predictions, as well as for investigating their neural substrates."
}
@article{GUERRA201743,
title = "Visually perceived spatial distance affects the interpretation of linguistically mediated social meaning during online language comprehension: An eye tracking reading study",
journal = "Journal of Memory and Language",
volume = "92",
pages = "43 - 56",
year = "2017",
issn = "0749-596X",
doi = "https://doi.org/10.1016/j.jml.2016.05.004",
url = "http://www.sciencedirect.com/science/article/pii/S0749596X16300304",
author = "Ernesto Guerra and Pia Knoeferle",
keywords = "Spatial distance, Social relations, Real-time semantic interpretation, Eye tracking",
abstract = "Recent experimental evidence suggests that spatial distance between two depicted objects in a non-referential visual context (i.e., when neither spatial distance nor the objects were mentioned) can rapidly and incrementally modulate the processing of semantic similarity between and-coordinated subject noun phrases in a sentence. The present research examines in three eye-tracking reading experiments whether these spatial distance effects extend to another abstract domain (social relations). More importantly, we assessed how precisely cognitive mechanisms link spatial information to sentence interpretation. To this end we varied between experiments the (order of the) constituents conveying information about social relations. We examined to what extent object distance effects on sentence interpretation depend upon a one-to-one mapping (relating objects to nouns). The eye-tracking record showed that spatial distance effects extended to abstract language other than semantic similarity and that these effects occurred as soon as the readers encountered linguistic information about social relations – independent of whether that information was conveyed by the (coordinated) nouns or by other constituents. Finally, the direction of the spatial distance effects seemed to depend on the activation level of the spatial distance representations, as determined by the constituent order. We discuss the contribution of these results to accounts of situated sentence comprehension."
}
@article{HANNE201583,
title = "Sentence comprehension and morphological cues in aphasia: What eye-tracking reveals about integration and prediction",
journal = "Journal of Neurolinguistics",
volume = "34",
pages = "83 - 111",
year = "2015",
issn = "0911-6044",
doi = "https://doi.org/10.1016/j.jneuroling.2014.12.003",
url = "http://www.sciencedirect.com/science/article/pii/S0911604414000864",
author = "Sandra Hanne and Frank Burchert and Ria De Bleser and Shravan Vasishth",
keywords = "Aphasia, Sentence comprehension deficits, Prediction, Eye-tracking, Online morpho-syntactic processing, Morphological cues",
abstract = "Comprehension of non-canonical sentences can be difficult for individuals with aphasia (IWA). It is still unclear to which extent morphological cues like case marking or verb inflection may influence IWA's performance or even help to override deficits in sentence comprehension. Until now, studies have mainly used offline methods to draw inferences about syntactic deficits and, so far, only a few studies have looked at online syntactic processing in aphasia. We investigated sentence processing in German-speaking IWA by combining an offline (sentence-picture matching) and an online (eye-tracking in the visual-world paradigm) method. Our goal was to determine whether IWA are capable of using inflectional morphology (number-agreement markers on verbs and case markers in noun phrases) as a cue to sentence interpretation. We report results of two visual-world experiments using German reversible SVO and OVS sentences. In each study, there were eight IWA and 20 age-matched controls. Experiment 1 targeted the role of unambiguous case morphology, while Experiment 2 looked at processing of number-agreement cues at the verb in case-ambiguous sentences. IWA showed deficits in using both types of morphological markers as a cue to non-canonical sentence interpretation and the results indicate that in aphasia, processing of case-marking cues is more vulnerable as compared to verb-agreement morphology. We ascribe this finding to the higher cue reliability of agreement cues, which renders them more resistant against impairments in aphasia. However, the online data revealed that IWA are in principle capable of successfully computing morphological cues, but the integration of morphological information is delayed as compared to age-matched controls. Furthermore, we found striking differences between controls and IWA regarding subject-before-object parsing predictions. While in case-unambiguous sentences IWA showed evidence for early subject-before-object parsing commitments, they exhibited no straightforward subject-first prediction in case-ambiguous sentences, although controls did so for ambiguous structures. IWA delayed their parsing decisions in case-ambiguous sentences until unambiguous morphological information, such as a subject-verb-number-agreement cue, was available. We attribute the results for IWA to deficits in predictive processes based on morpho-syntactic cues during sentence comprehension. The results indicate that IWA adopt a wait-and-see strategy and initiate prediction of upcoming syntactic structure only when unambiguous case or agreement cues are available."
}
@article{KIM20141609,
title = "Investigating graph comprehension in students with dyslexia: An eye tracking study",
journal = "Research in Developmental Disabilities",
volume = "35",
number = "7",
pages = "1609 - 1622",
year = "2014",
issn = "0891-4222",
doi = "https://doi.org/10.1016/j.ridd.2014.03.043",
url = "http://www.sciencedirect.com/science/article/pii/S0891422214001425",
author = "Sunjung Kim and Linda J. Lombardino and Wind Cowles and Lori J. Altmann",
keywords = "Graph comprehension, Developmental dyslexia, Eye tracking, College students",
abstract = "The purpose of this study was to examine graph comprehension in college students with developmental dyslexia. We investigated how graph types (line, vertical bar, and horizontal bar graphs), graphic patterns (single and double graphic patterns), and question types (point locating and comparison questions) differentially affect graph comprehension of students with and without dyslexia. Groups were compared for (1) reaction times for answering comprehension questions based on graphed data and (2) eye gaze times for specific graph subregions (x-axis, y-axis, pattern, legend, question, and answer). Dyslexic readers were significantly slower in their graph comprehension than their peers with group differences becoming more robust with the increasing complexity of graphs and tasks. In addition, dyslexic readers’ initial eye gaze viewing times for linguistic subregions (question and answer) and total viewing times for both linguistic (question and answer) and nonlinguistic (pattern) subregions were significantly longer than their control peers’ times. In spite of using elementary-level paragraphs for comprehension and simple graph forms, young adults with dyslexia needed more time to process linguistic and nonlinguistic stimuli. These findings are discussed relative to theories proposed to address fundamental processing deficits in individuals with dyslexia."
}
@article{CHERCHI2018454,
title = "Using eye track devices to understand individual decisions process in stated preferences experiments: an application to the choice of electric vehicles",
journal = "Transportation Research Procedia",
volume = "32",
pages = "454 - 463",
year = "2018",
note = "Transport Survey Methods in the era of big data:facing the challenges",
issn = "2352-1465",
doi = "https://doi.org/10.1016/j.trpro.2018.10.050",
url = "http://www.sciencedirect.com/science/article/pii/S2352146518302047",
author = "Elisabetta Cherchi",
keywords = "decision process, stated preferences, eye -traker, electric vehicles",
abstract = "In this paper we discuss the use of eye tracking technology to explore how individuals process information in a stated preference experiment. With the aim to add some evidences to a very short literature, we dig deeper into the analysis of the visual attention measures to discuss the heterogeneity of the visual process across participants, the attendance of attributes, the visual attention paid and potential trade-offs revealed by the consecutive fixations of pairs of attributes. Our results reinforce the evidence of significant heterogeneity in the individual’s visual process, and suggest that the analysis of the sequence of the information fixated can help understanding the decision process."
}
@article{MITTERERDALTOE2014459,
title = "Are fish products healthy? Eye tracking as a new food technology tool for a better understanding of consumer perception",
journal = "LWT - Food Science and Technology",
volume = "55",
number = "2",
pages = "459 - 465",
year = "2014",
issn = "0023-6438",
doi = "https://doi.org/10.1016/j.lwt.2013.10.013",
url = "http://www.sciencedirect.com/science/article/pii/S0023643813003563",
author = "Marina L. Mitterer-Daltoé and Maria I. Queiroz and Susana Fiszman and Paula Varela",
keywords = "Heatmaps, Fish, Consumers, Healthiness, Side vegetables",
abstract = "This study explored the use of eye tracking methods to investigate what underlies perceptions of the healthiness of different fish products. Fifteen different combinations of fish products (fillet, nuggets and fishburger) and side vegetables (lettuce, boiled potatoes, tempura and French fries) were presented as stimuli. Consumers had to answer the question: “In your opinion, how healthy is this dish?” Qualitatively, the results of the eye-tracking heatmaps revealed that the fishburger was an “attractive stimulus” as consumers focused more on a “new or different presentation” in order to decide whether the dish was more or less healthy. Quantitatively, the eye tracking metrics showed that first fixation was not an important variable for explaining the responses. Both the fish products and the side vegetables had a significant effect on the perception of healthiness, but their interaction did not. The findings suggested that unusual presentations and fried products were perceived as being less healthy. Eye tracking proved a successful tool for acquiring a better understanding of perceptions of some quality factors, opening the door to application of this technique in other studies that focus on the consumers' visual perception of food."
}
@article{TAKACS20181,
title = "How pictures in picture storybooks support young children’s story comprehension: An eye-tracking experiment",
journal = "Journal of Experimental Child Psychology",
volume = "174",
pages = "1 - 12",
year = "2018",
issn = "0022-0965",
doi = "https://doi.org/10.1016/j.jecp.2018.04.013",
url = "http://www.sciencedirect.com/science/article/pii/S0022096517306586",
author = "Zsofia K. Takacs and Adriana G. Bus",
keywords = "Picture storybooks, Dual coding, Eye-tracking, Kindergarten, Multimedia learning, Experiment",
abstract = "In a within-participant design, 41 children (mean age = 64 months, range = 50–81) listened to brief stories in four conditions. Written text was present on the screen in all conditions (similar to the typical storybook experience) but combined with other sources of information: (a) only oral narration, (b) oral narration and a picture that was congruent with the narration, (c) oral narration and an incongruent picture, and (d) only a picture but no oral narration. Children’s eye movements while looking at the screen were recorded with an eye-tracker. An important finding was that a congruent picture contributed substantially to children’s story retellings, more so than a picture that was incongruent with the narration. The eye-tracking data showed that children explored pictures in a way that they could maximally integrate the narration and the picture. Consequences for interactive reading and picture storybook format are discussed."
}
@article{MAJOONI201552,
title = "Scientific Visualizations Based on Integrated Model of Text and Picture Comprehension via Eye-tracking",
journal = "Procedia - Social and Behavioral Sciences",
volume = "176",
pages = "52 - 59",
year = "2015",
note = "International Educational Technology Conference, IETC 2014, 3-5 September 2014, Chicago, IL, USA",
issn = "1877-0428",
doi = "https://doi.org/10.1016/j.sbspro.2015.01.443",
url = "http://www.sciencedirect.com/science/article/pii/S1877042815004802",
author = "Azam Majooni and Mona Masood and Amir Akhavan",
keywords = "eye tracking, picture-text sequence, visualization, cognitive load",
abstract = "This study investigates the “color combination effect” and the “sequence of pictures and text effect” in the “Integrated Model of Text and Picture Comprehension” (ITPC) on the formation of the mental model and cognitive load in both desktop and mobile devices. These effects are studied using an experiment including scientific contexts with specific color combinations and different picture and text sequences. The participants of this experiment are graduate students from different fields of science in Universiti Sains Malaysia. Four tasks are assigned for each participant in each phase and every task includes a scientific context accompanied with visualization. After each task the participant is asked to answer a set of questions related to the context. Eye-tracking methods are adopted to record gaze data of the participants while reading each context. Analysis of the gaze data and the percentage of the correct answers to the questions indicate that the sequence of picture and text and use of color in the visualizations results in reduction of the cognitive load of the participants."
}
@article{VANENGEN201856,
title = "Eyes and ears: Using eye tracking and pupillometry to understand challenges to speech recognition",
journal = "Hearing Research",
volume = "369",
pages = "56 - 66",
year = "2018",
note = "Aging & Speech Communication 2017",
issn = "0378-5955",
doi = "https://doi.org/10.1016/j.heares.2018.04.013",
url = "http://www.sciencedirect.com/science/article/pii/S0378595517305282",
author = "Kristin J. Van Engen and Drew J. McLaughlin",
keywords = "Speech recognition, Eye tracking, Pupillometry, Listening effort",
abstract = "Although human speech recognition is often experienced as relatively effortless, a number of common challenges can render the task more difficult. Such challenges may originate in talkers (e.g., unfamiliar accents, varying speech styles), the environment (e.g. noise), or in listeners themselves (e.g., hearing loss, aging, different native language backgrounds). Each of these challenges can reduce the intelligibility of spoken language, but even when intelligibility remains high, they can place greater processing demands on listeners. Noisy conditions, for example, can lead to poorer recall for speech, even when it has been correctly understood. Speech intelligibility measures, memory tasks, and subjective reports of listener difficulty all provide critical information about the effects of such challenges on speech recognition. Eye tracking and pupillometry complement these methods by providing objective physiological measures of online cognitive processing during listening. Eye tracking records the moment-to-moment direction of listeners' visual attention, which is closely time-locked to unfolding speech signals, and pupillometry measures the moment-to-moment size of listeners' pupils, which dilate in response to increased cognitive load. In this paper, we review the uses of these two methods for studying challenges to speech recognition."
}
@article{KOORNNEEF2006445,
title = "On the use of verb-based implicit causality in sentence comprehension: Evidence from self-paced reading and eye tracking",
journal = "Journal of Memory and Language",
volume = "54",
number = "4",
pages = "445 - 465",
year = "2006",
issn = "0749-596X",
doi = "https://doi.org/10.1016/j.jml.2005.12.003",
url = "http://www.sciencedirect.com/science/article/pii/S0749596X05001464",
author = "Arnout W. Koornneef and Jos J.A. Van Berkum",
keywords = "Language comprehension, Interpersonal verbs, Implicit causality, Pronoun resolution, Immediacy, Prediction",
abstract = "In two experiments, we examined the recent claim (Stewart, Pickering, & Sanford, 2000) that verb-based implicit causality information is used during sentence–final clausal integration only. We did so by looking for mid-sentence reading delays caused by pronouns that are inconsistent with the bias of a preceding implicit causality verb (e.g., “David praised Linda because he…”). In a self-paced reading task, such pronouns immediately slowed down reading, at the two words immediately following the pronoun. In eye tracking, bias-inconsistent pronouns also immediately perturbed the reading process, as indexed by significant delays in various first pass measures at and shortly after the critical pronoun. Hence, readers can recruit verb-based implicit causality information in the service of comprehension rapidly enough to impact on the interpretation of a pronoun early in the subordinate clause. We take our results to suggest that implicit causality is used proactively, allowing readers to focus on, and perhaps even predict, who or what will be talked about next."
}
@article{VAISH201822,
title = "Desire understanding in 2-year-old children: An eye-tracking study",
journal = "Infant Behavior and Development",
volume = "52",
pages = "22 - 31",
year = "2018",
issn = "0163-6383",
doi = "https://doi.org/10.1016/j.infbeh.2018.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S0163638318301425",
author = "Amrisha Vaish and Robert Hepach and Tobias Grossmann",
keywords = "Desire understanding, Theory of mind, Eye tracking, Pupil dilation",
abstract = "‘Much research has investigated children’s understanding of others’ mental states in terms of beliefs, but far less is known about their understanding of others’ desires. To fill this gap, we used an eye-tracking paradigm to test 2-year-old children’s desire understanding by measuring their anticipatory looking behavior as well as changes in their internal arousal (i.e., changes in pupil dilation). Children showed increased pupil dilation when an adult reached for an object she had previously emoted negatively towards (the object incongruent with her desire). Children also showed weaker evidence of anticipating that an adult will reach for an object that she had emoted positively towards (the object congruent with her desire). These results suggest that 2-year-olds robustly recognize whether or not an individual’s actions are consistent with her desires, and seem to have a budding capacity to predict an individual’s actions based on her desires. Thus, by age 2 years, children are on their way to acquiring a robust desire psychology."
}
@article{LIU2014237,
title = "Using eye tracking to understand learners' reading process through the concept-mapping learning strategy",
journal = "Computers & Education",
volume = "78",
pages = "237 - 249",
year = "2014",
issn = "0360-1315",
doi = "https://doi.org/10.1016/j.compedu.2014.05.011",
url = "http://www.sciencedirect.com/science/article/pii/S0360131514001365",
author = "Pei-Lin Liu",
keywords = "Pedagogical issues, Evaluation methodologies, Teaching/learning strategies",
abstract = "The author used an eye-tracking methodology to examine the influence of the concept-mapping learning strategy on learners performing an English reading task. Eighty-six freshmen enrolled in English courses participated in this control-group pretest-posttest experiment, and received either traditional or concept-mapping instruction for learning English reading skills. A concept-mapping strategy was introduced to the learners in the experimental group to improve their reading ability. The results of independent t tests, in which eye-tracking data on fixation time and fixation path were used, indicated that the participants who received concept-mapping instruction exhibited shorter fixation times on the core concept and other content in the text, compared with the group that received traditional instruction. Moreover, the experimental group demonstrated longer and irregular rereading paths than the control group (CG) did. These results indicated that concept mapping serves as a reference to assist average readers to improve and to identify primary ideas that clarify the meaning of an article."
}
@article{ROBERTSON2019102708,
title = "Eye tracking reveals subtle spoken sentence comprehension problems in children with dyslexia",
journal = "Lingua",
volume = "228",
pages = "102708",
year = "2019",
issn = "0024-3841",
doi = "https://doi.org/10.1016/j.lingua.2019.06.009",
url = "http://www.sciencedirect.com/science/article/pii/S0024384119301020",
author = "Erin K. Robertson and Jennifer E. Gallant",
keywords = "Dyslexia, Children, Spoken sentence comprehension, Eye tracking",
abstract = "Children with dyslexia who did not have SLI (n=31) and typically-developing (TD, n=31) children with similar oral language and nonverbal skills completed a spoken sentence-picture matching task while an eye tracker recorded fixations and dwell time. No group differences were found on accuracy – which was very high across both groups. However, there were online processing differences. The TD group made more target fixations and the dyslexic group made more fixations to syntax distractors. Time course analyses revealed that compared to the dyslexic group, the TD group looked longer at the target when sentences became unambiguous. Across groups, sentence accuracy, target fixations, and cumulative target dwell time were correlated. Word reading was correlated with sentence accuracy and both online sentence processing measures, but only in the dyslexic group. In conclusion, the eye tracking data uncovered more than the behavioral measures alone, and children with dyslexia showed subtle sentence comprehension difficulties compared to TD peers."
}
@article{TALLON2019145,
title = "Comprehension of business process models: Insight into cognitive strategies via eye tracking",
journal = "Expert Systems with Applications",
volume = "136",
pages = "145 - 158",
year = "2019",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2019.06.032",
url = "http://www.sciencedirect.com/science/article/pii/S0957417419304324",
author = "Miles Tallon and Michael Winter and Rüdiger Pryss and Katrin Rakoczy and Manfred Reichert and Mark W. Greenlee and Ulrich Frick",
keywords = "Visual literacy, Business process model, Eye tracking, Latent class analysis, Cognitive workload",
abstract = "Process Models (PM) are visual documentations of the business processes within or across enterprises. Activities (tasks) are arranged together into a model (i.e., similar to flowcharts). This study aimed at understanding the underlying structure of PM comprehension. Though standards for describing PM have been defined, the cognitive work load they evoke, their structure, and the efficacy of information transmission are only partially understood. Two studies were conducted to better differentiate the concept of visual literacy (VL) and logical reasoning in interpreting PM. Study I: A total of 1047 students from 52 school classes were assessed. Three different process models of increasing complexity were presented on tablets. Additionally, written labels of the models’ elements were randomly allocated to scholars in a 3-group between-subjects design. Comprehension of process models was assessed by a series of 3 × 4 (=12) dichotomous test items. Latent Class Analysis of solved items revealed 6 qualitatively differing solution patterns, suggesting that a single test score is insufficient to reflect participants’ performance. Study II: Overall, 21 experts and 15 novices with respect to visual literacy were presented the same set of PMs as in Study I, while wearing eye tracking glasses. The fixation duration on relevant parts of the PM and on questions were recorded, as well as the total time needed to solve all 12 test items. The number of gaze transitions between process model and comprehension questions was measured as well. Being an expert in visual literacy did not alter the capability of correctly understanding graphical logical PMs. Presenting PMs that are labelled by single letters had a significant influence on reducing the time spent on irrelevant model parts but did not affect the fixation duration on relevant areas of interest. Both samples’ participants required longer response times with increasing model complexity. The number of toggles (i.e., gaze transitions between model and statement area of interest) was predictive for membership in one of the latent classes. Contrary to expectations, denoting the PM events and decisions not with real-world descriptions, but with single letters, led to lower cognitive workload in responding to comprehension questions and to better results. Visual Literacy experts could neither outperform novices nor high-school students in comprehending PM."
}