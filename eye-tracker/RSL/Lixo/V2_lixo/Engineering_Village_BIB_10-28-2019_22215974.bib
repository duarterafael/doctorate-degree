@article{20151700778984 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Reader comprehension ranking by monitoring eye gaze using eye tracker},
journal = {International Journal of Intelligent Systems Technologies and Applications},
author = {Singh, Chandan and Yadav, Dhananjay and Lee, Jinho},
volume = {13},
number = {4},
year = {2014},
pages = {294 - 307},
issn = {17408865},
abstract = {This paper concentrates on measuring comprehension ability of a reader by calculating reader ranking based on correct answer lines recorded by eye gaze tracker (mounted on reader's eye) and number of correct answers given by reader. Time is measured to find the answer line (page time T<inf>1</inf>) and time spent on the answer line (score time T<inf>2</inf>). The ratio (T<inf>2</inf>/T<inf>1</inf>) of both these time parameters plays vital role in evaluation of rank of reader. Score is calculated only if reader reads the answer line/s and after that gives the correct answer otherwise the score will be zero for same question. Finally, the reader gets score and rank among the existing readers on the basis of time ratio and correctness of answers.<br/> Copyright &copy; 2014 Inderscience Enterprises Ltd.},
key = {Eye tracking},
keywords = {Intelligent systems;},
note = {Eye gaze trackers;Eye trackers;Eye-gaze;Reader comprehension;Time parameter;Time ratio;Time spent;},
URL = {http://dx.doi.org/10.1504/IJISTA.2014.068831},
} 


@inproceedings{20181505007188 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Assessing cognitive workload on printed and electronic media using eye-Tracker and EDA wristband},
journal = {International Conference on Intelligent User Interfaces, Proceedings IUI},
author = {Brishtel, Iuliia and Ishimaru, Shoya and Augereau, Olivier and Kise, Koichi and Dengel, Andreas},
year = {2018},
pages = {ACM SIGAI; ACM SIGCHI - },
address = {Tokyo, Japan},
abstract = {With the expansion of e-learning platforms, we receive a great opportunity to learn and study just using an electronic device. In this paper, we measured the differences in information processing on screen and paper with 18 participants using an eye-tracker and an EDA wristband. Our findings show that the media type has a significant influence on cognitive workload and understandability of the content. The results of this work are of vital importance for the design of new intelligent user interfaces and reveal the necessity to take mental processes of users more into account.<br/> &copy; 2018 Copyright is held by the owner/author(s).},
key = {Eye tracking},
keywords = {Data processing;E-learning;User interfaces;},
note = {Cognitive workloads;E-learning platforms;Electrodermal activity;Electronic device;Electronic media;Intelligent User Interfaces;Reading;Understandability;},
URL = {http://dx.doi.org/10.1145/3180308.3180354},
} 


@inproceedings{20154001342280 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Restricted focus viewer: A tool for tracking visual attention},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Blackwell, Alan F. and Jansen, Anthony R. and Marriott, Kim},
volume = {1889},
year = {2000},
pages = {162 - 177},
issn = {03029743},
address = {Edinburgh, United kingdom},
abstract = {Eye-tracking equipment has proven useful in examining the cognitive processes people use when understanding and reasoning with diagrams. However, eye-tracking has several drawbacks: accurate eyetracking equipment is expensive, often awkward for participants, requires frequent re-calibration and the data can be difficult to interpret. We introduce an alternative tool for diagram research: the Restricted Focus Viewer (RFV). This is a computer program which takes an image, blurs it and displays it on a computer monitor, allowing the participant to see only a small region of the image in focus at any time. The region in focus can be moved using the computer mouse. The RFV records what the participant is focusing on at any point in time. It is cheap, non-intrusive, does not require calibration and provides accurate data about which region is being focused upon. We describe this tool, and also provide an experimental comparison with eye-tracking. We show that the RFV gives similar results to those obtained by Hegarty (1992) when using eyetracking equipment to investigate reasoning about mechanical diagrams.<br/> &copy; Springer-Verlag Berlin Heidelberg 2000.},
key = {Eye tracking},
keywords = {Behavioral research;Calibration;Display devices;Graphic methods;},
note = {Cognitive process;Computer mouse;Experimental comparison;Non-intrusive;Recalibrations;Small region;Visual Attention;},
} 


@inproceedings{20154201393743 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {How engineers understand entity relationship diagrams (ERD): Insights from eye tracker data},
journal = {Proceedings of the IADIS International Conference Information Systems 2012, IS 2012},
author = {Tokdemir, Gul and Cagiltay, Nergiz Ercil and Kilic, Ozkan},
year = {2012},
pages = {213 - 220},
address = {Berlin, Germany},
abstract = {Entity Relationship Diagram (ERD) is one of the main tools used in software design process. This representation enables software engineers to understand system data requirements at a more comprehensive level. Designing and understanding of ERD and hence system data requirements is a critical issue for the success of software projects. In this study we are introducing an experiment environment which would be used to understand the behaviors of software engineers during designing and understanding these representations. This experimental setting is planned to be used to measure the software engineers' performance during ERD defect detection process. We believe such an environment can be used to develop some reviewing guidelines for the software engineers to improve their reviewing process in ERD which in turn will provide some tools for the educators to improve design and review skills of future software engineers. The results of this study would also provide recommendations for the researchers in similar experiments.<br/> &copy; 2012 IADIS.},
key = {Eye tracking},
keywords = {Data mining;Defects;Engineering education;Engineers;Information systems;Information use;Professional aspects;Software design;Software engineering;},
note = {Data requirements;Defect detection;Diagrams;Entity relationship diagrams;Experimental settings;Eye-tracker data;Reviewing process;Software design process;},
} 


@inproceedings{20120614757648 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic real-time FACS-coder to anonymise drivers in eye tracker videos},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
author = {Selpi and Wilhelm, Torsten and Jansson, Marcus and Hagstrom, Li and Brandin, Niklas and Andersson, Magnus and Gronvall, John-Fredrik},
year = {2011},
pages = {1986 - 1993},
issn = {15505499},
address = {Barcelona, Spain},
abstract = {Driver's face is a rich source of information for understanding driver behaviour. From the driver's face, one could get an idea of the driver's emotional state and where s/he looks at. In recent years, naturalistic driving studies and field operational tests have been conducted to collect driver behavioural data, which often includes video of the driver, from many drivers driving for an extended period of time. Due to the Data Privacy Act, it is desirable to make the driver video anonymous, while preserving the original facial expressions. This paper describes our attempt to make a system that could do so. The system is a combination of an automatic Facial Action Coding System (FACS) coder based on Active Appearance Models (AAMs), a classifier that analyses local deformations in the AAM shape mesh and a 3D visualisation. The image acquisition hardware is based on a SmartEye eye tracker installed in a vehicle. The eye tracker we used provides a constant image quality independent of external illumination, which is a precondition for deploying the system in a vehicle environment. While the system uses Action Unit (AU) activations internally, the evaluation was done using the six basic emotions. &copy; 2011 IEEE.<br/>},
key = {Eye tracking},
keywords = {Computer keyboards;Computer vision;Data privacy;},
note = {3D Visualisation;Active appearance models;External illumination;Facial Action Coding System;Facial Expressions;Local deformations;Naturalistic driving studies;Operational test;},
URL = {http://dx.doi.org/10.1109/ICCVW.2011.6130492},
} 


@inproceedings{20183405733749 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Fixation oriented object segmentation using mobile eye tracker},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Wan, Qianwen and Rajeev, Srijith and Kaszowska, Aleksandra and Panetta, Karen and Taylor, Holly A. and Agaian, Sos},
volume = {10668},
year = {2018},
pages = {The Society of Photo-Optical Instrumentation Engineers (SPIE) - },
issn = {0277786X},
address = {Orlando, FL, United states},
abstract = {Eye tracking technology allows researchers to monitor position of the eye and infer one's gaze direction, which is used to understand the nature of human attention within psychology, cognitive science, marketing and artificial intelligence. Commercially available head-mounted eye trackers allow researchers to track pupil movements (saccades and fixations) using infrared camera and capture the field of vision by a front-facing scene camera. The wearable eye tracker opened a new way to research in unconstrained environment settings; however, the recorded scene video typically has non-uniform illumination, low quality image frames, and moving scene objects. One of the most important tasks for analyzing the recorded scene video data is finding the boundary between different objects in a single frame. This paper presents a multi-level fixation-oriented object segmentation method (MFoOS) to solve the above challenges in segmenting the scene objects in video data collected by the eye tracker in order to support cognition research. MFoOS shows its advancement in position-invariance, illumination, noise tolerance and is task-driven. The proposed method is tested using real-world case studies designed by our team of psychologists focused on understanding visual attention in human problem solving. The extensive computer simulation demonstrates the method's accuracy and robustness for fixation-oriented object segmentation. Moreover, a deep-learning image semantic segmentation combining MFoOS results as label data was explored to demonstrate the possibility of on-line deployment of eye tracker fixation-oriented object segmentation.<br/> &copy; COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.},
key = {Eye tracking},
keywords = {Behavioral research;Cameras;Cognitive systems;Deep learning;Eye movements;Image segmentation;Problem solving;Semantics;Video recording;},
note = {Cognitive science;Eye tracking technologies;Image semantics;Object segmentation;Online deployment;},
URL = {http://dx.doi.org/10.1117/12.2304868},
} 


@article{20161502209182 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Embedding an Eye Tracker into a Surgical Microscope: Requirements, Design, and Implementation},
journal = {IEEE Sensors Journal},
author = {Eivazi, Shahram and Bednarik, Roman and Leinonen, Ville and Von Und Zu Fraunberg, Mikael and Jaaskelainen, Juha E.},
volume = {16},
number = {7},
year = {2016},
pages = {2070 - 2078},
issn = {1530437X},
abstract = {Eye tracking has long been known as a tool for attention tracking, however, the understanding of gaze in the critical domains such as surgery is still in its infancy. In image-guided surgery, studying the role that visual attention plays in eye-hand coordination, situation awareness, and instrumentation control is critical in order to understand the nature of expertise and explore the possibilities for gaze-based interaction. To date, the eye-tracking technology has not been embedded into an operation room microscope and thus limited knowledge is available about the role of attention in real-life image-guided surgery. To advance the state-of-the-art, we adopted an optical solution for eye tracking and embedded a binocular eye tracker into a surgical microscope. We present the design principles and development evaluation cycles, as well as highlight the technical challenges encountered when embedding an eye tracker for a surgical microscope. The developed solution can be applied for other types of microscopes and ocular-based optical devices, for example, ophthalmology, otolaryngology, plastic and reconstructive surgery, and astronomical devices.<br/> &copy; 2001-2012 IEEE.},
key = {Eye tracking},
keywords = {Behavioral research;Microscopes;Operating rooms;Patient rehabilitation;Stereo vision;Surgery;},
note = {Astronomical devices;Eye tracking technologies;Eye-hand coordination;Gaze-based interaction;Instrumentation control;microsurgery;Reconstructive surgery;Technical challenges;},
URL = {http://dx.doi.org/10.1109/JSEN.2015.2501237},
} 


@inproceedings{20191106636073 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Visual Behaviors Analysis Based on Eye Tracker in Subjective Image Quality Assessment},
journal = {Proceedings - 2018 11th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics, CISP-BMEI 2018},
author = {Wang, Xuan and Meng, Fang and Huang, Xiyu},
year = {2018},
address = {Beijing, China},
abstract = {The study of the visual behaviors of observers in subjective image quality assessment is helpful in understanding of human visual system. It can also be used to improve the reliability of assessment results. In this paper, we propose a subjective image quality assessment system based on eye tracker. The system can record the viewpoints of observers' eye movements in the process of experiment. The system also can analyze the visual behaviors of observers. In the experiment, we first verify the accuracy of the recorded viewpoints. After, we choose the observers with different professional backgrounds. From the analysis of the assessment results and the corresponding viewpoints, we can see that non-experts are more easily to be attracted by the image contents, and the viewpoints of experts are more overall.<br/> &copy; 2018 IEEE.},
key = {Image quality},
keywords = {Biomedical engineering;Eye movements;Eye tracking;Image analysis;Quality control;},
note = {Eye trackers;Human Visual System;Image content;Professional backgrounds;Subjective image quality;Visual behavior;},
URL = {http://dx.doi.org/10.1109/CISP-BMEI.2018.8633162},
} 


@inproceedings{20193007218581 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Detecting cognitive bias in a relevance assessment task using an eye tracker},
journal = {Eye Tracking Research and Applications Symposium (ETRA)},
author = {Harris, Christopher G.},
year = {2019},
pages = {ACM SIGCHI; ACM SIGGRAPH - },
address = {Denver, CO, United states},
abstract = {Cognitive biases, such as the bandwagon effect, occur when a participant places a disproportionate emphasis on external information when making decisions under uncertainty. These effects are challenging for humans to overcome &ndash; even when they are explicitly made aware of their own biases. One challenge for researchers is to detect if the information is used in decision making and to what degree. One can gain a better understanding of how this external information is used in decision making using an eye tracker. In this paper, we evaluate cognitive biases in the context of assessing the binary relevance of a set of documents in response to a given information need. We show that these cognitive biases can be observed by examining gaze time in Areas of Interest (AOI) that contain this pertinent external information.<br/> &copy; 2019 Copyright is held by the owner/author(s). Publication rights licensed to ACM.},
key = {Eye tracking},
keywords = {Decision making;Human computer interaction;},
note = {Bandwagon effect;Binary relevances;Cognitive bias;External informations;Eye trackers;Gaze tracking;Making decision;Relevance assessments;},
URL = {http://dx.doi.org/10.1145/3314111.3319824},
} 


@inproceedings{20182805543457 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Evaluating gender dierence on algorithmic problems using eye-tracker},
journal = {Eye Tracking Research and Applications Symposium (ETRA)},
author = {Obaidellah, Unaizah and Haek, Mohammed Al},
volume = {Part F137344},
year = {2018},
pages = {ACM SIGCHI; ACM SIGGRAPH - },
address = {Warsaw, Poland},
abstract = {Gender dierences in programming comprehension has been a topic of discussion in recent years. We conducted an eye-tracking study on 51(21 female, 30 male) computer science undergraduate university students to examine their cognitive processes in pseudocode comprehension. We aim to identify their reading strategies and eye gaze behavior on the comprehension of pseudocodes in terms of performance and visual eort when solving algorithmic problems of varying diculty levels. Each student completed a series of tasks requiring them to rearrange randomized pseudocode statements in a correct order for the problem presented. Our results indicated that the speed of analyzing the problems were faster among male students, although female students xated longer in understanding the problem requirements. In addition, female students more commonly xated on indicative verbs (i.e., prompt, print), while male students xated more on operational statements (i.e., loops, variables calculations, le handling).<br/> &copy; 2018 Association for Computing Machinery.},
key = {Eye tracking},
keywords = {Problem solving;Students;},
note = {Algorithmic problems;Cognitive process;Eye-tracking studies;Gender dierences;Novice programmer;Pseudo-code;Reading strategies;University students;},
URL = {http://dx.doi.org/10.1145/3204493.3204537},
} 


@inproceedings{20181605012160 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Cognitive State Measurement on Learning Materials by Utilizing Eye Tracker and Thermal Camera},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
author = {Ishimaru, Shoya and Jacob, Soumy and Roy, Apurba and Bukhari, Syed Saqib and Heisel, Carina and Grobmann, Nicolas and Thees, Michael and Kuhn, Jochen and Dengel, Andreas},
volume = {8},
year = {2017},
pages = {32 - 36},
issn = {15205363},
address = {Kyoto, Japan},
abstract = {We demonstrate how information derived from pervasive sensors can quantify cognitive states of learners while they are reading a textbook. Eye tracking is one of the most effective approaches to measuring reading behavior. For example, high fixation duration represents a reader's attention on a document. However, it is still a challenging task to predict the reason for the attention (i.e., is it because of his/her interest or trouble of understanding?). In this paper, we utilize additional sensing modality to solve the problem. On the dataset of 12 high school students' reading behaviors, we have found that the changing of pupil diameter and nose temperature are highly correlated with their cognitive states including their interests and efforts for reading/solving tasks on learning materials in Physics.<br/> &copy; 2017 IEEE.},
key = {Eye tracking},
keywords = {Physics;},
note = {Confidence;Didactics;Interest;Reading;Thermal image analysis;Workload;},
URL = {http://dx.doi.org/10.1109/ICDAR.2017.378},
} 


@inproceedings{20151400707435 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Playing around the eye tracker: A serious game based dataset},
journal = {CEUR Workshop Proceedings},
author = {Riegler, Michael and Eg, Ragnhild and Calvet, Lilian and Lux, Mathias and Halvorsen, Pal and Griwodz, Carsten},
volume = {1345},
year = {2015},
pages = {34 - 40},
issn = {16130073},
address = {Vienna, Austria},
abstract = {This work applies crowdsourcing and gamification approaches to the study of human visual perception and attention. With the presented dataset, we wish to contribute raw data on the salience of image segments. The data collection takes place in the designed game, where players are tasked with guessing the content of a gradually uncovered image. Because the image is uncovered tile-by-tile, the game mechanics allow us to collect information on the image segments that are most important to identifying the image content. The dataset can be applied to both computer vision and image retrieval algorithms, aiming to build on the current understanding of human visual perception and attention. Moreover, the end objective is to test the game as a potential substitute to professional eye tracking systems.<br/> Copyright &copy; 2015 for the individual papers by the paper's authors. Copying permitted for private and academic purposes. This volume is published and copyrighted by its editors.},
key = {Eye tracking},
keywords = {Image retrieval;Serious games;Vision;},
note = {Data collection;Eye trackers;Eye tracking systems;Gamification;Human visual perception;Image content;Image retrieval algorithms;Image segments;},
} 


@inproceedings{20182805537882 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Development of a low-cost eye tracker  A proof of concept},
journal = {Advances in Intelligent Systems and Computing},
author = {Vigario, Ricardo and Gamas, Filipa and Morais, Pedro and Quintao, Carla},
volume = {781},
year = {2019},
pages = {285 - 296},
issn = {21945357},
address = {Orlando, FL, United states},
abstract = {Humans live in, and interact with, a very complex and multi-sensory environment. Yet, one parcels efficiently the incoming information through attention mechanisms. Even if restricted to the visual sensory system alone, full understanding of one&rsquo;s perception often implies a suitable identification of that person&rsquo;s direction of gaze. There is a considerable amount of new and commercially available eye tracking devices. We investigate the use of a mobile phone to acquire precise information on the direction of gaze, in a controlled visual stimulation environment. The main advantages of the proposed new approach are its price, ease of use and ubiquitous availability. The results attained in this proof-of-concept study display fairly high accuracy and precision for the estimation of the direction of gaze.<br/> &copy; Springer International Publishing AG, part of Springer Nature 2019.},
key = {Eye tracking},
keywords = {Computer software portability;Costs;Human computer interaction;Human engineering;Sensory perception;},
note = {Attention;Attention mechanisms;Eye trackers;Eye tracking devices;New approaches;Proof of concept;Visual perception;Visual stimulation;},
URL = {http://dx.doi.org/10.1007/978-3-319-94334-3_29},
} 


@inproceedings{20122615174078 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Eye tracker data quality: What it is and how to measure it},
journal = {Eye Tracking Research and Applications Symposium (ETRA)},
author = {Holmqvist, Kenneth and Nystrom, Marcus and Mulvey, Fiona},
year = {2012},
pages = {45 - 52},
address = {Santa Barbara, CA, United states},
abstract = {Data quality is essential to the validity of research results and to the quality of gaze interaction. We argue that the lack of standard measures for eye data quality makes several aspects of manufacturing and using eye trackers, as well as researching eye movements and vision, more difficult than necessary. Uncertainty regarding the comparability of research results is a considerable impediment to progress in the field. In this paper, we illustrate why data quality matters and review previous work on how eye data quality has been measured and reported. The goal is to achieve a common understanding of what data quality is and how it can be defined, measured, evaluated, and reported. &copy; 2012 ACM.<br/>},
key = {Eye tracking},
keywords = {Data reduction;Eye movements;},
note = {accuracy;Data quality;Eye trackers;latency;precision;},
URL = {http://dx.doi.org/10.1145/2168556.2168563},
} 


@inproceedings{20180304650872 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Impact of misplaced words in reading comprehension of Chinese sentences: Evidences from eye movement and electroencephalography},
journal = {Workshop Proceedings of the 23rd International Conference on Computers in Education, ICCE 2015},
author = {Ho, Hong-Fa and Chen, Guan-An and Vicente, Celesamae T.},
year = {2015},
pages = {573 - 579},
address = {Hangzhou, China},
abstract = {This pilot study aimed to investigate the impact of misplaced words in Chinese sentences by using eye-Tracker and electroencephalography (EEG) technology. There were 5 participants. Four of which were graduate students and one was a college student. Their average age was 24.4 years old. The participants were asked to read text with and without misplaced words. After reading, they were asked to answer a question that determined whether they understood the content of the stimulus previously displayed. Eye movement data and attention levels were recorded using an eye tracker and an EEG device. The data were saved in the background system automatically and synchronously while the experiment was performed. The findings suggest that: 1.) The number of misplaced words do not affect the reading comprehension of participants. Instead, wrong answers resulted from the question that evaluated the reading comprehension on one stimulus that contained too many information 2.) In increasing the number of misplaced words in a stimulus, participants did not spend more time gazing at them in comparison to other stimuli that had lesser or no misplaced words 3.) When asked to read a stimulus as quickly as possible, the analysis showed that most of the participants did not gaze longer at the regions of the misplaced words. They spent less than 5% of the time gazing at these regions of interest 4.) EEG data analysis yielded mixed results since some participants that gazed at misplaced words had high attention levels and some did not show an increase in their attention levels.<br/>},
key = {Electroencephalography},
keywords = {Electrophysiology;Eye movements;Eye tracking;Students;},
note = {Background systems;College students;Eye movement datum;Eye trackers;Graduate students;Misplaced words in Chinese;Reading comprehension;Regions of interest;},
} 


@inproceedings{20064710254585 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {An eye-tracking methodology for characterizing program comprehension processes},
journal = {Eye Tracking Research and Applications Symposium (ETRA)},
author = {Bednarik, Roman and Tukiainen, Markku},
volume = {2005},
year = {2005},
pages = {125 - 132},
address = {San Diego, CA, United states},
abstract = {Program comprehension processes have previously been studied using methodologies such as think-aloud or comprehension summary analysis. Eye-tracking, however, has not been previously widely applied to studies of behavioral aspects of programming. We present a study in which program comprehension was investigated with a help of a remote eye-tracker. Novice and intermediate programmers used a program visualization tool to aid their comprehension while the location of fixations, fixation durations and attention switching between the areas of interest were recorded. In this paper 1) we propose an approach how to investigate trends in repeated-measures sparse-data of few cases captured by an eye-tracker and 2) using this technique, we characterize the development of program comprehension strategies during dynamic program visualization with help of eye-movement data. &copy; 2006 ACM.},
key = {Eye movements},
keywords = {Information analysis;Psychology computing;Switching systems;Tracking (position);Vision;},
note = {Program comprehension;Program visualization;Psychology of programming;},
} 


@inproceedings{20193807459521 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Indentation: Simply a matter of style or support for program comprehension?},
journal = {IEEE International Conference on Program Comprehension},
author = {Bauer, Jennifer and Siegmund, Janet and Peitek, Norman and Hofmeister, Johannes C. and Apel, Sven},
volume = {2019-May},
year = {2019},
pages = {154 - 164},
address = {Montreal, QC, Canada},
abstract = {An early study showed that indentation is not a matter of style, but provides actual support for program comprehension. In this paper, we present a non-exact replication of this study. Our aim is to provide empirical evidence for the suggested level of indentation made by many style guides. Following Miara and others, we also included the perceived difficulty, and we extended the original design to gain additional insights into the influence of indentation on visual effort by employing an eye-tracker. In the course of our study, we asked 22 participants to calculate the output of Java code snippets with different levels of indentation, while we recorded their gaze behavior. We did not find any indication that the indentation levels affect program comprehension or visual effort, so we could not replicate the findings of Miara and others. Nevertheless, our modernization of the original experiment design is a promising starting point for future studies in this field.<br/> &copy; 2019 IEEE.},
key = {Computer programming},
keywords = {Eye tracking;},
note = {Experiment design;Eye trackers;Gaze behavior;Original design;Perceived difficulties;Program comprehension;Style guides;Visual Effort;},
URL = {http://dx.doi.org/10.1109/ICPC.2019.00033},
} 


@inproceedings{20184806146901 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Effect of Devanagari font type in reading comprehension: An eye tracking study},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Ralekar, Chetan and Saha, Punyajoy and Gandhi, Tapan K. and Chaudhury, Santanu},
volume = {11278 LNCS},
year = {2018},
pages = {136 - 147},
issn = {03029743},
address = {Allahabad, India},
abstract = {In this world of digitization, screen reading has grown immensely due to the availability of affordable display devices. Most of the people prefer to read on display devices as compared to the print media. To make the reading experience of the reader pleasant and comfortable, the font designers strive hard to choose suitable typographical properties of the text such as font type, font size etc. Some of the researchers suggest that the typography of the text affects the reading performance of the readers to some extent. However, the research focusing on the effect of typography on the reading behavior of the readers is limited and it is hardly touched upon for the Indian scripts. Therefore, the proposed paper aims to find out the effect of Devanagari font type on the reading performance, especially reading comprehension of the readers. In addition to this, a method to reduce the error in the gaze estimation of the eye tracker is also proposed. In order to understand the reading behavior, an eye tracking experiment is performed on 14 participants asking them to read 22 pages, in 3 different font types, presented on the screen of the eye tracker. The performance of the readers is analyzed in terms of total reading time, comprehension score, number of fixations, fixation duration and number of regressions. Our results show that there is a significant difference in the fixation duration, a number of fixations and the comprehension score, when the same document is read in different font type. Thus, there is a scope for improvement in the reading comprehension, by changing the physical properties of the document without changing its content. These findings might be useful to understand the readers&rsquo; preference for the font and to design a proper font type for online reading.<br/> &copy; Springer Nature Switzerland AG 2018.},
key = {Eye tracking},
keywords = {Display devices;Human computer interaction;Typesetting;},
note = {Devanagari script;Eye-tracking studies;Fixation duration;Font type;Gaze estimation;Number of fixations;Reading comprehension;Reading performance;},
URL = {http://dx.doi.org/10.1007/978-3-030-04021-5_13},
} 


@inproceedings{20095312583797 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Impact of the visitor pattern on program comprehension and maintenance},
journal = {2009 3rd International Symposium on Empirical Software Engineering and Measurement, ESEM 2009},
author = {Jeanmart, Sebastien and Gueheneuc, Yann-Gael and Sahraoui, Houari and Habra, Naji},
year = {2009},
pages = {69 - 78},
address = {Lake Buena Vista, FL, United states},
abstract = {In the software engineering literature, many works claim that the use of design patterns improves the com-prehensibility of programs and, more generally, their maintainability. Yet, little work attempted to study the impact of design patterns on the developers' tasks of program comprehension and modification. We design and perform an experiment to collect data on the impact of the Visitor pattern on comprehension and modification tasks with class diagrams. We use an eye-tracker to register saccades and fixations, the latter representing the focus of the developers' attention. Collected data show that the Visitor pattern plays a role in maintenance tasks: class diagrams with its canonical representation requires less efforts from developers. &copy; 2009 IEEE.<br/>},
key = {Eye tracking},
keywords = {Computer programming;Eye movements;Software engineering;},
note = {Canonical representations;Class diagrams;Design Patterns;Eye trackers;Maintenance tasks;Program comprehension;Program comprehension and maintenances;Visitor patterns;},
URL = {http://dx.doi.org/10.1109/ESEM.2009.5316015},
} 


@inproceedings{20174204284459 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Eye tracking as a tool in manga-based interactive E-book on reading comprehension in Japanese learning},
journal = {Lecture Notes in Electrical Engineering},
author = {Wang, Chun-Chia and Ho, Hong-Fa and Chen, Guan-An and Su, Hui-Sheng},
volume = {422},
year = {2018},
pages = {165 - 172},
issn = {18761100},
address = {Tokyo, Japan},
abstract = {As indicated by some studies, the problem of prior knowledge often exists when exploring the outcome of reading comprehension in academic language learning. This pilot study aimed to employ eye tracking technology to explore how students with different levels of prior knowledge processed the content of manga-based interactive E-book while learning Japanese language. Students&rsquo; visual behaviors were tracked and recorded when they read a Japanese conversation with the relationship between graphical manga and interactive textual annotations. According to the pretest scores, 6 university students were categorized into high and low prior knowledge (PK) groups. Using EyeNTNU-120 eye tracker to compare including Total Contact Time (TCT), Number of Fixations (NOF), and Number of Clicks on textual annotations of the two PK groups based on areas of interests (AOIs) was measured. After the eye tracking experiment, students received a posttest of reading comprehension. The results revealed that (1) the high PK students showed longer reading time in graphic AOIs than the low PK students, (2) the low PK students showed longer reading time in text AOIs than the high PK students, (3) the low PK students showed longer reading time in annotation AOIs than the high PK students, (4) the high and low PK students had no significant difference in the whole reading time, (5) the low PK students showed more NOF of texts that the high PK students, (6) the low PK students clicked many of annotations AOIs than the high PK students, and (7) the low PK students had a significant outcome of reading comprehension compared with pretest and posttest scores. This suggests that interactive E-book containing graphical manga attracted students&rsquo; visual attention and improved students&rsquo; outcome of reading comprehension. Suggestions are made for future studies and instructional design for interactive E-book learning.<br/> &copy; Springer Nature Singapore Pte Ltd. 2018.},
key = {Eye tracking},
keywords = {Behavioral research;Computation theory;Electronic publishing;Eye movements;Students;},
note = {E-books;Eye tracking technologies;Instructional designs;Number of fixations;Prior knowledge;Reading comprehension;Textual annotations;University students;},
URL = {http://dx.doi.org/10.1007/978-981-10-3187-8_17},
} 


@inproceedings{20141317513847 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Exploring the difficulties in digital logic circuit reading comprehension via saccade analysis},
journal = {Proceedings of the 21st International Conference on Computers in Education, ICCE 2013},
author = {Ho, Hong-Fa},
year = {2013},
pages = {210 - 215},
address = {Bali, Indonesia},
abstract = {The purpose of this paper is to explore whether there are differences in the reading process between high-grade and low-grade students by tasking them to find a bug in a digital logic circuit. Based on the pre-test scores, 155 high school students were divided into a high-grade group and a low-grade group. To examine their reading process, both groups were asked to find a bug in a digital circuit, and an infrared eye tracker recorded their eye movement. Correlation coefficient was used to analyze the saccadic data. The findings show 1) the integrative saccades from signal names of the timing diagram to other Regions of Interest (ROI) has the lowest correlation coefficient (0.3345); 2) there is a larger difference in the integrative saccades between the high and low-grade groups from signal names of timing diagram to timing diagram ROIs of RESET, CLOCK, INPUT and OUTPUT. These findings show that the low-grade group had some difficulties in reading comprehension when reading timing diagrams of RESET and OUTPUT, but fewer difficulties when reading CLOCK and INPUT. In addition, difficulties in reading comprehension also appeared when calculating OUTPUT. This paper contributes to the field of learning science by providing evidence of the saccade difference between digital circuit readers with and without difficulties in reading comprehension.<br/>},
key = {Eye movements},
keywords = {Clocks;Computer circuits;Digital circuits;Eye tracking;Logic circuits;Students;Timing circuits;},
note = {Correlation coefficient;Digital logic circuit;High school students;Input and outputs;Learning science;Reading comprehension;Regions of interest;Timing diagrams;},
} 


@inproceedings{20181605012159 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Using the Eye Gaze to Predict Document Reading Subjective Understanding},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
author = {Sanches, Charles Lima and Augereau, Olivier and Kise, Koichi},
volume = {8},
year = {2017},
pages = {28 - 31},
issn = {15205363},
address = {Kyoto, Japan},
abstract = {The traditional way to analyze the content of a document is to perform document image analysis. However, analyzing how the user perceives a document is another way to get information about the documents but also about the users. By using sensors such as eye tracker, it is possible analyze the reader's skill or the document comprehensibility. In this paper, we focus on predicting the user's understanding as it can be used as a feedback either for the author (to improve his document) or the user (to review the parts he did not understand). The eye movements of the readers are recorded by an eye tracker while they read several documents, then several features are extracted and a support vector regression system is used to predict the readers' understanding. In our experiment, 17 subjects were asked to read 19 documents for a total of 323 recordings. As a first result, we prove that the subjective understanding of the reader can be predicted more accurately by using the eye gaze than by asking a multiple choice question.<br/> &copy; 2017 IEEE.},
key = {Eye tracking},
keywords = {Eye movements;Forecasting;},
note = {Document image analysis;Eye trackers;Eye-gaze;Multiple choice questions;Support vector regression (SVR);},
URL = {http://dx.doi.org/10.1109/ICDAR.2017.377},
} 


@inproceedings{20193807453939 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic gaze-based detection of mind wandering during narrative film comprehension},
journal = {Proceedings of the 9th International Conference on Educational Data Mining, EDM 2016},
author = {Mills, Caitlin and Bixler, Robert and Wang, Xinyi and D'Mello, Sidney K.},
year = {2016},
pages = {30 - 37},
address = {Raleigh, NC, United states},
abstract = {Mind wandering (MW) reflects a shift in attention from task-related to task-unrelated thoughts. It is negatively related to performance across a range of tasks, suggesting the importance of detecting and responding to MW in real-time. Currently, there is a paucity of research on MW detection in contexts other than reading. We addressed this gap by using eye gaze to automatically detect MW during narrative film comprehension, an activity that is used across a range of learning environments. In the current study, students self-reported MW as they watched a 32.5-minute commercial film. Students&rsquo; eye gaze was recorded with an eye tracker. Supervised machine learning models were used to detect MW using global (content-independent), local (content-dependent), and combined global+local features. We achieved a student-independent score (MW F<inf>1</inf>) of .45, which reflected a 29% improvement over a chance baseline. Models built using local features were more accurate than the global and combined models. An analysis of diagnostic features revealed that MW primarily manifested as a breakdown in attentional synchrony between eye gaze and visually salient areas of the screen. We consider limitations, applications, and refinements of the MW detector.<br/> &copy; 2016 International Educational Data Mining Society. All rights reserved.},
key = {Eye tracking},
keywords = {Computer aided instruction;Data mining;Learning systems;Machine learning;Students;Supervised learning;},
note = {Combined model;Content dependent;Diagnostic features;Eye-gaze;Learning environments;Local feature;Mind wandering;Supervised machine learning;},
} 


@inproceedings{20140217175961 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {An empirical study assessing the effect of SeeIT 3D on comprehension},
journal = {2013 1st IEEE Working Conference on Software Visualization - Proceedings of VISSOFT 2013},
author = {Sharif, Bonita and Jetty, Grace and Aponte, Jairo and Parra, Esteban},
year = {2013},
address = {Eindhoven, Netherlands},
abstract = {A study to assess the effect of SeeIT 3D, a software visualization tool is presented. Six different tasks in three different task categories are assessed in the context of a large open-source system. Ninety-seven subjects were recruited from three different universities to participate in the study. Two methods of data collection: traditional questionnaires and an eye-tracker were used. The main goal was to determine the impact and added benefit of SeeIT 3D while performing typical software tasks within the Eclipse IDE. Results indicate that SeeIT 3D performs significantly better in one task category namely overview tasks but takes significantly longer when completing bug fixing tasks. Scores obtained by the subjects in the SeeIT 3D group are 13% better and 45% faster for overview tasks. &copy; 2013 IEEE.<br/>},
key = {Three dimensional computer graphics},
keywords = {Eye tracking;Open source software;Open systems;Surveys;Visualization;},
note = {Empirical studies;Eye trackers;Eye-tracking studies;Methods of data collections;Open source system;Software tasks;Software visualization;Software visualization tool;},
URL = {http://dx.doi.org/10.1109/VISSOFT.2013.6650519},
} 


@article{20171003422372 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2019 Elsevier Inc.},
copyright = {Compendex},
title = {Vertical error correction of eye trackers in nonrestrictive reading condition},
journal = {IPSJ Transactions on Computer Vision and Applications},
author = {Sanches, Charles Lima and Augereau, Olivier and Kise, Koichi},
volume = {8},
number = {1},
year = {2016},
issn = {18826695},
abstract = {The eye tracking technology is used for four decades for studying reading behavior. The applications are various: estimating the reader comprehension, identifying the reader, summarizing a read document, creating a reading-life log, etc. The gaze data used in such applications has to be accurate enough to perform the analysis. In order to improve the accuracy, most of the experiments are set up with restrictive conditions such as using a head fixation and a professional eye tracker. It implies that the results are valid only in restrictive laboratory settings and an unrealistic small error is produced by the experiment. However, the use of affordable eye trackers in realistic conditions of reading leads to large errors in the recordings. We propose a new algorithm to correct the vertical error and to align the gazes with the text. The proposed algorithm is robust to rereading and skipping some parts of text, contrary to all the other algorithms of the state of the art. We show that up to 69 % of the gazes are aligned with the correct text lines.<br/> &copy; 2016 The Author(s).},
key = {Eye tracking},
keywords = {Error correction;Eye movements;},
note = {Eye trackers;Eye tracking technologies;Gaze analysis;Reader comprehension;Reading understanding;Realistic conditions;Restrictive conditions;Sequence alignments;},
URL = {http://dx.doi.org/10.1186/s41074-016-0008-x},
} 



