Scopus
EXPORT DATE: 28 October 2019

@ARTICLE{Cai201963,
author={Cai, L.Z. and Kwong, J.W. and Azad, A.D. and Kahn, D. and Lee, G.K. and Nazerali, R.S.},
title={Where Do We Look? Assessing Gaze Patterns in Cosmetic Face-Lift Surgery with Eye Tracking Technology},
journal={Plastic and reconstructive surgery},
year={2019},
volume={144},
number={1},
pages={63-70},
doi={10.1097/PRS.0000000000005700},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068964610&doi=10.1097%2fPRS.0000000000005700&partnerID=40&md5=d8b7a006d63ac70dafb95226b125c2f6},
affiliation={Calif. From the Division of Plastic and Reconstructive Surgery, Stanford University, Stanford School of Medicine, Palo Alto, United States},
abstract={BACKGROUND: Aesthetics plays a central role in determining success in plastic surgery. Understanding perceptions of favorable aesthetics is critical to ensure patient satisfaction. Eye-tracking technology offers an objective way of evaluating attention and understanding how viewers direct their focus on patients who undergo cosmetic face-lift procedures. METHODS: Thirty-six subjects ranging from layperson to attending plastic surgeon viewed 15 sets of photographs before and after patients underwent an elective face-lift procedure. They were instructed to evaluate the aesthetic quality on a Likert scale while eye-tracking equipment tracked their gaze and analyzed their distribution of attention. RESULTS: Postoperative images showed a Likert score improvement of 0.51 ± 0.26, with the greatest difference in attending cosmetic plastic surgeons (1.36 ± 0.22; p < 0.05). The nose was the most common first fixation location (31 percent of first fixations) and the most viewed area (16 ± 3 percent of fixation time) for all subjects. Experienced subjects spent less time in nonrelevant areas (30 ± 11 percent for attending cosmetic plastic surgeons and 37 ± 10 percent for attending noncosmetic plastic surgeons) compared with less experienced subjects (50 ± 15 percent for laypersons). CONCLUSIONS: This study demonstrates that viewers with greater experience in cosmetic surgery focus quickly on the cheeks, chin, and neck and have evenly distributed gaze across the entire face. These results suggest that a layperson's gaze is drawn to the center of the face (because of both unfamiliarity with the face-lift procedure and the natural tendency to look at the central face), whereas attending plastic surgeons exhibit holistic gaze patterns and are more aware of the impact of the procedure.},
keywords={adult;  article;  attention;  cheek;  chin;  clinical article;  controlled study;  esthetic surgery;  eye tracking;  female;  gaze;  human;  layperson;  Likert scale;  male;  neck;  nose;  photography;  plastic surgeon;  rhytidoplasty},
publisher={NLM (Medline)},
issn={15294242},
pubmed_id={31246802},
language={English},
abbrev_source_title={Plast. Reconstr. Surg.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Li2019,
author={Li, Y. and Allen, C. and Shyu, C.-R.},
title={Quantifying and understanding the differences in visual activities with contrast subsequences},
journal={Eye Tracking Research and Applications Symposium (ETRA)},
year={2019},
doi={10.1145/3314111.3319842},
art_number={a42},
note={cited By 0; Conference of 11th ACM Symposium on Eye Tracking Research and Applications, ETRA 2019 ; Conference Date: 25 June 2019 Through 28 June 2019;  Conference Code:149180},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069542534&doi=10.1145%2f3314111.3319842&partnerID=40&md5=49712e6a7d4d88a30e404b50cde1a8bb},
affiliation={Department of Computer Science, University of Missouri, Columbia, MO, United States; School of Health Professions, University of Missouri, Columbia, MO, United States; Informatics Institute, University of Missouri, Columbia, MO, United States},
abstract={Understanding differences and similarities between scanpaths has been one of the primary goals for eye tracking research. Sequences of areas of interest mapped from fixations are a major focus for many analytic techniques since these sequences directly relate to the semantic meaning of the visual input. Many studies analyze complete sequences while overlooking the micro-transitions in subsequences. In this paper, we propose a method which extracts subsequences as features and finds contrasting patterns between different viewer groups. The contrast patterns help domain experts to quantify variations between visual activities and understand reasoning processes for complex visual tasks. Experiments were conducted with 39 expert and novice radiographers using nine radiology images corresponding to nine levels of task complexity. Identified contrast patterns, validated by an expert, prove that the method effectively reveals visual reasoning processes that are otherwise hidden. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
author_keywords={Contrast mining;  Diagnostic reasoning;  Eye movement;  Pattern analysis;  Radiographer;  Scanpath},
keywords={Eye movements;  Semantics, Analytic technique;  Contrast patterns;  Diagnostic reasoning;  Expert and novices;  Pattern analysis;  Radiographer;  Reasoning process;  Scan path, Eye tracking},
funding_details={National Science FoundationNational Science Foundation, NSF, IIS-0812515},
funding_text 1={We thank Dr. Hongfei Cao for initial experiment design and data collection. The project was partially supported by the National Science Foundation under grant number IIS-0812515.},
references={Appel, T., Scharinger, C., Gerjets, P., Kasneci, E., Cross-subject workload classification using pupil-related measures (2018) Proceedings of the 2018 ACM Symposium on Eye Tracking Research & Applications - ETRA’18, pp. 1-8. , https://doi.org/10.1145/3204493.3204531, ACM Press, New York, New York, USA; Borji, A., Sihite, D.N., Itti, L., Quantitative analysis of human-model agreement in visual saliency modeling: A comparative study (2013) IEEE Transactions on Image Processing, 22 (1), pp. 55-69. , https://doi.org/10.1109/TIP.2012.2210727, jan 2013; Cao, H., Li, Y., Allen, C.M., Phinney, M.A., Shyu, C.-R., Visual reasoning indexing and retrieval using in-memory computing (2016) International Journal of Semantic Computing, 10, pp. 299-322. , https://doi.org/10.1142/S1793351X16400110, 03 2016; Chen, S., Epps, J., Using task-induced pupil diameter and blink rate to infer cognitive load (2014) Human-Computer Interaction, 29 (4), pp. 390-413. , https://doi.org/10.1080/07370024.2014.892428, jul 2014; Chuk, T., Chan, A.B., Hsiao, J.H., Understanding eye movements in face recognition using hidden Markov models (2014) Journal of Vision, 14 (11), p. 8. , https://doi.org/10.1167/14.11.8, sep 2014; Chuk, T., Chan, A.B., Hsiao, J.H., Is having similar eye movement patterns during face learning and recognition beneficial for recognition performance? Evidence from hidden Markov modeling (2017) Vision Research, 141, pp. 204-216. , https://doi.org/10.1016/J.VISRES.2017.03.010, dec 2017; Cristino, F., Mathôt, S., Theeuwes, J., Gilchrist, I.D., Scan-Match: A novel method for comparing fixation sequences (2010) Behavior Research Methods, 42 (3), pp. 692-700. , https://doi.org/10.3758/BRM.42.3.692, aug 2010; Dong, G., Bailey, J., (2012) Contrast Data Mining: Concepts, Algorithms, and Applications, , 1st ed.). Chapman & Hall/CRC; Eraslan, S., Yesilada, Y., Harper, S., (2014) Identifying Patterns in Eye-Tracking Scanpaths in Terms of Visual Elements of Web Pages, pp. 163-180. , https://doi.org/10.1007/978-3-319-08245-5_10, Springer, Cham; Gegenfurtner, A., Lehtinen, E., Säljö, R., Expertise differences in the comprehension of visualizations: A meta-analysis of eye-tracking research in professional domains (2011) Educational Psychology Review, 23 (4), pp. 523-552. , https://doi.org/10.1007/s10648-011-9174-7, dec 2011; Goldberg, J.H., Helfman, J.I., Scanpath clustering and aggregation (2010) Proceedings of the 2010 Symposium on Eye-Tracking Research & Applications - ETRA’10, p. 227. , https://doi.org/10.1145/1743666.1743721, ACM Press, New York, New York, USA; Haass, M.J., Matzen, L.E., Butler, K.M., Armenta, M., A new method for categorizing scanpaths from eye tracking data (2016) Proceedings of the Ninth Biennial ACM Symposium on Eye Tracking Research & Applications - ETRA’16, pp. 35-38. , https://doi.org/10.1145/2857491.2857503, ACM Press, New York, New York, USA; Jarodzka, H., Holmqvist, K., Nyström, M., A vector-based, multidimensional scanpath similarity measure (2010) Proceedings of the 2010 Symposium on Eye-Tracking Research & Applications - ETRA’10, p. 211. , https://doi.org/10.1145/1743666.1743718, ACM Press, New York, New York, USA; Kübler, T.C., Kasneci, E., Rosenstiel, W., Subsmatch: Scanpath similarity in dynamic scenes based on subsequence frequencies (2014) Proceedings of the Symposium on Eye Tracking Research and Applications - ETRA’14, pp. 319-322. , https://doi.org/10.1145/2578153.2578206, ACM Press, New York, New York, USA; Kübler, T.C., Rothe, C., Schiefer, U., Rosenstiel, W., Kasneci, E., SubsMatch 2.0: Scanpath comparison and classification based on subsequence frequencies (2017) Behavior Research Methods, 49 (3), pp. 1048-1064. , https://doi.org/10.3758/s13428-016-0765-6, jun 2017; Lao, J., Miellet, S., Pernet, C., Sokhn, N., Caldara, R., IMAP4: An open source toolbox for the statistical fixation mapping of eye movement data with linear mixed modeling (2017) Behavior Research Methods, 49 (2), pp. 559-575. , https://doi.org/10.3758/s13428-016-0737-x, apr 2017; Le Meur, O., Coutrot, A., Introducing context-dependent and spatially-variant viewing biases in saccadic models (2016) Vision Research, 121, pp. 72-84. , https://doi.org/10.1016/J.VISRES.2016.01.005, apr 2016; Mast, M., Burmester, M., Exposing repetitive scanning in eye movement sequences with t-pattern detection (2011) Proceedings IADIS International Conference Interfaces and Human Computer Interaction (IHCI), pp. 137-145. , http://www.iadisportal.org/digital-library/exposing-repetitive-scanning-in-eye-movement-sequences-with-t-pattern-detection; Mills, M., Hollingworth, A., Van Der Stigchel, S., Hoffman, L., Dodd, M.D., Examining the influence of task set on eye movements and fixations (2011) Journal of Vision, 11 (8), p. 17. , https://doi.org/10.1167/11.8.17arXiv:NIHMS150003, jul 2011; Tavakoli, H.R., Atyabi, A., Rantanen, A., Laukka, S.J., Nefti-Meziani, S., Heikkilä, J., Predicting the valence of a scene from observers’ eye movements (2015) PLOS ONE, 10 (9). , https://doi.org/10.1371/journal.pone.0138198, sep 2015; Räihä, K.-J., (2010) Some Applications of String Algorithms in Human-Computer Interaction, pp. 196-209. , https://doi.org/10.1007/978-3-642-12476-1_14, Springer, Berlin, Heidelberg; Raptis, G.E., Katsini, C., Belk, M., Fidas, C., Samaras, G., Avouris, N., Using eye gaze data and visual activities to infer human cognitive styles (2017) Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization - UMAP’17, pp. 164-173. , https://doi.org/10.1145/3079628.3079690, ACM Press, New York, New York, USA; Rousseeuw, P.J., Silhouettes: A graphical aid to the interpretation and validation of cluster analysis (1987) J. Comput. Appl. Math., 20, pp. 53-65. , https://doi.org/10.1016/0377-0427(87)90125-7, nov 1987; Agustin, J.S., Skovsgaard, H., Mollenbach, E., Barret, M., Tall, M., Hansen, D.W., Hansen, J.P., Evaluation of a low-cost open-source gaze tracker (2010) Proceedings of the 2010 Symposium on Eye-Tracking Research & Applications - ETRA’10, p. 77. , https://doi.org/10.1145/1743666.1743685, ACM Press, New York, New York, USA; Shin, D., Kovalenko, M., Ersoy, I., Li, Y., Doll, D., Shyu, C.-R., Hammer, R., PathEdEx - Uncovering High-explanatory Visual Diagnostics Heuristics Using Digital Pathology and Multiscale Gaze Data (2017) Journal of Pathology Informatics, 8, p. 29. , https://doi.org/10.4103/jpi.jpi_29_17, jul 2017; Simola, J., Salojärvi, J., Kojo, I., Using hidden Markov model to uncover processing states from eye movements in information search tasks (2008) Cognitive Systems Research, 9 (4), pp. 237-251. , https://doi.org/10.1016/J.COGSYS.2008.01.002, oct 2008; West, J.M., Haake, A.R., Rozanski, E.P., Karn, K.S., Eyepatterns: Software for identifying patterns and similarities across fixation sequences (2006) Proceedings of the 2006 Symposium on Eye Tracking Research & Applications - ETRA ’06, p. 149. , https://doi.org/10.1145/1117309.1117360, ACM Press, New York, New York, USA},
editor={Spencer S.N.},
sponsors={ACM SIGCHI; ACM SIGGRAPH},
publisher={Association for Computing Machinery},
isbn={9781450367097},
language={English},
abbrev_source_title={Eye Track. Res. Appl. Symp. (ETRA)},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Kong2019,
author={Kong, H.-K. and Liu, Z. and Zhu, W. and Karahalios, K.},
title={Understanding visual cues in visualizations accompanied by audio narrations},
journal={Conference on Human Factors in Computing Systems - Proceedings},
year={2019},
doi={10.1145/3290605.3300280},
note={cited By 0; Conference of 2019 CHI Conference on Human Factors in Computing Systems, CHI 2019 ; Conference Date: 4 May 2019 Through 9 May 2019;  Conference Code:147770},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067609589&doi=10.1145%2f3290605.3300280&partnerID=40&md5=49d97f0f879429947a5fc3d7110ce6e4},
affiliation={University of Illinois Urbana-Champaign, Urbana, IL, United States; Adobe Research, Seattle, WA, United States; Adobe Research, UIUC, San Francisco, CA, United States},
abstract={It is often assumed that visual cues, which highlight specific parts of a visualization to guide the audience’s attention, facilitate visualization storytelling and presentation. This assumption has not been systematically studied. We present an in-lab experiment and a Mechanical Turk study to examine the effects of integral and separable visual cues on the recall and comprehension of visualizations that are accompanied by audio narration. Eye-tracking data in the in-lab experiment confirm that cues helped the viewers focus on relevant parts of the visualization faster. We found that in general, visual cues did not have a significant effect on learning outcomes, but for specific cue techniques (e.g. glow) or specific chart types (e.g heatmap), cues significantly improved comprehension. Based on these results, we discuss how presenters might select visual cues depending on the role of the cues and the visualization type. © 2019 Copyright held by the owner/author(s).},
author_keywords={Learning;  Narrative visualization;  Visual cues},
keywords={Data visualization;  Eye tracking;  Human computer interaction;  Human engineering, Audio narrations;  Experiment confirm;  Learning;  Learning outcome;  Mechanical turks;  Visual cues, Visualization},
references={Boucheix, J.-M., Lowe, R.K., An eye tracking comparison of external pointing cues and internal continuous cues in learning with complex animations (2010) Learning and Instruction, 20 (2), pp. 123-135. , 2010; Boy, J., Detienne, F., Fekete, J.-D., Storytelling in information visualizations: Does it engage users to explore data? (2015) Proceedings of the ACM CHI’15 Conference on Human Factors in Computing Systems, 1, pp. 1449-1458. , https://doi.org/10.1145/2702123.2702452, February 2016 2015; Cavender, A.C., Bigham, J.P., Ladner, R.E., ClassinFocus: Enabling improved visual attention strategies for deaf and hard of hearing students (2009) Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility, pp. 67-74. , ACM; Cole, F., DeCarlo, D., Finkelstein, A., Kin, K., Morley, R.K., Santella, A., Directing gaze in 3D models with stylized focus (2006) Rendering Techniques, 2006 (2006), p. 17th; De Koning, B.B., Jarodzka, H., Attention guidance strategies for supporting learning from dynamic visualizations (2017) Learning from Dynamic Visualization, pp. 255-278. , Springer; De Koning, B.B., Tabbers, H.K., Rikers, R.M.J.P., Paas, F., Attention cueing as a means to enhance learning from an animation (2007) Applied Cognitive Psychology, 21 (6), pp. 731-746. , 2007; De Koning, B.B., Tabbers, H.K., Rikers, R.M.J.P., Paas, F., Attention guidance in learning from a complex animation: Seeing is understanding? (2010) Learning and Instruction, 20 (2), pp. 111-122. , 2010; De Koning, B.B., Tabbers, H.K., Rikers, R.M.J.P., Paas, F., Attention cueing as a means to enhance learning from an animation (2007) Applied Cognitive Psychology, 21 (6), pp. 731-746. , https://doi.org/10.1002/acp.1346, sep 2007; De Koning, B.B., Tabbers, H.K., Rikers, R.M.J.P., Paas, F., Attention guidance in learning from a complex animation: Seeing is understanding? (2010) Learning and Instruction, 20 (2), pp. 111-122. , https://doi.org/10.1016/j.learninstruc.2009.02.010, 2010; Gao, T., Hullman, J.R., Adar, E., Hecht, B., Diakopoulos, N., NewsViews: An automated pipeline for creating custom geovisualizations for news (2014) Proceedings of the 32nd Annual ACM Conference on Human Factors in Computing Systems - CHI’14, (2014), pp. 3005-3014. , https://doi.org/10.1145/2556288.2557228; Garner, W.R., Interaction of stimulus dimensions in concept and choice processes (1976) Cognitive Psychology, 8 (1), pp. 98-123. , 1976; Aisch, G., Gebeloff, R., (2015) The Changing Nature of Middle-Class Jobs, , https://www.nytimes.com/interactive/2015/02/23/business/economy/the-changing-nature-of-middle-class-jobs.html, Feb. 2015; Griffin, A.L., Robinson, A.C., Comparing color and leader line highlighting strategies in coordinated view geovisualizations (2015) IEEE Transactions on Visualization and Computer Graphics, 21 (3), pp. 339-349. , 2015; Hoffmann, R., Baudisch, P., Weld, D.S., Evaluating visual cues for window switching on large screens (2008) Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 929-938. , ACM; Hullman, J., Diakopoulos, N., Visualization rhetoric: Framing effects in narrative visualization (2011) IEEE Transactions on Visualization and Computer Graphics, 17 (12), pp. 2231-2240. , https://doi.org/10.1109/TVCG.2011.255, 2011; Hullman, J., Diakopoulos, N., Adar, E., Con-textifier: Automatic generation of annotated stock visualizations (2013) Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI’13, (2013), p. 2707. , https://doi.org/10.1145/2470654.2481374; Hullman, J., Drucker, S., Riche, N.H., Lee, B., Fisher, D., Adar, E., A deeper understanding of sequence in narrative visualization (2013) IEEE Transactions on Visualization and Computer Graphics, 19 (12), pp. 2406-2415. , https://doi.org/10.1109/TVCG.2013.119, 2013; Kong, H.-K., Liu, Z., Karahalios, K., Internal and external visual cue preferences for visualizations in presentations (2017) Computer Graphics Forum, 36, pp. 515-525. , Wiley Online Library; Kosara, R., Mackinlay, J., Storytelling: The next step for visualization (2013) Computer, pp. 44-50. , http://kosara.net/papers/2013/Kosara, 2013; Lee, S., Kim, S.-H., Kwon, B.C., VLAT: Development of a visualization literacy assessment test (2017) IEEE Transactions on Visualization and Computer Graphics, 23 (1), pp. 551-560. , 2017; Lin, L., Atkinson, R.K., Using animations and visual cueing to support learning of scientific concepts and processes (2011) Computers & Education, 56 (3), pp. 650-658. , 2011; Oelke, D., Janetzko, H., Simon, S., Neuhaus, K., Keim, D.A., Visual boosting in pixel-based visualizations (2011) Computer Graphics Forum, 30, pp. 871-880. , Wiley Online Library; Ren, D., Brehmer, M., Lee, B., Hollerer, T., Choe, E.K., Chartaccent: Annotation for data-driven storytelling (2017) 2017 IEEE Pacific Visualization Symposium (PacificVis), pp. 230-239. , IEEE; Segel, E., Heer, J., Narrative visualization: Telling stories with data (2010) IEEE Transactions on Visualization and Computer Graphics, 16, pp. 1139-1148. , https://doi.org/10.1109/TVCG.2010.179; (2017) Much of Sub-Saharan Africa, Mobile Phones Are More Common Than Access to Electricity, , https://www.economist.com/graphic-detail/2017/11/08/in-much-of-sub-saharan-africa-mobile-phones-are-more-common-than-access-to-electricity, Nov. 2017; (2018) How Heavy Use of Social Media Is Linked to Mental Illness, , https://www.economist.com/graphicdetail/2018/05/18/how-heavy-use-of-social-media-is-linked-to-mental-illness, May 2018; (2018) Which Traits Predict Graduates’ Earnings?, , https://www.economist.com/graphic-detail/2018/06/15/which-traits-predict-graduates-earnings, 2018},
sponsors={ACM SIGCHI},
publisher={Association for Computing Machinery},
isbn={9781450359702},
language={English},
abbrev_source_title={Conf Hum Fact Comput Syst Proc},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Fujii2019,
author={Fujii, K. and Rekimoto, J.},
title={Subme an interactive subtitle system with english skill estimation using eye tracking},
journal={ACM International Conference Proceeding Series},
year={2019},
doi={10.1145/3311823.3311865},
art_number={a23},
note={cited By 0; Conference of 10th Augmented Human International Conference, AH 2019 ; Conference Date: 11 March 2019 Through 12 March 2019;  Conference Code:145912},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062936751&doi=10.1145%2f3311823.3311865&partnerID=40&md5=3129b332df8fcb1656ef87c527b6e7cd},
affiliation={University of Tokyo Bunkyo-ku, Tokyo, Japan; University of Tokyo, Sony Computer Science Laboratories Inc., Tokyo, Japan},
abstract={Owing to the improvement in accuracy of eye tracking devices, eye gaze movements occurring while conducting tasks are now a part of physical activities that can be monitored just like other life-logging data. Analyzing eye gaze movement data to predict reading comprehension has been widely explored and researchers have proven the potential of utilizing computers to estimate the skills and expertise level of users in various categories, including language skills. However, though many researchers have worked specifically on written texts to improve the reading skills of users, little research has been conducted to analyze eye gaze movements in correlation to watching movies, a medium which is known to be a popular and successful method of studying English as it includes reading, listening, and even speaking, the later of which is attributed to language shadowing. In this research, we focus on movies with subtitles due to the fact that they are very useful in order to grasp what is occurring on screen, and therefore, overall understanding of the content. We realized that the viewers' eye gaze movements are distinct depending on their English level. After retrieving the viewers' eye gaze movement data, we implemented a machine learning algorithm to detect their English levels and created a smart subtitle system called SubMe. The goal of this research is to estimate English levels through tracking eye movement. This was conducted by allowing the users to view a movie with subtitles. Our aim is create a system that can give the user certain feedback that can help improve their English studying methods. ©2019 Association for Computing Machinery.},
author_keywords={Human computer interaction;  Learning;  User interface},
keywords={Eye movements;  Human computer interaction;  Learning algorithms;  Machine learning;  Motion pictures;  User interfaces, English skills;  Eye tracking devices;  Learning;  Lifelogging;  Physical activity;  Reading comprehension;  Reading skills;  Written texts, Eye tracking},
references={D'Ydewalle, G., Foreign-language acquisition by watching subtitled television ProgramsJournal of Foreign Language Education and Research, p. 12; Secules, T., Herron, C., Tomasello, M., The effect of video context on foreign language learning The Modern Language Journal, 76 (4), pp. 480-490. , 1992; Bisson, M.-J., Van Heuven, W.J.B., Conklin, K., Tunney, R.J., Processing of native and foreign language subtitles in films: An eye tracking study (2014) Applied Psycholinguistics, 35, pp. 399-418; Fukunaga, N., Those anime students: Foreign language literacy development through Japanese popular culture Journal of Adolescent & Adult Literacy, 50 (3), pp. 206-222. , 2006; Conklin, K., Pellicer-Sanchez, A., Using eye-tracking in applied linguistics and second language research (2016) Second Language Research, 32 (3), pp. 453-467; Montero Perez, M., Peters, E., Desmet, P., Enhancing vocabulary learning through captioned video: An eye? Tracking study (2015) The Modern Language Journal, 99 (2), pp. 308-328; Rayner, K., Eye movements in reading and information processing: 20 years of research Psychological Bulletin, 124 (3), pp. 372-422. , Nov 1998; Buscher, G., Dengel, A., Gaze-based filtering of relevant document segments (2019) International World Wide Web Conference (WWW)., pp. 20-24; Bulling, A., Ward, J.A., Gellersen, H., Troster, G., Robust recognition of reading activity in transitusing wearable electrooculography Proc. Of Pervasive, 8, pp. 19-37; Dimigen, O., Sommer, W., Hohlfeld, A., Jacobs, A., Kliegl, R., Coregistration of eye movements andeeg in natural reading: Analyses and review Journalof Experimental Psychology: General, 140 (4), p. 552. , 2011; Yoshimura, K., Kise, K., Kunze, K., The eye as the window of the language ability: Estimation of English skills by analyzing eye movement while reading documents 2015 13th International Conference on Document Analysis and Recognition (ICDAR), , ISBN:978-1-4799-1805-8, 23-26 Aug. 2015, Electronic; Berzak, Y., Katz, B., Levy, R., Assessing Language Proficiency from Eye Movements in Reading Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 1, pp. 1986-1996. , 10.18653/v1/N18-1180; Augereau, O., Kunze, K., Fujiyoshi, H., Kise, K., Estimation of english skill with a mobile eye tracker UbiComp'16 Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct, pp. 1777-1781. , ISBN:978-1-4503-4462-3, Heidelberg, Germany September 12 - 16, 2016; Kunze, K., Kawaichi, H., Yoshimura, K., Kise, K., Towards inferring language expertise using eye tracking CHI'13 Extended Abstracts on Human Factors in Computing Systems, pp. 217-222. , 10.1145/2468356.2468396, Pages; Chujo, K., Oghigian, K., How many words do you need to know to understand TOEIC, TOEFL & EIKEN An examination of text coverage and high frequency vocabulary Journal of Asia TEFL, 6 (2), pp. 121-148. , 2009; Nez-Gomez, P.M., Aizawa, A., Recognition of understanding level and language skill using measurements of reading behavior Proceedings of the 19th International Conference on Intelligent User Interfaces, pp. 95-104. , ACM; Copeland, L., Gedeon, T., Mendis, B., Predicting reading comprehension scores from eye movements using artificial neural networks and fuzzy output error Artificial Intelligence Research., 3, p. 2014. , 10.5430/air.v3n3p35.8; Wang, S., Wang, L., Movie dictionary: A multimedia lexicon tool for language learning (2010) IEEE International Conference on Computer Science and Information Technology, pp. 484-487; Zhu, Y., (2017) ViVo: Video-Augmented Dictionary for Vocabulary Learning CHI Conference on Human Factors in Computing Systems, pp. 5568-5579; Kovacs, G., Smart subtitles for language learning (2013) CHI EA'13 CHI'13 Extended Abstracts on Human Factors in Computing Systems, , ISBN:978-1-4503-1952-2, Paris, France April 27 - May 02; Kovacs, G., Miller, R.C., Smart subtitles for vocabulary learnin (2014) CHI'14 Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 853-862. , ISBN:978-1-4503-2473-1, g, Toronto, Ontario, Canada April 26 - May 01; Kurzhals, K., Cetinkaya, E., Hu, Y., Wang, W., Weiskopf, D., Close to the Action: Eye-Tracking Evaluation of Speaker-Following Subtitles CHI 17 Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, pp. 6559-6568. , ISBN:978-1-4503-4655-9, Denver, Colorado, USA May 06 - 11, 2017; Ma, Q., Wang, S., Liu, J., Li, N., Interactive subtitle: Subtitle interaction for language learning ChineseCHI'18 Proceedings of the Sixth International Symposium of Chinese CHI, pp. 116-119. , ISBN:978-1-4503-6508-6, Montreal, QC, Canada April 21 - 22, 2018; Openframeworks, , http://www.openframeworks.cc; The Corpus of Contemporary American English (COCA)., , https://corpus.byu.edu/coca; Prinzie, A., Van Den Poel, D., Random Forests for multiclass classification: Random (2008) MultiNomial Logit Expert Systems with Applications, 34 (3), pp. 1721-1732; Wesche, M., Paribakht, T.S., Assessing Second Language Vocabulary Knowledge: Depth versus BreadthCanadian Modern Language Review, 53 (1), pp. 13-40. , 1996; Papoutsaki, A., Scalable webcam eye tracking by learning from user interactions HI EA'15 Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems, pp. 219-222. , ISBN:978-1-4503-3146-3, Seoul, Republic of Korea April 18 - 23, 2015; Flesch, R., A new readability yardstick Journal of Applied Psychology, 32, pp. 221-233; Dale, E., Chall, J.A., Formula for Predicting ReadabilityEducational Research Bulletin, 27, pp. 11-20; Sugai, K., Yamane, S., Kanzaki, K., The Time Domain Factors Affecting EFL Learners Listening Comprehension: A study on Japanese (2016) EFL Learners Annual Review of English Language Education in Japan, 27, pp. 97-108},
publisher={Association for Computing Machinery},
isbn={9781450365475},
language={English},
abbrev_source_title={ACM Int. Conf. Proc. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Christoforou2017,
author={Christoforou, C. and Papadopoulos, T.C. and Constantinidou, F. and Theodorou, M.},
title={Your brain on the movies: A computational approach for predicting box-office performance from viewer’s brain responses to movie trailers},
journal={Frontiers in Neuroinformatics},
year={2017},
volume={11},
doi={10.3389/fninf.2017.00072},
art_number={72},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043783896&doi=10.3389%2ffninf.2017.00072&partnerID=40&md5=cfee4fa365445f79ffa6a5402c7b4f76},
affiliation={Division of Computer Science, Mathematics and Science, St. John’s University, New York, NY, United States; Division of Research and Development, R.K.I Leaders Ltd., Larnaca, Cyprus; Center for Applied Neuroscience, University of Cyprus, Nicosia, Cyprus; Department of Psychology, University of Cyprus, Nicosia, Cyprus},
abstract={The ability to anticipate the population-wide response of a target audience to a new movie or TV series, before its release, is critical to the film industry. Equally important is the ability to understand the underlying factors that drive or characterize viewer’s decision to watch a movie. Traditional approaches (which involve pilot test-screenings, questionnaires, and focus groups) have reached a plateau in their ability to predict the population-wide responses to new movies. In this study, we develop a novel computational approach for extracting neurophysiological electroencephalography (EEG) and eye-gaze based metrics to predict the population-wide behavior of movie goers. We further, explore the connection of the derived metrics to the underlying cognitive processes that might drive moviegoers’ decision to watch a movie. Towards that, we recorded neural activity—through the use of EEG—and eye-gaze activity from a group of naive individuals while watching movie trailers of pre-selected movies for which the population-wide preference is captured by the movie’s market performance (i.e., box-office ticket sales in the US). Our findings show that the neural based metrics, derived using the proposed methodology, carry predictive information about the broader audience decisions to watch a movie, above and beyond traditional methods. In particular, neural metrics are shown to predict up to 72% of the variance of the films’ performance at their premiere and up to 67% of the variance at following weekends; which corresponds to a 23-fold increase in prediction accuracy compared to current neurophysiological or traditional methods. We discuss our findings in the context of existing literature and hypothesize on the possible connection of the derived neurophysiological metrics to cognitive states of focused attention, the encoding of long-term memory, and the synchronization of different components of the brain’s rewards network. Beyond the practical implication in predicting and understanding the behavior of moviegoers, the proposed approach can facilitate the use of video stimuli in neuroscience research; such as the study of individual differences in attention-deficit disorders, and the study of desensitization to media violence. © 2017 Christoforou, Papadopoulos, Constantinidou and Theodorou.},
author_keywords={EEG;  Eye-tracking;  Film test screening;  Neuro-cinematics;  Neuro-marketing;  Pilot test screening},
keywords={accuracy;  adult;  Article;  attention deficit disorder;  behavior;  cognition;  cognitive neuroscience;  computer analysis;  cortical synchronization;  electroencephalography;  eye movement;  female;  functional magnetic resonance imaging;  human;  human experiment;  long term memory;  male;  neurophysiology;  normal human;  prediction;  program effectiveness;  questionnaire;  social marketing;  young adult},
funding_details={European CommissionEuropean Commission, 8.1.12.13.1.1.177},
funding_text 1={This work was partially supported by the Ministry of Commerce of Cyprus through the grant co-funded by the European Structural Funds and the European Union (CC, PI: #8.1.12.13.1.1.177).},
references={Berns, G.S., Moore, S.E., A neural predictor of cultural popularity (2012) J. Consum. Psychol., 22, pp. 154-160; Blankertz, B., Tomioka, R., Lemm, S., Kawanabe, M., Muller, K.-R., Optimizing spatial filters for robust EEG single-trial analysis (2008) IEEE Signal Process. Mag., 25, pp. 41-56; Boksem, M.A.S., Smidts, A., Brain responses to movie trailers predict individual preferences for movies and their population-wide commercial success (2015) J. Mark. Res., 52, pp. 482-492; Christoforou, C., Christou-Champi, S., Constantinidou, F., Theodorou, M., From the eyes and the heart: A novel eye-gaze metric that predicts video preferences of a large audience (2015) Front. Psychol., 6, p. 579; Christoforou, C., Constantinidou, F., Shoshilou, P., Simos, P.G., Single-trial linear correlation analysis: Application to characterization of stimulus modality effects (2013) Front. Comput. Neurosci., 7, p. 15; Christoforou, C., Mavridis, N., Machado, E.L., Spanoudis, G., Android tele-operation through brain-computer interfacing: A real-world demo with non-expert users (2010) Proceedings of the 2010 International Symposium on Robotics and Intelligent Sensors (IRIS2010) (Nagoya, pp. 294-299; Christoforou, C., Sajda, P., Parra, L.C., Second order bilinear discriminant analysis for single trial EEG analysis (2008) Advances in Neural Information Processing Systems, 20, pp. 313-320. , J. Platt, D. Koller, Y. Singer and S. Roweis (Vancouver, BC: Curran Associates, Inc.); Clauss, M., Bayerl, P., Neumann, H., (2004) A Statistical Measure for Evaluating Regions-Of-Interest Based Attention Algorithms, 3175, pp. 383-390. , in Pattern Recognition, eds C. E. Rasmussen, H. H. Bülthoff, B. Schölkopf and M. A. Giese (Berlin, Heidelberg: Springer Berlin Heidelberg; Das, J.P., (2016) Consciousness Quest: Where East Meets West, on Mind, Meditation, and Neural Correlates, , New Delhi: Sage Publications; Dmochowski, J.P., Bezdek, M.A., Abelson, B.P., Johnson, J.S., Schumacher, E.H., Parra, L.C., Audience preferences are predicted by temporal reliability of neural processing (2014) Nat. Commun., 5; Dmochowski, J.P., Sajda, P., Dias, J., Parra, L.C., Correlated components of ongoing EEG point to emotionally laden attention—a possible marker of engagement? (2012) Front. Hum. Neurosci., 6; Dorr, M., Martinetz, T., Gegenfurtner, K.R., Barth, E., Variability of eye movements when viewing dynamic natural scenes (2010) J. Vis., 10, p. 28; Dyrholm, M., Christoforou, C., Parra, L.C., Bilinear discriminant component analysis (2007) J. Mach. Learn. Res, 8, pp. 1097-1111. , http://www.jmlr.org/papers/volume8/dyrholm07a/dyrholm07a.pdf, Available online at; Eastman, S.T., Ferguson, D.A., (2012) Media Programming: Strategies and Practices, , http://books.google.com/books?id=xqslYAAACAAJ; Eckstein, M.K., Guerra-Carrillo, B., Miller Singley, A.T., Bunge, S.A., Beyond eye gaze: What else can eyetracking reveal about cognition and cognitive development? (2017) Dev. Cogn. Neurosci., 25, pp. 69-91; Engel, A.K., Fries, P., Singer, W., Dynamic predictions: Oscillations and synchrony in top-down processing (2001) Nat. Rev. Neurosci., 2, pp. 704-716; Falk, E.B., Berkman, E.T., Lieberman, M.D., From neural responses to population behavior: Neural focus group predicts population-level media effects (2012) Psychol. Sci., 23, pp. 439-445; Fanti, K.A., Panayiotou, G., Lombardo, M.V., Kyranides, M.N., Unemotional on all counts: Evidence of reduced affective responses in individuals with high callous-unemotional traits across emotion systems and valences (2016) Soc. Neurosci, 11, pp. 72-87; Fell, J., Klaver, P., Lehnertz, K., Grunwald, T., Schaller, C., Elger, C.E., Human memory formation is accompanied by rhinal-hippocampal coupling and decoupling (2001) Nat. Neurosci., 4, pp. 1259-1264; Goldstein, R.B., Woods, R.L., Peli, E., Where people look when watching movies: Do all viewers look at the same place? (2007) Comput. Biol. Med., 37, pp. 957-964; Hennig-Thurau, T., Houston, M.B., Walsh, G., Determinants of motion picture box office and profitability: An interrelationship approach (2007) Rev. Manage. Sci., 1, pp. 65-92; Howard, M.W., Rizzuto, D.S., Caplan, J.B., Madsen, J.R., Lisman, J., Aschenbrenner-Scheibe, R., Gamma oscillations correlate with working memory load in humans (2003) Cereb. Cortex, 13, pp. 1369-1374; Kong, W., Zhao, X., Hu, S., Zhang, J., Dai, G., Vecchiato, G., The study of memorization index based on W-GFP during the observation of TV commercials (2012) Proceedings of the International Conference on Systems and Informatics (ICSAI2012), pp. 2198-2202. , (Yantai, China: IEEE; Mantini, D., Perrucci, M.G., Del Gratta, C., Romani, G.L., Corbetta, M., Electrophysiological signatures of resting state networks in the human brain (2007) Proc. Natl. Acad. Sci. U S A, 104, pp. 13170-13175; Mathôt, S., Schreij, D., Theeuwes, J., OpenSesame: An open-source, graphical experiment builder for the social sciences (2012) Behav. Res. Methods, 44, pp. 314-324; Müller, M.M., Gruber, T., Keil, A., Modulation of induced gamma band activity in the human EEG by attention and visual information processing (2000) Int. J. Psychophysiol., 38, pp. 283-299; Parra, L., Christoforou, C., Gerson, A., Dyrholm, M., Luo, A., Wagner, M., Spatiotemporal linear decoding of brain state (2008) IEEE Signal Process. Mag., 25, pp. 107-115; Rajashekar, U., Cormack, L.K., Bovik, A.C., (2004) Point-Of-Gaze Analysis Reveals Visual Search Strategies, pp. 296-306. , in Electronic Imaging 2004, eds E. B. Rogowitz and T. N. Pappas (San Jose, CA: International Society for Optics and Photonics); Rodriguez, E., George, N., Lachaux, J.P., Martinerie, J., Renault, B., Varela, F.J., Perception’s shadow: Long-distance synchronization of human brain activity (1999) Nature, 397, pp. 430-433; Smith, T.J., Watching you watch movies: Using eye tracking to inform cognitive film theory (2013) Psychocinematics: Exploring Cognition at the Movies, pp. 165-191. , Chapter 9, ed. A. P. Shimamura (New York, NY: Oxford University Press; Smith, T.J., Mital, P.K., Attentional synchrony and the influence of viewing task on gaze behavior in static and dynamic scenes (2013) J. Vis., 13, p. 16; Vecchiato, G., Kong, W., Giulio Maglione, A., Cherubino, P., Trettel, A., Babiloni, F., Cross-cultural analysis of neuroelectrical cognitive and emotional variables during the appreciation of TV commercials (2014) Neuropsychol. Trends, 16, pp. 23-29; Vecchiato, G., Maglione, A.G., Cherubino, P., Wasikowska, B., Wawrzyniak, A., Latuszynska, A., Neurophysiological tools to investigate consumer’s gender differences during the observation of TV commercials (2014) Comput. Math. Methods Med., 2014; Vecchiato, G., Toppi, J., Astolfi, L., de Vico Fallani, F., Cincotti, F., Mattia, D., Spectral EEG frontal asymmetries correlate with the experienced pleasantness of TV commercial advertisements (2011) Med. Biol. Eng. Comput., 49, pp. 579-583},
correspondence_address1={Christoforou, C.; Division of Computer Science, Mathematics and Science, St. John’s UniversityUnited States; email: christoc@stjohns.edu},
publisher={Frontiers Media S.A.},
issn={16625196},
language={English},
abbrev_source_title={Front. Neuroinformatics},
document_type={Article},
source={Scopus},
}

@ARTICLE{Ishikawa20151526,
author={Ishikawa, E. and Kawashima, H. and Matsuyama, T.},
title={Using designed structure of visual content to understand content-browsing behavior},
journal={IEICE Transactions on Information and Systems},
year={2015},
volume={E98D},
number={8},
pages={1526-1535},
doi={10.1587/transinf.2014EDP7422},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938948832&doi=10.1587%2ftransinf.2014EDP7422&partnerID=40&md5=eb63327e82698b5c4b141cf0ca5109bf},
affiliation={Graduate School of Informatics, Kyoto University, Kyoto-shi, 606-8501, Japan},
abstract={Studies on gaze analysis have revealed some of the relationships between viewers' gaze and their internal states (e.g., interests and intentions). However, understanding content browsing behavior in uncontrolled environments is still challenging because human gaze can be very complex; it is affected not only by viewers' states but also by the spatio-semantic structures of visual content. This study proposes a novel gaze analysis framework which introduces the content creators' point of view to understand the meaning of browsing behavior. Visual content such as web pages, digital articles and catalogs are comprised of structures intentionally designed by content creators, which we refer to as designed structure. This paper focuses on two design factors of designed structure: spatial structure of content elements (content layout), and their relationships such as "being in the same group". The framework was evaluated with an experiment involving 12 participants, wherein the participant's state was estimated from their gaze behavior. The results from the experiment show that the use of design structure improved estimation accuracies of user states compared to other baseline methods. Copyright © 2015 The Institute of Electronics, Information and Communication Engineers.},
author_keywords={Catalog browsing;  Content design;  Eye tracking;  User states},
keywords={Semantics;  Websites, Browsing behavior;  Catalog browsing;  Content creators;  Content design;  Eye-tracking;  Semantic structures;  Spatial structure;  User states, Structural design},
references={Yarbus, A., (1967) Eye Movements and Vision, , Plenum Press; Jacob, R.J.K., Karn, K.S., Commentary on section 4. Eye tracking in human-computer interaction and usability research: Ready to deliver the promises (2003) The Mind's Eye: Cognitive and Applied Aspects of Eye Movement Research, pp. 573-605. , ed. R. Radach, J. Hyona, and H. Deubel, North Holland; Russo, J.E., Rosen, L.D., An eye fixation analysis of multialter-native choice (1975) Mem. Cogn., 3 (3), pp. 267-276; Takagi, H., Recognizing users' uncertainty on the basis of eye movement patterns: A step toward an effective task assistance system (2000) J. IPS Japan, 41 (5), pp. 1317-1327; Nakano, Y.I., Ishii, R., Estimating user's engagement from eye-gaze behaviors in human-agent conversations (2010) Proc. International Conference on Intelligent User Interfaces (IUI2010), pp. 139-148; Qvarfordt, P., Zhai, S., Conversing with the user based on eye-gaze patterns (2005) Proc. ACM Conf. on Human Factors in Computing Systems (CHI2005), pp. 221-230; Goldberg, J.H., Stimson, M.J., Lewenstein, M., Scott, N., Wichansky, A.M., Eye tracking in web search tasks: Design implications (2002) Proc. Symposium on Eye Tracking Research and Applications (ETRA2002), pp. 51-58. , New York, NY, USA, ACM; Steichen, B., Wu, M.M.A., Toker, D., Conati, C., Carenini, G., Te, Te, Hi, Hi: Eye gaze sequence analysis for informing user-adaptive information visualizations (2014) Proc. International Conference on User Modeling, Adaptation, and Personalization (UMAP2014), 8538, pp. 183-194. , Springer International Publishing, Cham; Resnick, M.L., Albert, W., The impact of advertising location and user task on the emergence of banner ad blindness: An eye tracking study (2013) Proc. Human Factors and Ergonomics Society Annual Meeting, 57 (1), pp. 1037-1041; Bednarik, R., Vrzakova, H., Hradis, M., What do you want to do next: A novel approach for intent prediction in gaze-based interaction (2012) Proc. Symposium on Eye Tracking Research and Applications (ETRA2012), pp. 83-90; Sugano, Y., Ozaki, Y., Kasai, H., Ogaki, K., Image preference estimation with a data-driven approach: A comparative study between gaze and image features (2014) Eye Movement Research, 7 (3), pp. 1-9; Pasupa, K., Saunders, C.J., Szedmak, S., Klami, A., Kaski, S., Gunn, S.R., Learning to rank images from eye movements (2009) International Conference on Computer Vision Workshops (ICCV Workshops), pp. 2009-2016; Chen, L., Pu, P., Users' eye gaze pattern in organization-based recommender interfaces (2011) Proc. International Conference on Intelligent User Interfaces (IUI2011), pp. 311-314. , ACM Press; Pan, B., Hembrooke, H.A., Gay, G.K., Granka, L.A., Feusner, M.K., Newman, J.K., The seterminants of web page viewing behavior: An eye-tracking study (2004) Proc. Symposium on Eye Tracking Research and Applications (ETRA2004), pp. 147-154; Kotler, P., (2000) Marketing Management, , Millenium Edition, Prentice-Hall; Breiman, L., Random forests (2001) Machine Learning, 45 (1), pp. 5-32; Shimonishi, K., Kawashima, H., Yonetani, R., Ishikawa, E., Matsuyama, T., Learning aspects of interest from gaze (2013) Proc. the 6th Workshop on Eye Gaze in Intelligent Human Machine Interaction (Gaze-in 2013), pp. 41-44},
publisher={Maruzen Co., Ltd.},
issn={09168532},
coden={ITISE},
language={English},
abbrev_source_title={IEICE Trans Inf Syst},
document_type={Article},
source={Scopus},
}

@ARTICLE{Alers201569,
author={Alers, H. and Redi, J.A. and Heynderickx, I.},
title={Quantifying the importance of preserving video quality in visually important regions at the expense of background content},
journal={Signal Processing: Image Communication},
year={2015},
volume={32},
pages={69-80},
doi={10.1016/j.image.2015.01.006},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924366009&doi=10.1016%2fj.image.2015.01.006&partnerID=40&md5=6f0e12e032e33b5bc536e5ae6517e331},
affiliation={Delft University of Technology, Mekelweg 4, Delft, 2628 CD, Netherlands; Philips Research Laboratories, Prof. Holstlaan 4, Eindhoven, 5656 AA, Netherlands},
abstract={Advances in digital technology have allowed us to embed significant processing power in everyday video consumption devices. At the same time, we have placed high demands on the video content itself by continuing to increase spatial resolution while trying to limit the allocated file size and bandwidth as much as possible. The result is typically a trade-off between perceptual quality and fulfillment of technological limitations. To bring this trade-off to its optimum, it is necessary to understand better how people perceive video quality. In this work, we particularly focus on understanding how the spatial location of compression artifacts impacts visual quality perception, and specifically in relation with visual attention. In particular we investigate how changing the quality of the region of interest of a video affects its overall perceived quality, and we quantify the importance of the visual quality of the region of interest to the overall quality judgment. A three stage experiment was conducted where viewers were shown videos with different quality levels in different parts of the scene. By asking them to score the overall quality we found that the quality of the region of interest has 10 times more impact than the quality of the rest of the scene. These results are in line with similar effects observed in still images, yet in videos the relevance of the visual quality of the region of interest is twice as high than in images. The latter finding is directly relevant for the design of more accurate objective quality metrics for videos, that are based on the estimation of local distortion visibility. © 2015 Elsevier B.V. All rights reserved.},
author_keywords={Eye tracking;  Perception;  Region of interest;  ROI;  Video quality},
keywords={Behavioral research;  Digital devices;  Economic and social effects;  Image segmentation;  Sensory perception, Compression artifacts;  Digital technologies;  Eye-tracking;  Objective qualities;  Region of interest;  ROI;  Technological limitations;  Video quality, Video signal processing},
references={Cisco, I., (2012) Cisco Visual Networking Index: Forecast and Methodology, 2011-2016, , CISCO White Paper, 2011-2016; Haskell, B.G., (1997) Digital Video: An Introduction to MPEG-2: An Introduction to MPEG-2, , Springer; Schwarz, H., Marpe, D., Wiegand, T., Overview of the scalable video coding extension of the H. 264/AVC standard (2007) IEEE Trans. Circuits Syst. Video Technol., 17 (9), pp. 1103-1120; Sullivan, G.J., Ohm, J., Han, W.J., Wiegand, T., Overview of the high efficiency video coding (HEVC) standard (2012) IEEE Trans. Circuits Syst. Video Technol., 22 (12), pp. 1649-1668; Shao, L., Enhancement of compressed video signals using a local blockiness metric (2008) 2008 IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 1397-1400; Shao, L., Wang, J., Kirenko, I., De Haan, G., Quality adaptive least squares trained filters for video compression artifacts removal using a no-reference block visibility metric (2011) J. Visual Commun. Image Represent., 22 (1), pp. 23-32; Lin, W., Jay Kuo, C.C., Perceptual visual quality metrics: A survey (2011) J. Visual Commun. Image Represent., 22 (4), pp. 297-312; Hemami, S.S., Reibman, A.R., No-reference image and video quality estimation: Applications and human-motivated design (2010) Signal Process. Image Commun., 25 (7), pp. 469-481; Engelke, U., Kaprykowsky, H., Zepernick, H., Ndjiki-Nya, P., Visual attention in quality assessment (2011) IEEE Signal Process. Mag., 28 (6), pp. 50-59; Simons, D.J., Chabris, C.F., Gorillas in our midst: Sustained inattentional blindness for dynamic events (1999) Perception - London, 28 (9), pp. 1059-1074; Carrasco, M., Visual attention: The past 25 years (2011) Vision Res., 51 (13), pp. 1484-1525; Koch, C., Ullman, S., Shifts in selective visual attention: Towards the underlying neural circuitry (1987) Matters of Intelligence, pp. 115-141. , Springer The Netherlands; Smith, A.T., Singh, K.D., Greenlee, M.W., Attentional suppression of activity in the human visual cortex (2000) NeuroReport, 11 (2), pp. 271-278; Redi, J., Liu, H., Zunino, R., Heynderickx, I., Interactions of visual attention and quality perception (2011) International Society for Optics and Photonics, IS&T/SPIE Electronic Imaging, pp. 78650S-78650S. , February; Ninassi, A., Le Meur, O., Le Callet, P., Barba, D., Tirel, A., A. Task impact on the visual attention in subjective image quality assessment (2006) Proceedings of European Signal Processing Conference, , September; Vu, E.C.L., Chandler, D.M., Visual fixation patterns when judging image quality: Effects of distortion type, amount, and subject experience (2008) IEEE Southwest Symposium on Image Analysis and Interpretation, 2008, SSIAI 2008, pp. 73-76. , IEEE, March; Alers, H., Liu, H., Redi, J., Heynderickx, I., Studying the risks of optimizing the image quality in saliency regions at the expense of background content (2010) IS&T/SPIE Electronic Imaging. Image Quality and System Performance VII; Kowler, E., Eye movements: The past 25years (2011) Vision Res., 51 (13), pp. 1457-1483; Engelke, U., Pepion, R., Le Callet, P., Zepernick, H.J., Linking distortion perception and visual saliency in H. 264/AVC coded video containing packet loss (2010) International Society for Optics and Photonics Visual Communications and Image Processing 2010, July, pp. 774406-774406; Meur, O., Le Callet, P., What we see is most likely to be what matters: Visual attention and applications (2009) 16th IEEE International Conference on Image Processing (ICIP), 2009, IEEE, November, pp. 3085-3088; Le Meur, O., Ninassi, A., Le Callet, P., Barba, D., Overt visual attention for free-viewing and quality assessment tasks: Impact of the regions of interest on a video quality metric (2010) Signal Process. Image Commun., 25 (7), pp. 547-558; Engelke, U., Zepernick, H., Maeder, A., Visual attention modeling: Region-of-interest versus fixation patterns IEEE Picture Coding Symposium, 2009, PCS 2009, pp. 1-4. , May, 2009; Wang, J., Chandler, D.M., Callet, P.L., Quantifying the relationship between visual salience and visual importance (2010) International Society for Optics and Photonics IS&T/SPIE Electronic Imaging, February, pp. 75270K-75270K; Seshadrinathan, K., Soundararajan, R., Bovik, A.C., Cormack, L.K., A subjective study to evaluate video quality assessment algorithms (2010) International Society for Optics and Photonics IS&T/SPIE Electronic Imaging, February, pp. 75270H-75270H; Alers, H., Liu, H., Redi, J., Heynderickx, I., TUD Video Quality Database: Eye-Tracking Release 2, , http://www.mmi.tudelft.nl/iqlab/video_task_eye_tracking_1; Redi, J., Heynderickx, I., Macchiavello, B., Farias, M., On the impact of packet-loss impairments on visual attention mechanisms (2013) IEEE International Symposium on Circuits and Systems (ISCAS), IEEE, pp. 1107-1110. , May, 2013; Alers, H., Redi, J.A., Heynderickx, I., Examining the effect of task on viewing behavior in videos using saliency maps (2012) International Society for Optics and Photonics IS&T/SPIE Electronic Imaging, February, pp. 82910X-82910X; Redi Jaheynderickx, I., Image quality and visual attention interactions: Towards a more reliable analysis in the saliency space (2011) Third International Workshop on Quality of Multimedia Experience (QoMEX), 2011, IEEE, September, pp. 201-206; Recommendation, I.T.U.R.B.T., (2002) 500-11, Methodology for the Subjective Assessment of the Quality of Television Pictures, 4, p. 2. , International Telecommunication Union Geneva, Switzerland; Keelan, B., (2002) Handbook of Image Quality: Characterization and Prediction, , CRC Press; Engeldrum, P.G., (2000) Psychometric Scaling: A Toolkit for Imaging Systems Development, , Imcotek Press; De Ridder, H., Cognitive issues in image quality measurement (2001) J. Electron. Imaging, 10 (1), pp. 47-55; Redi, J., Liu, H., Alers, H., Zunino, R., Heynderickx, I., Comparing subjective image quality measurement methods for the creation of public databases (2010) International Society for Optics and Photonics IS&T/SPIE Electronic Imaging, pp. 752903-752903. , January; Sheikh, H.R., Sabir, M.F., Bovik, A.C., A statistical evaluation of recent full reference image quality assessment algorithms (2006) IEEE Trans. Image Process., 15 (11), pp. 3440-3451; Nisbett, R.E., Wilson, T.D., The halo effect: Evidence for unconscious alteration of judgments (1977) J. Pers. Soc. Psychol., 35 (4), p. 250; Lu, Z., Lin, W., Yang, X., Ong, E., Yao, S., Modeling visual attention's modulatory aftereffects on visual sensitivity and quality evaluation (2005) IEEE Trans. Image Process., 14 (11), pp. 1928-1942; You, J., Korhonen, J., Perkis, A., Attention modeling for video quality assessment: Balancing global quality and local quality (2010) IEEE International Conference on Multimedia and Expo (ICME), 2010, IEEE, July, pp. 914-919; Ninassi, A., Le Meur, O., Le Callet, P., Barbba, D., Does where you gaze on an image affect your perception of quality? Applying visual attention to image quality metric (2007) IEEE International Conference on Image Processing, 2007, ICIP 2007, IEEE, 2, pp. II-169. , September; Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., Image quality assessment: From error visibility to structural similarity (2004) IEEE Trans. Image Process., 13 (4), pp. 600-612},
correspondence_address1={Alers, H.; Delft University of Technology, Mekelweg 4, Netherlands},
publisher={Elsevier},
issn={09235965},
coden={SPICE},
language={English},
abbrev_source_title={Signal Process Image Commun},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wehrmeyer2014,
author={Wehrmeyer, J.},
title={Eye-tracking deaf and hearing viewing of sign language interpreted news broadcasts},
journal={Journal of Eye Movement Research},
year={2014},
volume={7},
number={1},
art_number={3},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897388501&partnerID=40&md5=1236008b7e84a357136fe04833991b17},
affiliation={North West University, South Africa},
abstract={In this study, the viewing habits of deaf and hearing adults are investigated using eye tracking while they watched interpreted news broadcasts. The study shows that deaf viewers primarily focus on the interpreter and secondarily access picture material, but make very little use of subtitles or lip-reading. In contrast, hearing viewers prioritise pictorial content but also spend significant proportions of time examining subtitles, lip-reading and even watching the interpreter. Viewing patterns are dependent on pictorial information density rather than comprehension. The study confirms the precedence of the interpreter as primary source for deaf viewers, but also questions the efficiency of subtitling as an alternative information source for deaf viewers if an interpreter is present.},
author_keywords={Cognitive psychology;  Divided attention;  Eye-tracking;  Sign language interpreting;  Subtitling},
references={Aarons, D., Akach, P., South African Sign Language: one language or many? (2002) Language in South Africa, pp. 127-147. , In R. Mesthrie (ed.), Cambridge: Cambridge University Press; Akach, P., Lubbe, J., The giving of personal names in spoken languages and signed language-a comparison (2003) Acta Academica Supplementum, 2, pp. 104-128; Baaring, I., Respeaking-based online subtitling in Denmark. inTRAlinea Special edition Respeaking (2006), http:www.intralinea.org/specials/articles/Respeakingbased_online_subtitling_in_Denmark, Accessed 27/02/2013; Baker-Shenk, C., Cokely, D., (1981) American Sign Language: A teacher's resource text on grammar and culture, , Washington D.C: Gallaudet University Press; Bartoll, E., Tejerina, A.M., The positioning of subtitles for the deaf and hard of hearing (2010) Listening to subtitles: subtitles for the deaf and hard-of-hearing, pp. 69-86. , In AMatamala & P. Orero (eds.), Frankfort am Main: Peter Lang; (2009) Online subtitling editorial guidelines, 1. , http://www.bbc.co.uk/guidelines/futuremedia/accessibility/subtitling_guidelines/online_sub-editorialguidelines_vs1_1.pdf, British Broadcasting Company,. Accessed 03/06/2013; Berke, J., (2009) Deaf community-South Africa: schools, organisations and television, , http://deafness.about.com/od/internationaldeaf/a/southafrica.htm, Accessed 11/11/2009; Bidoli, C., (2009) Sign language: a newcomer to the interpreting forum, , http://www.openstarts.units.it/dspace/bitstream/10077/2454/1/08.pdf, (Paper given at the International Conference on Quality in Conference Interpreting.), Accessed 21/12/09; (1996) Constitution of the Republic of South Africa, , http://www.info.gov.za/documents/constitution/1996/a108-96.pdf, Constitution, Accessed 12/10/2010; (1996), http://www.info.gov.za/documents/constitution/1996/96cons1.htm#6, Constitution, Chapter 1:1-6. Founding provisions, Accessed 12/10/2010; (2012) Deaf Federation of South Africa, , http://www.deafsa.co.za, DeafSA,. Accessed 15/06/2012; (2009) Policy on the provision and regulation of South African sign language interpreters, , http://www.deafsa.co.za/resources/SASLI_policy.pdf, DeafSA, Accessed 20/06/2012; (2008) DeafSA Constitution, , http://www.deafsa.co.za/resources/Constitution.pdf, DeafSA, Accessed 20/06/2012; De Korte, T., (2006) Live inter-lingual subtitling in the Netherlands, , http:www.intralinea.org/specials/articles/Live_interlingual_subtitling_in_the_Netherlands, inTRAlinea Special edition Respeaking, Accessed 27/02/2013; De Valois, R., De Valois, K., (1990) Spatial vision, , Oxford: Oxford University Press; Duncan, J., The demonstration of capacity limits (1980) Cognitive Psychology, 12, pp. 75-96; Duncan, J., The locus of interference in the perception of simultaneous stimuli (1980) Psychological Review, 87, pp. 272-300; d'Ydewalle, G., De Bruycker, W., ye Movements of Children and Adults While Reading Television Subtitles (2007) European Psychologist, 12 (3), pp. 196-205; Ganiso, M., (2012) Sign language in South Africa: language planning and policy challenges, , Grahamstown: Rhodes University. Unpublished MA dissertation; Gile, D., (1995) Basic concepts and models for interpreter and translator training, , Amsterdam & Philadelphia: John Benjamins; Goldberg, J., Wichansky, A., Eye tracking in usability evaluation: a practitioner's guide (2003) The mind's eye: cognitive and applied aspects of eye movement research. Amsterdam: Elsevier Science, pp. 493-516. , In Hyönä, J., Radach, R. & Deubel, H. (eds); Heap, M., Morgans, H., Language policy and SASL: interpreters in the public service (2006) Disability and social change: a South African agenda, pp. 134-147. , In Watermeyer, B., Swartz, L., Lorenzo, T., Schneider, M. & Priestley, M. (eds.), Cape Town: HSRC Press; Higgs, C., (2006) Subtitles for the deaf and the hard of hearing on TV: legislation and practice in the UK, , http:www.intralinea.org/specials/articles/Subtitles_for_the_deaf_and_the_hard_of_hearing, inTRAlinea Special edition Respeaking, Accessed 27/02/2013; Humphrey, J., Alcorn, B., (1996) So you want to be an interpreter: an introduction to sign language interpreting, , Amarillo, Texas: H&H Publishers; Jackson, D., Paul, P., Smith, J., Prior knowledge and reading comprehension ability of deaf adolescents (1997) Journal of Deaf Studies and Deaf Education, 2 (3), pp. 172-184; Jacobs, L., The efficiency of interpreting input for processing lecture information by deaf college students (1977) Journal of Rehabilitation of the Deaf, 11, pp. 10-14; Jensema, C., Viewer reaction to different television captioning speeds (1998) American Annals of the Deaf, 143 (4), pp. 318-324; Jensema, C.J., Danturthi, R.S., Burch, R., Time spent viewing captions on television programs (2000) American Annals of the Deaf, 145 (5), pp. 464-468; Krejtz, I., Szarkowska, A., Krejtz, K., The effects of shot changes on eye movements in subtitling (2013) Journal of Eye Movement Research, 6 (5), pp. 1-12. , 3; Kyle, J., (2007) Sign on television: analysis of data. Deaf Studies Trust, , http://stakeholers.ofcom.org.uk/binaries/consultations/signing/responses/deafstudies_annex.pdf, Available at, Accessed 12/08/2012; Kyle, J., Harris, M., Concurrent correlates and predictors of reading and spelling achievement in deaf and hearing school children (2006) Journal of Deaf Studies and Deaf Education, 11 (3), pp. 273-288; Lambourne, A., (2006) Subtitle respeaking: a new skill for a new age, , http:www.intralinea.org/specials/articles/Subtitle_respeaking, inTRAlinea Special edition Respeaking, Accessed 27/02/2013; Lane, H., Hoffmeister, R., Bahan, B., (1996) Journey into the Deaf world, , California: Dawnsign Press; Lång, J., Mäkisalo, J., Gowases, T., Pietinen, S., Using Eye Tracking to Study the Effect of Badly Synchronized Subtitles on the Gaze Paths of Television Viewers (2013) New Voices in Translation Studies, 10, pp. 72-86; Lawson, L., (2002) The role of sign in the structure of the Deaf community, pp. 31-34. , In Gregory, S. & Hartley, G. Constructing deafness London: Printer Press; Leeson, L., Saeed, J., (2012) Irish Sign Language: a cognitive linguistic account, , Edinburgh: Edinburgh University Press; Lewis, M., (2009) Ethnologue: Languages of the World, , Sixteenth edition. Dallas, Texas: SIL International; Lewis, M.S., Jackson, D.W., Television literacy (2001) Journal of Deaf Studies and Deaf Education, 6 (1), pp. 43-53. , Comprehension of program content using closedcaptions for the deaf; Lombard, S., (2006) The accessibility of a written Bible versus a signed Bible for the deaf-born person with sign language as first language, , Bloemfontein: University of the Free State. Unpublished MA thesis; Lotriet, A., (2011) Sign language interpreting in South Africa: meeting the challenges, , http://criticallink.org/wp-content/uploads/2011/09/CL2_Lotriet.pdf, Accessed 30/03/2012; Lorenzo, L., (2010) Criteria for elaborating subtitles for deaf and hard of hearing children in Spain: A guide of good practice, pp. 139-148. , In Matamala, A. & Orero, P. Listening to subtitles: subtitles for the deaf and hard-ofhearing. Frankfort am Main: Peter Lang; Magongwa, L., (2012) The current status of South African Sign Language, , Lecture given at the University of Pretoria, 31 May 2012; Marsh, A., (2006) Respeaking for the BBC, , http:www.intralinea.org/specials/articles/Respeaking_for_the_BBC, inTRAlinea Special edition Respeaking, Accessed 27/02/2013; Marschark, M., Peterson, R., Winston, E., (2005) Sign language interpreting and interpreter education: directions for research and practice, , Oxford & New York: Oxford University Press; Marschark, M., Sapere, P., Convertino, C., Seewagen, R., Maltzen, H., Educational interpreting: access and outcomes (2005) Sign language interpreting and interpreter education: directions for research and practice, pp. 1-34. , In M. Marschark, R. Peterson & E. Winston (eds), Oxford & New York: Oxford University Press; Marschark, M., Sapere, P., Convertino, C., Seewagen, R., Maltzen, H., Comprehension of sign language interpreting: deciphering a complex task situation (2004) Sign Language Studies, 4 (4), pp. 345-368; Matamala, A., Orero, P., (2010) Listening to subtitles: subtitles for the deaf and hard-of-hearing, , Frankfort am Main: Peter Lang; Mesthrie, R., Language in South Africa, , Cambridge: Cambridge University Press; Miller, J., Divided attention: evidence for coactivation with redundant signals (1982) Cognitive Psychology, 14 (2), pp. 247-279; Montero, I.C., Soneira, A.M., Spanish deaf people as recipients of closed captioning (2010), pp. 25-44. , In Matamala, A. & Orero, P. Listening to subtitles: subtitles for the deaf and hard-of-hearing. Frankfort am Main: Peter Lang; Morgan, R., (2001) Barriers to justice: Deaf people and the courts, , Issues in Law, Race and Gender 8. Law, Race and Gender Research Unit, University of Cape Town; Morgan, R., (2008) Deaf me normal: Deaf South Africans tell their stories, , Pretoria: Unisa Press; Morgan, R., Aarons, D., How many South African sign languages are there? A sociolinguistic question (1999) In Proceedings of the 13th World congress of the World Federation of the Deaf. Sydney: Australian Association of the Deaf, pp. 356-374; Napier, J., McKee, R., Goswell, D., (2010) Sign language interpreting: theory and practice in Australia and New Zealand, , NSW: Federation Press; (2011) Basic hints for interaction with people with hearing loss, , http://www.ncppdsa.org.za, [NCPPDSA]. National Council for Persons with Physical Disabilities in South Africa Accessed 20/09/2011; Nebel, K., Weise, H., Stude, P., De Greiff, A., Diener, H.C., Keidel, M., On the neural basis of focused and divided attention (2005) Cognitive Brain Research, 25, pp. 760-776; Newhoudt-Druchen, W., Working together (2006) Proceedings of the inaugural conference of the World Association of Sign Language Interpreters, pp. 8-11. , In McKee, R.L. (ed.), Gloucestershire: Douglas Maclean; Neves, J., 10 fallacies about subtitling for the d/Deaf and hard of hearing (2008) JoSTrans, 10, pp. 128-143. , http://www.jostrans.org/issue10/art_neves.pdf, Accessed 29/10/2014; Olivier, J., (2007) South African Sign Language, , http://www.cyberserve.co.az/users/~jako/lang/signlanguage/index.htm, Accessed 12/10/2010; Orero, P., (2006) Real-time subtitling in Spain: an overview, , http://www.intralinea.org/specials/articles/Realtime_subtitling_in_Spain, inTRAlinea Special edition Respeaking, Accessed 27/02/2013; Pashler, H., Dissociations and dependencies between speed and accuracy: evidence for a twocomponent theory of divided attention in simple tasks (1989) Cognitive Psychology, 21, pp. 469-514; Pederson, J., Audiovisual translation-in general and in Scandinavia (2010) Perspectives, 18 (1), pp. 1-22; Penn, C., The sociolinguistics of South African Sign Language (1992) Language and society in Africa, pp. 277-284. , In Herbert, R. (ed.),. Johannesburg: Witwatersrand University Press; Penn, C., Doldin, D., Landman, K., Steenekamp, J., (1992) Dictionary of Southern African signs for communication with the Deaf, , Pretoria: HSRC; Penn, C., Reagan, T., The properties of South African Sign Language: lexical diversity and syntactic unity (1994) Sign Language Studies, 85, pp. 319-327; Pereira, A., Criteria for elaborating subtitles for deaf and hard of hearing adults in Spain: Description of a case study (2010) Listening to subtitles: subtitles for the deaf and hardof-hearing, pp. 87-102. , In Matamala, A. & Orero, P, Frankfurt am Main: Peter Lang; Language issues: proposed recognition of South African Sign Language as official language (2009), http://www.pmg.org.za//20091113-language-issuesproposed-recognition-south-african-sign-languageofficial/html, [PMG]. Parliamentary Monitoring Group. Sepedi/Sesotho sa Leboa issues: briefings by Deaf SA, CRL Commission, Pan South African Language Board, Accessed 12/11/2012; (2007) Recognition of South African Sign Language as official language: briefing by Deaf Federation of South Africa, , http://www.pmg.org.za/print/8655, [PMG]. Parliamentary Monitoring Group, Accessed 13/11/2009; Posner, M., Orienting of attention (1980) Quarterly Journal of Experimental Psychology, 32 (1), pp. 3-25; Reagan, T., South African Sign Language and language in education policy in South Africa (2008) Stellenbosch Papers in Linguistics, 38, pp. 165-190; Reagan, T., (2012) Personal correspondence, , 27/06/2012; Remael, A., Van der Veer, B., (2006) Real-time subtitling in Flanders: needs and teaching, , http:www.intralinea.org/specials/articles/Realtime_subtitling_in_Flanders_Needs_and_teaching, inTRAlinea Special edition Respeaking, Accessed 27/02/2013; Ribas, M.A., Romero Fresco, P., A practical proposal for the training of respeakers 1 (2008) JoSTrans, 10, pp. 106-127. , http://www.jostrans.org/issue10/art_arumi.php, Accessed 29/01/2014; Romero Fresco, P., (2009) More haste less speed: edited versus verbatim respoken subtitles, , http://webs.uvigo.es/vialjournal/pdf/Vial-2009-Article6.pdf, Accessed 29/01/2014; Romero Fresco, P., (2011) Quality in Respeaking: The Reception of Respoken Subtitles, , http://www.respeaking.net/programme/romero.pdf, Accessed 29/01/2014; (2012) South African Disability Alliance: the collective voice of the disability sector in collaboration, , http://www.deafsa.co.za/resources/SADA_profile.pdf, SADA, Accessed 20/06/2012; Szarkowska, A., Krejtz, I., Klyszejko, Z., Wieczorek, A., Verbatim, standard, or edited? Reading patterns of different captioning styles among deaf, hard of hearing, and hearing viewers (2011) American Annals of the Deaf, 156 (4), pp. 363-378; (1996), http://www.info.gov.za/acts/1996/a84-96.pdf, SA Schools Act, No. 84 of 1996: South African schools act, 1996, Accessed 16/07/2012; Yearbook, S.A., (2009) South Africa Yearbook, , Pretoria: Central Statistical Service; Setton, R., (2011) Interpreting Chinese, interpreting China, , Amsterdam & Philadelphia: John Benjamins; Shlesinger, M., (2000) Strategic allocation of working memory and other attentional resources in simultaneous interpreting, , Ramat-Gan: Bar-Ilan University. Unpublished PhD thesis; (2009), http://www.signgenius.com/infostatistics.html, Signgenius,. Accessed 19/12/2009; Spelke, E., Hirst, W., Neisser, U., Skills of divided attention (1976) Cognition, 4, pp. 215-230; Statistics, S.A., (2009), http://www.tatssa.gov.za/census01/html/C2001disability.asp, [StatsSA], Accessed 18/10/2009; Statistics, S.A., (2012) Census 2011. Methodology and highlights of key results, , http://www.statssa.gov.za/census2011/Products/Census2011_Methodology_and_highlight_of_key_results.pdf, [StatsSA], Accessed 18/10/2009; Steiner, B., Signs from the void, The comprehension and production of sign language on television. (1998) Interpreting, 3 (2), pp. 99-146; Stone, C., (2009) Towards a Deaf translation norm, , Washington, D.C.: Gallaudet University Press; Stratiy, A., Best practices in interpreting: a Deaf community perspective (2005) Topics in signed languages and interpreting: theory and practice., pp. 231-250. , In Janzen, T. (ed.), Amsterdam & Philadelphia: John Benjamins; Tedstone, D., Colye, K., Cognitive impairments in sober alcoholics: performance on selective and divided attention tasks (2004) Drug and Alcohol Dependence, 75, pp. 277-286; Torres, M.S., Santana, R.H., Reading levels of Spanish deaf students (2005) American Annals of the Deaf, 150 (4), pp. 379-387; Utray, F., Ruiz, B., Moreiro, J.A., Maximum font size for subtitles in standard definition digital television: tests for a font magnifying application (2010) Listening to subtitles: subtitles for the deaf and hard-of-hearing, pp. 59-68. , In Matamala, A. & Orero, P. (eds.), Frankfurt am Main: Peter Lang; Van Herreweghe, M., Vermeerbergen, M., Deaf perspectives on communicative practices in South Africa: institutional language policies in educational settings (2010) Text & Talk, 30 (2), pp. 125-144; Vermeerbergen, M., Van Herreweghe, M., Akach, P., Matabane, E., Constituent order in Flemish Sign Language (VGT) and South African Sign Language (SASL) (2007) Sign Language & Linguistics, 10 (1), pp. 25-54; Wehrmeyer, J., (2013) A critical investigation of Deaf comprehension of signed TV news interpretation, , Pretoria: University of South Africa. Unpublished D. Litt. et Phil. thesis; Wehrmeyer, J., forthcoming, Submitted to New Voices in Translation Studies Deaf comprehension of TV sign language interpreters; Xiao, X., Yu, R., Survey on sign language interpreting in China (2009) Interpreting, 11 (2), pp. 137-163; Xiao, X., Yu, R., Sign language interpreting in China: a survey (2011) Interpreting Chinese, interpreting China, pp. 29-53. , In Setton, R. (ed.),. Amsterdam & Philadelphia: John Benjamins; Xiao, X., Li, F., Sign language interpreting on Chinese TV: a survey on user perspectives (2013) Perspectives, 21 (1), pp. 100-116},
correspondence_address1={Wehrmeyer, J.; North West UniversitySouth Africa},
publisher={International Group for Eye Movement Research},
issn={19958692},
language={English},
abbrev_source_title={J. Eye Mov. Res.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Huynh-Thu2011,
author={Huynh-Thu, Q. and Schiatti, L.},
title={Examination of 3D visual attention in stereoscopic video content},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2011},
volume={7865},
doi={10.1117/12.872382},
art_number={78650J},
note={cited By 25; Conference of Human Vision and Electronic Imaging XVI ; Conference Date: 24 January 2011 Through 27 January 2011;  Conference Code:84444},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953727908&doi=10.1117%2f12.872382&partnerID=40&md5=203e25ae74c2d92dbb2c0774c5d3c2e6},
affiliation={Technicolor, 1 Av. de Belle Fontaine - CS17616, 35576 Cesson-Sevigné, France},
abstract={Recent advances in video technology and digital cinema have made it possible to produce entertaining 3D stereoscopic content that can be viewed for an extended duration without necessarily causing extreme fatigue, visual strain and discomfort. Viewers focus naturally their attention on specific areas of interest in their visual field. Visual attention is an important aspect of perception and its understanding is therefore an important aspect for the creation of 3D stereoscopic content. Most of the studies on visual attention have focused on the case of still images or 2D video. Only a very few studies have investigated eye movement patterns in 3D stereoscopic moving sequences, and how these may differ from viewing 2D video content. In this paper, we present and discuss the results of a subjective experiment that we conducted using an eye-tracking apparatus to record observers' gaze patterns. Participants were asked to watch the same set of video clips in a free-viewing task. Each clip was shown in a 3D stereoscopic version and 2D version. Our results indicate that the extent of areas of interests is not necessarily wider in 3D. We found a very strong content dependency in the difference of density and locations of fixations between 2D and 3D stereoscopic content. However, we found that saccades were overall faster and that fixation durations were overall lower when observers viewed the 3D stereoscopic version. © 2011 Copyright SPIE - The International Society for Optical Engineering.},
author_keywords={eye tracking, gaze pattern;  stereoscopic video;  visual attention},
keywords={2D video;  Areas of interests;  Content dependencies;  Digital cinemas;  Eye movement patterns;  Eye-tracking;  Fixation duration;  Specific areas;  stereoscopic video;  Still images;  Subjective experiments;  Video clips;  Video technologies;  Visual Attention;  Visual fields;  Visual strain, Computer graphics;  Three dimensional;  Video recording, Eye movements},
references={Yarbus, A., (1967) Eye Movements and Vision, , New-York, Plenum; Posner, M.I., Orienting of attention (1980) Quarterly Journal of Experimental Psychology, 32 (1), pp. 3-25; Jansen, L., Onat, S., König, P., Influence of disparity on fixation and saccades in free viewing of natural scenes (2009) Journal of Vision, 9 (1), pp. 1-19. , January; Wexler, M., Ouarti, N., Depth affects where we look (2008) Current Biology, 18, pp. 1872-1876. , December; Wismeijer, D.A., Erkelens, C.J., Van Ee, R., Wexler, M., Depth cue combination in spontaneous eye movements (2010) Journal of Vision, 10 (6), pp. 1-15. , June; Ramasamy, C., House, D., Duchowski, A., Daugherty, B., Using eye tracking to analyze stereoscopic filmmaking (2009) Proc. SIGGRAPH 2009, , Posters, Article No. 28; Häkkinen, J., Kawai, T., Takatalo, J., Mitsuya, R., Nyman, G., What do people look at when they watch stereoscopic movies? (2010) Proc. SPIE Conf. Stereoscopic Displays and Applications XXI, 7524. , San Jose, January; Hoffman, D.M., Girshick, A.R., Akeley, K., Banks, M.S., Vergence-accommodation conflicts hinder visual performance and cause visual fatigue (2008) Journal of Vision, 8 (3), pp. 1-30; Le Meur, O., Chevet, J.-C., Relevance of a feed-forward model of visual attention for goal-oriented and free-viewing tasks (2010) IEEE Trans. Image Processing, 19 (11), pp. 2801-2813. , November; Peters, R.J., Iyer, A., Itti, L., Koch, C., Components of bottom-up gaze allocation in natural images (2005) Vision Research, 45 (18), pp. 2397-2416. , August; Domański, M., Grajek, T., Klimaszewski, K., Kurc, M., Stankiewicz, O., Stankowski, J., Wegner, K., (2009) Poznań Multiview Video Test Sequences and Camera Parameters, , ISO/IEC JTC1/SC29/WG11 MPEG 2009/M17050, Xian, China, October},
correspondence_address1={Huynh-Thu, Q.; Technicolor, 1 Av. de Belle Fontaine - CS17616, 35576 Cesson-Sevigné, France},
sponsors={The Society for Imaging Science and Technology (IS and T); The Society of Photo-Optical Instrumentation Engineers (SPIE); iPlant Collaborative},
address={San Francisco, CA},
issn={0277786X},
isbn={9780819484024},
coden={PSISD},
language={English},
abbrev_source_title={Proc SPIE Int Soc Opt Eng},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Sawahata20081610,
author={Sawahata, Y. and Khosla, R. and Komine, K. and Hiruma, N. and Itou, T. and Watanabe, S. and Suzuki, Y. and Hara, Y. and Issiki, N.},
title={Determining comprehension and quality of TV programs using eye-gaze tracking},
journal={Pattern Recognition},
year={2008},
volume={41},
number={5},
pages={1610-1626},
doi={10.1016/j.patcog.2007.10.010},
note={cited By 25},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973463351&doi=10.1016%2fj.patcog.2007.10.010&partnerID=40&md5=04b8b22309f507a6e119373cad414b6a},
affiliation={NHK (Japan Broadcasting Corporation), Science and Technical Research Laboratories, 1-10-11, Kinuta, Setagaya, Tokyo, 157-8510, Japan; BSKM Research Laboratory, School of Business, La Trobe University, Melbourne, Vic. 3083, Australia; NHK Broadcasting Culture Research Institute, Atago-Mori Tower 16F, 2-5-1, Atago, Minato-ku, Tokyo, 105-6216, Japan},
abstract={Currently, TV programs are evaluated by using questionnaires given after previews or by using TV ratings. There are few objective criteria useful for describing technical know-how about program production. One of the TV program producers' concerns is how to choose expression methods that convey their ideas to viewers correctly and efficiently. Research has shown that eye-gaze direction is related to the human focus and attention. Gaze-based evaluations have been proposed for image-quality evaluations and certain usability tests. Such approaches are mainly based on how often a specific region attracted the subjects' gaze or how long their gaze was fixed on it. To apply these approaches to TV programs, all the object regions that seem to attract a viewer's gaze need to be specified in advance. This causes several problems including the accuracy of specifying the region by using an image processing technique is not equal to the human subject's recognition ability and it is not feasible to manually specify such regions in an enormous number of frames (images) comprising the program. Further, how characteristics of well-produced TV programs appear on the viewer's gaze has not been objectively analyzed yet. There is a need to investigate the relationship between gaze and program contents which can be used as means for improving comprehension and quality of the TV programs. In this paper, we propose a new measurement and evaluating method for this purpose. This paper focuses on the relationship between a viewer's comprehension of a program and their gaze direction in a real experimental TV educational program involving 26 elementary school children and broadcast by NHK Broadcasting Corporation of Japan. Correlation between TV program comprehension and entropy is investigated. That is, variances in the gaze direction in relation to program comprehension are based on a entropy value that represents the degree of dispersion in each frame and is calculated from a probability density function estimated from the gaze directions. The results indicate that the variances of the gaze direction for scenes that gave better comprehension tended to be lower. This tendency was further noticeable after a keyword utterance were related to the answers of corresponding questions. © 2007 Elsevier Ltd. All rights reserved.},
author_keywords={Entropy;  Eye-gaze direction;  Gaussian mixture models;  Performance optimization framework;  TV contents evaluation;  TV program comprehension},
keywords={Entropy;  Image quality;  Probability density function, Eye gaze tracking;  Gaussian mixture models;  Performance optimization frameworks;  TV contents evaluation;  TV program comprehension, Television broadcasting},
references={Friesen, C.K., Kingstone, A., The eyes have it!: reflexive orienting is triggered by non-predictive gaze (1998) Psychon. Bull. Rev., 5, pp. 490-495; Friesen, C.K., Ristic, J., Kingstone, A., Attentional effects of counterpredictive gaze and arrow cues (2004) J. Exp. Psychol.: Hum. Percept. Perform., 30, pp. 319-329; Ristic, J., Friesen, C.K., Kingstone, A., Are eyes special? It depends on how you look at it (2002) Psychol. Bull. Rev., 9, pp. 507-513; Tipples, J., Eye gaze is not unique: automatic orienting in response to noninformative arrows (2002) Psychon. Bull. Rev., 9, pp. 314-318; Driver, J., Davis, G., Ricciardelli, P., Kidd, P., Maxwell, E., Baron-Cohen, S., Gaze perception triggers visuospatial orienting by adults in a reflexive manner (1999) Visual Cognit., 6, pp. 509-540; Gibson, B.S., Bryant, T.A., Variation in cue duration reveals top-down modulation of involuntary orienting to uninformative symbolic cues (2005) Percept. Psychophys., 67, pp. 749-758; Troseth, G.I., Saylor, M.M., Archer, A.H., Young children's use of video as a source of socially relevant information (2006) J. Child Dev., 17 (3), pp. 786-799; Gibert, G., Bailly, G., Elisei, F., Evaluation of a virtual speech cuer (2006) Proceedings of ISCA Tutorial and Research Workshop on Experimental Linguistics, , Athens, Greece; Jacob, R.J.K., Karn, K.S., Eye tracking in human-computer interaction and usability research: ready to deliver the promises (2003) The Mind's Eye: Cognitive and Applied Aspects of Eye Movement Research, pp. 573-605. , Hyona J., Radach R., and Deubel H. (Eds), Elsevier, Amsterdam; Murtagh, F., Taskaya, T., Contreras, P., Mothe, J., Englmeier, K., Interactive visual user interfaces: a survey (2003) Artif. Intell. Rev., 19, pp. 263-283; Farid, M., Murtagh, F., Starck, J.L., Computer display control and interaction using eye-gaze, preprint of article published (2002) J. Soc. Inf. Disp., 10 (3), pp. 289-293. , (and figures p. 300); Adeler, F.H., Flegelman, M., Influence of fixation on the visual acuity (1934) Arch. Ophthalmol., 12, pp. 475-483; Robinson, D.R., A method of measuring eye movements using a search coil in a magnetic field (1963) IEEE Trans. Bio-Med. Electron., 10, pp. 137-145; Titterington, D., Smith, A., Makov, U., (1985) Statistical Analysis of Finite Mixture Distributions, , Wiley, New York; McLachlan, G., Peel, D., (2000) Finite Mixture Models, , Wiley Interscience, New York pp. 40-80; Dempser, A.P., Laird, N.M., Rubin, D.B., Maximum likelihood from incomplete data via the EM algorithm (1977) J. R. Stat. Soc. B, 39, pp. 1-38; Akaike, H., Information theory and an extension of the maximum likelihood principle (1973) The Second International Symposium on Information Theory, pp. 267-281. , Petrov B.N., and Csaki F. (Eds), Akadémi Kiadó, Budapest, Hungary; Schwartz, G., Estimating the dimension of a model (1978) Ann. Stat., 6, pp. 461-464; Fraley, C., Raftery, A.E., Model-based clustering, discriminant analysis, and density estimation (2002) J. Am. Stat. Assoc., 97, pp. 611-631; Rao, C.R., (1965) Linear Statistical Inference and its Applications, , Wiley, New York p. 349; Ito, H., An analysis of eye movements while watching educational TV programs (1991) Bull. Natl. Inst. Multimedia Educ., 5, pp. 147-162; Berry, C., Brosius, H.B., Multiple effects of visual format on TV news learning (1991) Appl. Cognit. Psychol., 5 (6), pp. 519-528; Baggett, P., Role of temporal overlap of visual and auditory material in forming dual media associations (1984) J. Educ. Psychol., 76, pp. 408-417; },
correspondence_address1={Sawahata, Y.; NHK (Japan Broadcasting Corporation), Science and Technical Research Laboratories, 1-10-11, Kinuta, Japan; email: sawahata.y-jq@nhk.or.jp},
publisher={Elsevier Ltd},
issn={00313203},
coden={PTNRA},
language={English},
abbrev_source_title={Pattern Recogn.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bednarik2007274,
author={Bednarik, R. and Tukiaeven, M.},
title={Validating the Restricted Focus Viewer: A study using eye-movement tracking},
journal={Behavior Research Methods},
year={2007},
volume={39},
number={2},
pages={274-282},
doi={10.3758/BF03193158},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547842070&doi=10.3758%2fBF03193158&partnerID=40&md5=4137499920d321d6c1aecfdabc60d1b8},
affiliation={University of Joensuu, Joensuu, Finland; Department of Computer Science, University of Joensuu, P.O. Box 111, 80101 Joensuu, Finland},
abstract={Investigation of cognitive processes and visual attention during problem-solving tasks is an important part of understanding human reasoning. Eyetracking technology has proven to have many benefits in revealing visual attention patterns. However, the high price of accurate eyetrackers and the difficulties associated with using them represent major obstacles to their wider application. Therefore, previous studies have sought to find alternatives to eyetracking. The Restricted Focus Viewer (RFV) brings a small part of an otherwise blurred display to the focus of visual attention: A user controls what part of the screen is in focus by using a computer mouse and explicitly selecting the area to be shown in focus. Recently, some studies have employed the RFV to investigate cognitive behavior of users, and some researchers have even enhanced the tool to study usability. We replicated a previous RFV-based study while also recording gaze data. We compared the attention allocation in time and space as reported by the RFV and an eyetracker. Further, we investigated the effects of RFV's display blurring on the visual attention allocation of 18 novice and expert programmers. Our results indicate that the data obtained from the two tools differ. Also, the RFV-blurring interferes with the strategies utilized by experts, and has an effect on fixation duration. However, task performance was preserved. Copyright 2007 Psychonomic Society, Inc.},
references={BEDNARIK, R., MYLLER, N., SUTINEN, E., TUKIAINEN, M., Effects of experience on gaze behavior during program animation (2005) Proceedings of the 17th Annual Workshop of the Psychology of Programming Interest Group (PPIG '05), pp. 49-61. , P. Romero, J. Good, E. Acosta Chaparro, & S. Bryant Eds, Brighton, U.K, University of Sussex; BEDNARIK, R., TUKIAINEN, M., Visual attention and representation switching in Java program debugging: A study using eye movement tracking (2004) Proceedings of the 16th Annual Workshop of the Psychology of Programming Interest Group (PPIG '04), pp. 159-169. , E. Dunican & T. R. G. Green Eds, Carlow, Ireland: Institute of Technology; FIX, V., WIEDENBECK, S., SCHOLTZ, J., Mental representations of programs by novices and experts (1993) Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '93), pp. 74-79. , New York: ACM Press; FUTRELLE, R.P., RUMSHISKY, A., Discourse structure of textgraphics documents (2001) Proceedings of the 1st International Symposium on Smart Graphics, , Hawthorne, New York: ACM Press; GOLDBERG, J.H., KOTVAL, X.P., Eye movement-based evaluation of the computer interface (1998) Advances in occupational ergonomics and safety, pp. 529-532. , S. K. Kumar Ed, Amsterdam: IOS Press; GUGERTY, L., OLSON, G.M., Comprehension differences in debugging by skilled and novice programmers (1986) Empirical studies of programmers: First workshop, pp. 13-27. , E. Soloway & S. Iyengar Eds, Norwood, NJ: Ablex; HYÖNÄ, J., LORCH JR., R.F., KAAKINEN, J.K., Individual differences in reading to summarize expository text: Evidence from eye fixation patterns (2002) Journal of Educational Psychology, 94, pp. 44-55; JANSEN, A.R., BLACKWELL, A.F., MARRIOTT, K., A tool for tracking visual attention: The Restricted Focus Viewer (2003) Behavior Research Methods, Instruments, & Computers, 35, pp. 57-69; JONES, M.N., MEWHORT, D.J.K., Tracking attention with the focus-window technique: The information filter must be calibrated (2004) Behavior Research Methods, Instruments, & Computers, 36, pp. 270-276; JUST, M.A., CARPENTER, P.A., Eye fixations and cognitive processes (1976) Cognitive Psychology, 8, pp. 441-480; KOENEMANN, J., ROBERTSON, S.P., Expert problem solving strategies for program comprehension (1991) Proceedings of the SIGCHI Conference on Human Factors in Computing Systems: Reaching through technology, pp. 125-130. , S. P. Robertson, G. M. Olson, & J. S. Olson Eds, New York: ACM Press; LAW, B., ATKINS, M.S., KIRKPATRICK, A.E., LOMAX, A.J., Eye gaze patterns differentiate novice and experts in a virtual laparoscopic surgery training environment (2004) Proceedings of the 2004 Symposium on Eye Tracking Research and Applications, pp. 41-48. , New York: ACM Press; RAYNER, K., Eye movements in reading and information processing: 20 years of research (1998) Psychological Bulletin, 124, pp. 372-422; ROMERO, P., COX, R., DU BOULAY, B., & LUTZ, R. (2002). Visual attention and representation switching during Java program debugging: A study using the Restricted Focus Viewer. In Diagrammatic Representation and Inference: Second International Conference, Diagrams 2002, Callaway Gardens, GA, USA. April 18-20, 2002: Proceedings (Lecture Notes in Computer Science, 2317, pp. 221-235). Berlin: Springer; ROMERO, P., DU BOULAY, B., COX, R., LUTZ, R., Java debugging strategies in multi-representational environments (2003) Proceedings of the 15th Annual Workshop of the Psychology of Programming Interest Group (PPIG '03), pp. 421-434. , M. Petre Ed; ROMERO, P., DU BOULAY, B., LUTZ, R., COX, R., The effects of graphical and textual visualisations in multi-representational debugging environments (2003) Proceedings of the 2003 IEEE Symposia on Human Centric Computing Languages and Environments, pp. 236-238. , J. Hosking & P. Cox Eds, Piscataway, NJ: IEEE Computer Society; ROMERO, P., LUTZ, R., COX, R., DU BOULAY, B., Coordination of multiple external representations during Java program debugging (2002) Proceedings of the 2002 IEEE Symposia on Human Centric Computing Languages and Environments, pp. 207-214. , S. Wiedenbeck & M. Petre Eds, Piscataway, NJ: IEEE Computer Society; SIBERT, L.E., JACOB, R.J.K., Evaluation of eye gaze interaction (2000) Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 281-288. , New York: ACM Press; TARASEWICH, P., FILLION, S., Discount eye tracking: The Enhanced Restricted Focus Viewer (2004) Proceedings of the 10th Americas Conference on Information Systems, pp. 1-9. , New York: AMCIS; VESSEY, I., Expertise in debugging computer programs: A process analysis (1985) International Journal of Man-Machine Studies, 23, pp. 459-494; WARE, C., MKAELIAN, H.H., An evaluation of an eye tracker as a device for computer input (1987) Proceedings of the SIGCHI/GI Conference on Human Factors in Computing Systems and Graphics Interface (CHI '87), pp. 183-188. , New York: ACM Press},
correspondence_address1={Bednarik, R.; Department of Computer Science, University of Joensuu, P.O. Box 111, 80101 Joensuu, Finland; email: bednarik@cs.joensuu.fi},
publisher={Psychonomic Society Inc.},
issn={1554351X},
pubmed_id={17695355},
language={English},
abbrev_source_title={Behav. Res. Methods},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Jansen200357,
author={Jansen, A.R. and Blackwell, A.F. and Marriott, K.},
title={A tool for tracking visual attention: The Restricted Focus Viewer},
journal={Behavior Research Methods, Instruments, and Computers},
year={2003},
volume={35},
number={1},
pages={57-69},
doi={10.3758/BF03195497},
note={cited By 34},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0038811735&doi=10.3758%2fBF03195497&partnerID=40&md5=2eeb93c875013fedaaadc209ca41d801},
affiliation={Monash University, Victoria, Australia; University of Cambridge, Cambridge, United Kingdom; Sch. of Comp. Sci./Software Eng., Monash University, Victoria, Vic. 3800, Australia},
abstract={Eye-tracking equipment has proven useful in examining the cognitive processes people use when understanding and reasoning with visual stimuli. However, eye-tracking has several drawbacks: accurate eye-tracking equipment is expensive, it is often awkward for participants, it requires frequent recalibration, and the data can be difficult to interpret. We introduce an alternative tool: the Restricted Focus Viewer (RFV). This is a computer program that takes an image, blurs it, and displays it on a computer monitor, allowing the participant to see only a small region of the image in focus at any time. The region in focus can be moved using the computer mouse. The RFV records what the participant is focusing on at any point in time. It is cheap, nonintrusive, does not require calibration, and provides accurate data about which region is being focused on. We describe this tool and also provide experimental comparisons with eye-tracking. The RFV (Version 2.1) is freely available at http://www.csse.monash.edu. au/projects/RFV/.},
keywords={algorithm;  article;  attention;  calibration;  clinical trial;  eye movement;  human;  instrumentation;  physiology;  psychology;  psychomotor performance;  vision, Algorithms;  Attention;  Calibration;  Clinical Trials;  Eye Movements;  Humans;  Psychology, Experimental;  Psychomotor Performance;  Visual Perception},
references={Blackwell, A.F., Jansen, A.R., Marriott, K., Restricted focus viewer: A tool for tracking visual attention (2000) Theory and Application of Diagrams: Lecture Notes in Artificial Intelligence (LNAI) 1889, pp. 162-177. , M. Anderson, P. Cheng, & V Haarslev (Eds.). New York: Springer-Verlag; Carpenter, P.A., Shah, P., A model of the perceptual and conceptual processes in graph comprehension (1998) Journal of Experimental Psychology: Applied, 4, pp. 75-100; Coren, S., Ward, L.M., Enns, J.T., (1994) Sensation and Perception (4th Ed.), , Harcourt Brace; Ericsson, K.A., Simon, H.A., (1993) Protocol Analysis: Verbal Reports as Data (Rev. Ed.), , Cambridge, MA: MIT Press; Futrelle, R.P., Rumshisky, A., Discourse structure of text-graphics documents (2001) 1st International Symposium on Smart Graphics, , A. Butz, A. Krueger, P. Oliver, & M. Zhou (Eds.). New York: ACM Press; Hegarty, M., Mental animation: Inferring motion from static diagrams of mechanical systems (1992) Journal of Experimental Psychology: Learning, Memory, & Cognition, 18, pp. 1084-1102; Henderson, J.M., McClure, K.K., Pierce, S., Schrock, G., Object identification without foveal vision: Evidence from an artificial scotoma paradigm (1997) Perception & Psychophysics, 59, pp. 323-346; Jansen, A.R., (2001) Restricted Focus Viewer (RFV) Version 2.1 User's Manual and Tutorial, , Tech. Rep. No. 2001/87. Monash University, School of Computer Science and Software Engineering; Just, M.A., Carpenter, P.A., Eye fixations and cognitive processes (1976) Cognitive Psychology, 8, pp. 441-480; Osaka, N., Oda, K., Moving window generator for reading experiments (1994) Behavior Research Methods, Instruments, & Computers, 26, pp. 49-53; Rayner, K., Eye movements in reading and information processing: 20 years of research (1998) Psychological Bulletin, 124, pp. 372-422; Rayner, K., Pollatsek, A., (1989) The Psychology of Reading, , Englewood Cliffs, NJ: Prentice-Hall; Rayner, K., Pollatsek, A., Eye movements and scene perception (1992) Canadian Journal of Psychology, 46, pp. 342-376; Romero, P., Cox, R., Boulay, B., Du Lutz, R., Visual attention and representation switching during Java program debugging: A study using the Restricted Focus Viewer (2002) Diagrammatic Representation and Inference: Lecture Notes in Artificial Intelligence (LNAI), 2317, pp. 221-235. , M. Hegarty, B. Meyer, & N. H. Narayanan (Eds.). New York: Springer-Verlag; Schnipke, S.K., Todd, M.W., Trials and tribulations of using an eye-tracking system (2000) CHI 2000 Extended Abstracts, , 273-274; Stark, L.W., Ezumi, K., Nouyen, T., Paul, R., Tharp, G., Yamashita, H.I., Visual search in virtual environments (1992) Proceedings of the SPIE: Human Vision, Visual Processing, and Digital Display III, 1666, pp. 577-589; Steinke, T.R., Eye movement studies in cartography and related fields (1987) Cartographica, 24, pp. 40-73; Tovée, M.J., (1996) An Introduction to the Visual System, , Cambridge: Cambridge University Press; Ummelen, N., (1997) Procedural and Declarative Information in Software Manuals, , Unpublished doctoral dissertation, Universiteit Twente, Utrecht; Yarbus, A.L., (1967) Eye Movements and Vision, , New York: Plenum},
correspondence_address1={Jansen, A.R.; Sch. of Comp. Sci./Software Eng., Monash University, Victoria, Vic. 3800, Australia; email: tonyj@mail.csse.monash.edu.au},
publisher={Psychonomic Society Inc.},
issn={07433808},
pubmed_id={12723780},
language={English},
abbrev_source_title={Behav. Res. Methods Instrum. Comput.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Blackwell2000162,
author={Blackwell, A.F. and Jansen, A.R. and Marriott, K.},
title={Restricted focus viewer: A tool for tracking visual attention},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2000},
volume={1889},
pages={162-177},
note={cited By 20; Conference of 1st International Conference on Theory and Application of Diagrams, Diagrams 2000 ; Conference Date: 1 September 2000 Through 3 September 2000;  Conference Code:122069},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942060157&partnerID=40&md5=777d5650f31d89dc87b037fd8949bbdb},
affiliation={Computer Laboratory, University of Cambridge, Cambridge, CB2 3QG, United Kingdom; School of Computer Science and Software Engineering, Monash University, Clayton, VIC  3800, Australia},
abstract={Eye-tracking equipment has proven useful in examining the cognitive processes people use when understanding and reasoning with diagrams. However, eye-tracking has several drawbacks: accurate eyetracking equipment is expensive, often awkward for participants, requires frequent re-calibration and the data can be difficult to interpret. We introduce an alternative tool for diagram research: the Restricted Focus Viewer (RFV). This is a computer program which takes an image, blurs it and displays it on a computer monitor, allowing the participant to see only a small region of the image in focus at any time. The region in focus can be moved using the computer mouse. The RFV records what the participant is focusing on at any point in time. It is cheap, non-intrusive, does not require calibration and provides accurate data about which region is being focused upon. We describe this tool, and also provide an experimental comparison with eye-tracking. We show that the RFV gives similar results to those obtained by Hegarty (1992) when using eyetracking equipment to investigate reasoning about mechanical diagrams. © Springer-Verlag Berlin Heidelberg 2000.},
keywords={Behavioral research;  Calibration;  Display devices;  Equipment;  Target tracking, Cognitive process;  Computer mouse;  Experimental comparison;  Eye-tracking;  Non-intrusive;  Recalibrations;  Small region;  Visual Attention, Graphic methods},
references={Carpenter, P.A., Shah, P., A model of the perceptual and conceptual processes in graph comprehension (1998) Journal of Experimental Psychology: Applied, 4 (2), pp. 75-100; Coren, S., Ward, L.M., Enns, J.T., (1994) Sensation and Perception, , Harcourt Brace and Co., fourth edition; Anders Ericsson, K., Herbert, A., (1993) Simon. Protocol Analysis: Verbal Reports as Data, , MIT Press, Cambridge, Massachusetts, revised edition; Hegarty, M., Mental animation: Inferring motion from static diagrams of mechanical systems (1992) Journal of Experimental Psychology: Learning, Memory and Cognition, 18 (5), pp. 1084-1102; Henderson, J.M., McClure, K.K., Pierce, S., Schrock, G., Object identification without foveal vision: Evidence from an artificial scotoma paradigm (1997) Perception & Psychophysics, 59 (3), pp. 323-346; Just, M.A., Patricia, A., Carpenter. Eye fixations and cognitive processes (1976) Cognitive Psychology, 8, pp. 441-480; Osaka, N., Oda, K., Moving window generator for reading experiments. Behavior Research Methods (1994) Instruments & Computers, 26 (1), pp. 49-53; Rayner, K., Eye movements in reading and information processing: 20 years of research (1998) Psychological Bulletin, 124 (3), pp. 372-422; Rayner, K., Pollatsek, A., (1989) The Psychology of Reading, , Prentice-Hall, Englewood Cliffs, New Jersey; Rayner, K., Pollatsek, A., Eye movements and scene perception (1992) Canadian Journal of Psychology, 46, pp. 342-376; Schnipke, S.K., Todd, M.W., Trials and tribulations of using an eyetracking system (2000) CHI 2000 Extended Abstracts, pp. 273-274; Stark, L.W., Ezumi, K., Nguyen, T., Paul, R., Tharp, G., Yamashita, H.I., Visual search in virtual environments (1992) Proceedings of the SPIE: Human Vision, Visual Processing, and Digital Display, 3 (1666), pp. 577-589; Steinke, T.R., Eye movement studies in cartography and related fields (1987) Cartographica, 24 (2), pp. 40-73. , Studies in Cartography, Monograph 37; Tovée, M.J., (1996) An Introduction to the Visual System, , Cambridge University Press; Ummelen, N., (1997) Procedural and Declarative Information in Software Manuals, , PhD thesis, Universiteit Twente, Utrecht; Yarbus, A.L., (1967) Eye Movements and Vision, , Plenum Press, NewY ork},
editor={Cheng P., Anderson M., Haarslev V.},
sponsors={},
publisher={Springer Verlag},
issn={03029743},
isbn={3540679154; 9783540679158},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}
